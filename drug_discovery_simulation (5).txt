#!/usr/bin/env python3 
"""Drug discovery simulation orchestrator built on Golden Turing AI architecture. 
 
This module instantiates a quantum-enhanced, multi-agent drug discovery pipeline 
modeled on the Golden Turing AI core and the multi-agent roadmap contained in the 
repository.  It integrates lambda-scale invariant geometry, curved spacetime 
simulators, and a lightweight LLM interface to coordinate the following agents: 
 
- StructuralAnalysisAgent 
- LigandDiscoveryAgent (inverse design + scaffold hopping) 
- QuantumSimulationAgent 
- SynthesisPlannerAgent 
- ScreeningAgent 
- SafetyAgent 
- IPAgent 
 
Each agent posts structured reports to a shared quantum blackboard.  The 
simulation optionally grounds itself in public datasets (RCSB PDB, PubChem, 
PatentsView, UniProt) when network access is available, falling back to curated 
examples if offline.  Quantum utility scores are derived from the 
``kg_scale_invariant_metric`` and ``phase4_entanglement`` modules to ensure the 
pipeline remains faithful to the repository's  -scale invariant principles. 
""" 
from __future__ import annotations 
 
import argparse
import ast
import asyncio
import copy
import csv
import difflib
import hashlib
import importlib
import io
import itertools
import json
import logging
import math
import os
import random
import shutil
import statistics
import tarfile
import tempfile
import textwrap
import time
import types
import zipfile
from datetime import datetime 
from collections import defaultdict, deque
from dataclasses import asdict, dataclass, field
from pathlib import Path 
from typing import Any, Callable, Dict, Iterable, List, Optional, Sequence, Set, Tuple 
from urllib import error as urlerror, request as urlrequest 
 
import numpy as np 
 
from kg_scale_invariant_metric import (
    FieldParams,
    GeometryParams,
    build_kg_operator,
    compute_modes,
    integrate_profile,
) 
from phase4_entanglement import (
    Params as EntanglementParams,
    build_adjacency,
    build_geometry,
    build_hamiltonian,
    single_particle_entropy_for_cut,
)
from rl_rewards import RewardPrimitives
 
 
LAMBDA_DILATION = float(np.sqrt(6.0) / 2.0) 
PHI_CONSTANT = float((1.0 + math.sqrt(5.0)) / 2.0) 
DUAL_SCALING_ALPHA = float(np.log(LAMBDA_DILATION) / np.log(PHI_CONSTANT))
DEFAULT_RANDOM_SEED = 1337
ENTROPY_FLOOR = 0.02
ENTROPY_CEILING = 12.0
ENTROPY_SHAPE_STRENGTH = 0.8
OCCUPANCY_PRIOR_WEIGHT = 0.35
 
 
SKLEARN_AVAILABLE = importlib.util.find_spec("sklearn") is not None
TORCH_AVAILABLE = importlib.util.find_spec("torch") is not None
PLOTLY_AVAILABLE = importlib.util.find_spec("plotly") is not None
MATPLOTLIB_AVAILABLE = importlib.util.find_spec("matplotlib") is not None
SHAP_AVAILABLE = importlib.util.find_spec("shap") is not None


logger = logging.getLogger(__name__)




@dataclass
class MDConfig:
    """Fully specified MD configuration to ensure reproducibility."""


    thermostat: str = "Langevin"
    barostat: str = "MonteCarlo"
    time_step_fs: float = 2.0
    total_time_ns: float = 2.0
    constraints: str = "h-bonds"
    cutoff_angstrom: float = 10.0
    pme_grid_spacing: float = 1.0
    solvent_model: str = "TIP3P"
    ion_concentration_molar: float = 0.15
    temperature_kelvin: float = 300.0
    pressure_atm: float = 1.0




@dataclass
class BindingResult:
    """Canonical binding free energy output derived from MD windows."""


    delta_g_kcal_mol: float
    temperature_kelvin: float
    standard_state: str
    force_field: str
    water_model: str
    md_windows: int
    convergence_diagnostics: Dict[str, Any]
    error_kcal_mol: float
    experimental_delta_g: Optional[float] = None




@dataclass
class QMResult:
    """Structured QM/MM post-processing result."""


    method: str
    qm_region: List[str]
    total_energy_hartree: float
    interaction_energy_hartree: float
    partial_charges: Dict[str, float]
    per_residue_energies: Optional[Dict[str, float]] = None




@dataclass
class MDTrajectorySummary:
    """Summary statistics derived from an MD trajectory."""


    rmsd: List[float]
    rmsf: List[float]
    hydrogen_bonds: List[int]
    contact_map_counts: Dict[str, int]
    potential_energy: List[float]
    temperature: List[float]
    key_distances: Dict[str, List[float]]




@dataclass
class VerificationConfig:
    """Configuration for a reproducible quantum/MD verification run."""


    name: str
    md_config: MDConfig
    benchmark_limit: int
    benchmark_proteins: List[str]
    description: str




def _deterministic_score(identifier: str) -> float:
    digest = hashlib.sha256(identifier.encode("utf-8")).digest()
    value = int.from_bytes(digest[:8], "big")
    return value / float(2**64 - 1)




class PretrainedModelHandle:
    """Lightweight deterministic stand-in for pretrained model artifacts."""


    def __init__(self, model_type: str, path: Path) -> None:
        self.model_type = model_type
        self.path = path
        self.fingerprint = hashlib.sha1(str(path).encode("utf-8")).hexdigest()  # nosec B324


    def score(self, identifier: str) -> float:
        token = f"{self.model_type}:{self.fingerprint}:{identifier}"
        return _deterministic_score(token)


    def describe(self) -> Dict[str, Any]:
        return {
            "modelType": self.model_type,
            "path": str(self.path),
            "fingerprint": self.fingerprint,
        }


@@ -371,2865 +440,2972 @@ class QuantumPretrainer:
        for entry in per_ligand_reports:
            smiles = entry.get("smiles")
            energy = entry.get("bindingFreeEnergy")
            if not smiles or energy is None:
                continue
            if not math.isfinite(energy):
                continue
            target = float(np.clip(np.tanh(-energy / 15.0), 0.0, 1.0))
            dataset.append((smiles, target))
        return dataset


    def train(self, dataset: Sequence[Tuple[str, float]]) -> LightweightGNN:
        if len(dataset) < self.min_samples:
            return self.surrogate_model
        context = self.context_provider()
        lambda_stats = QuantumContext.shell_statistics(context.lambda_shells)
        lambda_context = {
            "entropyMean": lambda_stats.get("entropyMean", 0.5),
            "curvatureMean": lambda_stats.get("curvatureMean", 0.1),
        }
        batch_size = max(4, min(16, len(dataset)))
        for start in range(0, len(dataset), batch_size):
            batch = dataset[start : start + batch_size]
            self.surrogate_model.train_step(batch, lambda_context=lambda_context, learning_rate=self.learning_rate)
        return self.surrogate_model


if SKLEARN_AVAILABLE:
    sklearn_metrics_module = importlib.import_module("sklearn.metrics")
    sklearn_model_selection_module = importlib.import_module("sklearn.model_selection")
    sklearn_ensemble_module = importlib.import_module("sklearn.ensemble")
    sklearn_linear_module = importlib.import_module("sklearn.linear_model")
    sklearn_neural_module = importlib.import_module("sklearn.neural_network")
    RandomForestRegressor = getattr(sklearn_ensemble_module, "RandomForestRegressor")
    RandomForestClassifier = getattr(sklearn_ensemble_module, "RandomForestClassifier")
    LogisticRegression = getattr(sklearn_linear_module, "LogisticRegression")
    MLPRegressor = getattr(sklearn_neural_module, "MLPRegressor")
    ParameterGrid = getattr(sklearn_model_selection_module, "ParameterGrid")
    roc_auc_score = getattr(sklearn_metrics_module, "roc_auc_score")
    precision_recall_fscore_support = getattr(sklearn_metrics_module, "precision_recall_fscore_support")
else:  # pragma: no cover - optional dependency
    RandomForestRegressor = None
    RandomForestClassifier = None
    LogisticRegression = None
    MLPRegressor = None
    ParameterGrid = None
    roc_auc_score = None
    precision_recall_fscore_support = None




@dataclass
class LambdaShellDescriptor:
    shell_index: int
    lambdaRadius: float
    lambdaCurvature: float
    lambdaEntropy: float
    lambdaEnergyDensity: float
    lambdaBhattacharyya: float
    lambdaOccupancy: float
    lambdaLeakage: float


    def to_dict(self) -> Dict[str, Any]:
        return {
            "shellIndex": self.shell_index,
            "lambdaRadius": self.lambdaRadius,
            "lambdaCurvature": self.lambdaCurvature,
            "lambdaEntropy": self.lambdaEntropy,
            "lambdaEnergyDensity": self.lambdaEnergyDensity,
            "lambdaBhattacharyya": self.lambdaBhattacharyya,
            "lambdaOccupancy": self.lambdaOccupancy,
            "lambdaLeakage": self.lambdaLeakage,
        }




def set_global_random_seed(seed: int) -> None:
    """Set random seeds across supported libraries for reproducibility."""


    random.seed(seed)
    np.random.seed(seed)
    os.environ.setdefault("PYTHONHASHSEED", str(seed))
    if TORCH_AVAILABLE:
        torch_module = importlib.import_module("torch")
        torch_module.manual_seed(seed)
        if hasattr(torch_module, "cuda") and hasattr(torch_module.cuda, "manual_seed_all"):
            torch_module.cuda.manual_seed_all(seed)
        if hasattr(torch_module, "backends") and hasattr(torch_module.backends, "cudnn"):
            cudnn = torch_module.backends.cudnn
            setattr(cudnn, "deterministic", True)
            setattr(cudnn, "benchmark", False)




# ---------------------------------------------------------------------------
# Lambda training diagnostics hook
# ---------------------------------------------------------------------------




def lambda_shell_training_hook(
    agent_name: str,
    context: "QuantumContext",
    current_state: Dict[str, Any],
) -> Dict[str, Any]:
    """Record shell-aware training diagnostics for downstream learning."""


    descriptors: Iterable[Dict[str, Any]] = ()
    if isinstance(current_state, dict):
        if "descriptors" in current_state:
            descriptors = current_state["descriptors"]
        elif "lambdaShellDiagnostics" in current_state:
            descriptors = current_state["lambdaShellDiagnostics"].get("descriptors", [])
    descriptors = list(descriptors) or context.lambda_shells
    if not descriptors:
        return {
            "agent": agent_name,
            "shellCount": 0,
            "entropyPerShell": [],
            "curvatureGradient": 0.0,
            "lambdaLeakage": 0.0,
            "timestamp": time.time(),
        }
    entropies = [float(entry.get("lambdaEntropy", 0.0)) for entry in descriptors]
    curvatures = [float(entry.get("lambdaCurvature", 0.0)) for entry in descriptors]
    leakages = [float(entry.get("lambdaLeakage", 0.0)) for entry in descriptors]
    curvature_gradient = float(curvatures[-1] - curvatures[0]) if len(curvatures) > 1 else 0.0
    record = {
        "agent": agent_name,
        "shellCount": len(descriptors),
        "entropyPerShell": entropies,
        "curvatureGradient": curvature_gradient,
        "lambdaLeakage": float(np.mean(leakages)),
        "timestamp": time.time(),
    }
    return record




# ---------------------------------------------------------------------------
# Utility loaders for repository components
# ---------------------------------------------------------------------------


def _dynamic_import(module_name: str, file_name: str):
    """Import repository modules that use non-standard suffixes (e.g. .py.txt)."""
    candidate = Path(file_name)
    if not candidate.exists():
        raise FileNotFoundError(f"Required module '{file_name}' not found")
    text = candidate.read_text(encoding="utf-8", errors="ignore")
    text = text.lstrip("\ufeff")
    text = text.encode("ascii", "ignore").decode("ascii")
    module = types.ModuleType(module_name)
    module.__file__ = str(candidate.resolve())
    exec(compile(text, module.__file__, "exec"), module.__dict__)
    return module




def _extract_default_config(candidate: Path) -> Dict[str, Any]:
    text = candidate.read_text(encoding="utf-8", errors="ignore")
    marker = "DEFAULT_AI_CONFIG"
    idx = text.find(marker)
    if idx == -1:
        return {"ai_state_dim": 32, "max_memory_size": 500}
    brace_start = text.find("{", idx)
    if brace_start == -1:
        return {"ai_state_dim": 32, "max_memory_size": 500}
    depth = 0
    end_idx = brace_start
    for pos in range(brace_start, len(text)):
        char = text[pos]
        if char == "{":
            depth += 1
        elif char == "}":
            depth -= 1
            if depth == 0:
                end_idx = pos + 1
                break
    snippet = text[brace_start:end_idx]
    try:
        config = ast.literal_eval(snippet)
        if isinstance(config, dict):
            return config
    except Exception:
        pass
    return {"ai_state_dim": 32, "max_memory_size": 500}




def load_golden_turing_ai():
    candidate = Path("golden_turing_module_10.py.txt")
    try:
        module = _dynamic_import("golden_turing_module_10", candidate.name)
        if not hasattr(module, "GoldenTuringAI"):
            raise AttributeError("GoldenTuringAI class not found in the loaded module")
        return module.GoldenTuringAI
    except Exception:
        base_config = _extract_default_config(candidate)


        class GoldenTuringAIStub:
            """Lightweight stand-in preserving Golden Turing multi-agent hooks."""


            def __init__(self, config: Optional[Dict[str, Any]] = None, crawler_id: str = "AI", initial_state_dim: Optional[int] = None):
                self.crawler_id = crawler_id
                self.config = copy.deepcopy(base_config)
                if config:
                    for key, value in config.items():
                        if isinstance(self.config.get(key), dict) and isinstance(value, dict):
                            self.config[key].update(value)
                        else:
                            self.config[key] = value
                if initial_state_dim:
                    self.config["ai_state_dim"] = initial_state_dim
                self.state_dim = int(self.config.get("ai_state_dim", 32))
                self.state = np.zeros(self.state_dim, dtype=float)
                self.blackboard = None
                self.agent_pool: Dict[str, Any] = {}
                self.planning_stack: deque = deque()
                self.strategy_history: deque = deque(maxlen=50)


            def register_agent(self, name: str, agent: Any) -> None:
                self.agent_pool[name] = agent


            def inject_blackboard_interface(self, blackboard: QuantumBlackboard) -> None:
                self.blackboard = blackboard


            def prioritize_planning_task(self, task: Dict[str, Any]) -> None:
                self.planning_stack.appendleft(task)


            def enqueue_planning_task(self, task: Dict[str, Any]) -> None:
                self.planning_stack.append(task)


            def manage_planning_stack(self) -> Optional[Dict[str, Any]]:
                if not self.planning_stack:
                    return None
                plan_task = self.planning_stack.popleft()
                return {"action_type": "EXECUTE_PLAN", "plan_task": plan_task}


            def delegate_task(self, agent_name: str, task: Dict[str, Any]) -> None:
                agent = self.agent_pool.get(agent_name)
                if agent and hasattr(agent, "receive_task"):
                    agent.receive_task(task)


        return GoldenTuringAIStub




# ---------------------------------------------------------------------------
# Shared data structures
# ---------------------------------------------------------------------------




@dataclass
class QuantumBlackboard:
    """Minimal quantum-inspired blackboard with  -scale persistence."""


    posts: Dict[str, Dict[str, Any]] = field(default_factory=dict)
    timeline: List[Tuple[str, str]] = field(default_factory=list)
    canonical_basis: str = "phi"


    @staticmethod
    def _lambda_to_phi(value: float) -> float:
        return float(np.sign(value) * np.power(abs(value) + 1e-9, DUAL_SCALING_ALPHA))


    def _canonicalize_scaling(self, payload: Any) -> Any:
        if isinstance(payload, dict):
            normalized: Dict[str, Any] = {}
            basis = payload.get("scalingBasis") or payload.get("basis")
            for key, value in payload.items():
                normalized[key] = self._canonicalize_scaling(value)
            if "descriptors" in payload and payload.get("descriptors") and isinstance(payload["descriptors"], list):
                descriptors = payload["descriptors"]
                if descriptors and any("lambda" in k for k in descriptors[0].keys()):
                    phi_descriptors = []
                    for descriptor in descriptors:
                        phi_descriptors.append(
                            {
                                "phiRadius": self._lambda_to_phi(descriptor.get("lambdaRadius", 0.0)),
                                "phiCurvature": self._lambda_to_phi(descriptor.get("lambdaCurvature", 0.0)),
                                "phiEntropy": self._lambda_to_phi(descriptor.get("lambdaEntropy", 0.0)),
                                "phiEnergyDensity": self._lambda_to_phi(descriptor.get("lambdaEnergyDensity", 0.0)),
                                "phiBhattacharyya": self._lambda_to_phi(descriptor.get("lambdaBhattacharyya", 0.0)),
                                "phiOccupancy": self._lambda_to_phi(descriptor.get("lambdaOccupancy", 0.0)),
                                "phiLeakage": self._lambda_to_phi(descriptor.get("lambdaLeakage", 0.0)),
                                "shellIndex": descriptor.get("shellIndex"),
                            }
                        )
                    fingerprint = payload.get("summary", {}).get("lambdaShellFingerprint") or payload.get("fingerprint", [])
                    phi_fingerprint = [self._lambda_to_phi(val) for val in fingerprint]
                    normalized["canonicalScaling"] = {
                        "basis": self.canonical_basis,
                        "descriptors": phi_descriptors,
                        "fingerprint": phi_fingerprint,
                    }
                    summary = normalized.setdefault("summary", {})
                    summary.setdefault("scalingBasis", basis or "lambda")
                    normalized["canonicalScaling"]["summary"] = {"scalingBasis": self.canonical_basis}
            if basis and basis != self.canonical_basis:
                normalized["canonicalBasis"] = self.canonical_basis
            return normalized
        if isinstance(payload, list):
            return [self._canonicalize_scaling(item) for item in payload]
        return payload


    async def post(self, channel: str, report: Dict[str, Any]) -> None:
        canonical_report = self._canonicalize_scaling(copy.deepcopy(report))
        self.posts[channel] = canonical_report
        self.timeline.append((channel, canonical_report.get("reportId") or canonical_report.get("jobId", " ")))


    async def read(self, channel: str) -> Optional[Dict[str, Any]]:
        return self.posts.get(channel)


    async def snapshot(self) -> Dict[str, Any]:
        return {"timeline": list(self.timeline), "posts": dict(self.posts)}




@dataclass
class QuantumContext:
    """Holds quantum enhancement metrics shared across agents."""


    curvature_profile: List[float]
    lambda_modes: List[float]
    entanglement_entropy: float
    enhancement_factor: float
    lambda_shells: List[Dict[str, Any]] = field(default_factory=list)
    lambda_basis: Dict[str, Any] = field(default_factory=dict)


    def to_snapshot(self) -> Dict[str, Any]:
        return {
            "curvature_profile": list(self.curvature_profile),
            "lambda_modes": list(self.lambda_modes),
            "entanglement_entropy": float(self.entanglement_entropy),
            "enhancement_factor": float(self.enhancement_factor),
            "lambda_shells": copy.deepcopy(self.lambda_shells),
            "lambda_basis": copy.deepcopy(self.lambda_basis),
        }


    def clone(self) -> "QuantumContext":
        return QuantumContext.from_snapshot(self.to_snapshot())


    @staticmethod
    def from_snapshot(snapshot: Dict[str, Any]) -> "QuantumContext":
        return QuantumContext(
            curvature_profile=list(snapshot.get("curvature_profile", [])),
            lambda_modes=list(snapshot.get("lambda_modes", [])),
            entanglement_entropy=float(snapshot.get("entanglement_entropy", 0.0)),
            enhancement_factor=float(snapshot.get("enhancement_factor", 0.0)),
            lambda_shells=copy.deepcopy(snapshot.get("lambda_shells", [])),
            lambda_basis=copy.deepcopy(snapshot.get("lambda_basis", {})),
        )


    @staticmethod
    def shell_statistics(descriptors: Iterable[Dict[str, Any]]) -> Dict[str, Any]:
        entries = list(descriptors or [])
        if not entries:
            return {
                "shellCount": 0,
                "entropyMean": 0.0,
                "entropyStd": 0.0,
                "bhattacharyyaMean": 0.0,
                "curvatureMean": 0.0,
                "entropyDistribution": [],
                "occupancyDistribution": [],
            }
        entropies = np.array([float(item.get("lambdaEntropy", 0.0)) for item in entries], dtype=float)
        curvatures = np.array([float(item.get("lambdaCurvature", 0.0)) for item in entries], dtype=float)
        bhattacharyya = np.array([float(item.get("lambdaBhattacharyya", 0.0)) for item in entries], dtype=float)
        occupancy = np.array([float(item.get("lambdaOccupancy", 0.0)) for item in entries], dtype=float)
        entropy_sum = float(np.sum(entropies))
        occ_sum = float(np.sum(occupancy))
        if entropy_sum <= 0.0:
            entropy_dist = np.full(len(entries), 1.0 / float(len(entries)), dtype=float)
        else:
            entropy_dist = entropies / entropy_sum
        if occ_sum <= 0.0:
            occupancy_dist = np.full(len(entries), 1.0 / float(len(entries)), dtype=float)
        else:
            occupancy_dist = occupancy / occ_sum
        return {
            "shellCount": int(len(entries)),
            "entropyMean": float(np.mean(entropies)),
            "entropyStd": float(np.std(entropies)),
            "bhattacharyyaMean": float(np.mean(bhattacharyya)),
            "curvatureMean": float(np.mean(curvatures)),
            "entropyDistribution": entropy_dist.tolist(),
            "occupancyDistribution": occupancy_dist.tolist(),
        }


    @staticmethod
    def diff_snapshots(before: Dict[str, Any], after: Dict[str, Any]) -> Dict[str, Any]:
        before_stats = QuantumContext.shell_statistics(before.get("lambda_shells", []))
        after_stats = QuantumContext.shell_statistics(after.get("lambda_shells", []))
        max_len = max(len(before_stats["occupancyDistribution"]), len(after_stats["occupancyDistribution"]))


        def _pad(values: List[float]) -> np.ndarray:
            arr = np.asarray(values, dtype=float)
            if arr.size < max_len:
                arr = np.pad(arr, (0, max_len - arr.size), constant_values=0.0)
            return arr


        before_occ = _pad(before_stats["occupancyDistribution"])
        after_occ = _pad(after_stats["occupancyDistribution"])
        occupancy_l1 = float(np.sum(np.abs(after_occ - before_occ)))
        basis_before = before.get("lambda_basis", {})
        basis_after = after.get("lambda_basis", {})
        basis_keys = set(basis_before.keys()) | set(basis_after.keys())
        basis_changes: Dict[str, Dict[str, Any]] = {}
        for key in basis_keys:
            if basis_before.get(key) != basis_after.get(key):
                basis_changes[key] = {"before": basis_before.get(key), "after": basis_after.get(key)}
        return {
            "shellCountDelta": after_stats["shellCount"] - before_stats["shellCount"],
            "entropyMeanDelta": after_stats["entropyMean"] - before_stats["entropyMean"],
            "entropyStdDelta": after_stats["entropyStd"] - before_stats["entropyStd"],
            "bhattacharyyaDelta": after_stats["bhattacharyyaMean"] - before_stats["bhattacharyyaMean"],
            "curvatureMeanDelta": after_stats["curvatureMean"] - before_stats["curvatureMean"],
            "occupancyL1Delta": occupancy_l1,
            "entanglementEntropyDelta": float(after.get("entanglement_entropy", 0.0) - before.get("entanglement_entropy", 0.0)),
            "enhancementFactorDelta": float(after.get("enhancement_factor", 0.0) - before.get("enhancement_factor", 0.0)),
            "lambdaBasisChanges": basis_changes,
        }




# ---------------------------------------------------------------------------
# Lightweight LLM interface
# ---------------------------------------------------------------------------




class LightweightLLM:
    """Adapter for the TinyLlama GGUF model with graceful degradation."""


    def __init__(self, model_path: Path, max_tokens: int = 256):
        self.model_path = model_path
        self.max_tokens = max_tokens
        self._llama = None
        try:
            from llama_cpp import Llama  # type: ignore


            if model_path.exists():
                self._llama = Llama(model_path=str(model_path), n_ctx=2048, n_threads=os.cpu_count() or 4)
        except Exception:
            # llama-cpp-python not available; the interface will synthesize responses heuristically
            self._llama = None


    def complete(self, prompt: str, temperature: float = 0.2) -> str:
        if self._llama is not None:
            output = self._llama(prompt=prompt, max_tokens=self.max_tokens, temperature=temperature, stop=["###"])
            if isinstance(output, dict):
                choices = output.get("choices", [])
                if choices:
                    return choices[0].get("text", "").strip()
        # Fallback heuristic completion
        summary = textwrap.shorten(prompt.split("\n")[-1], width=200)
        return f"Heuristic plan based on context: {summary}"




# ---------------------------------------------------------------------------
# Machine learning integration utilities
# ---------------------------------------------------------------------------




class FeatureExtractor:
    """Feature extraction for diverse chemical, structural, and quantum data."""


    def __init__(self, fingerprint_size: int = 256) -> None:
        self.fingerprint_size = fingerprint_size


    def _hash_sequence(self, sequence: str, size: Optional[int] = None) -> np.ndarray:
        length = size or self.fingerprint_size
        if length <= 0:
            length = 64
        vector = np.zeros(length, dtype=float)
        if not sequence:
            return vector
        for idx, char in enumerate(sequence):
            bucket = (hash((char, idx)) % length + length) % length
            vector[bucket] += 1.0
        norm = np.linalg.norm(vector)
        if norm > 0:
            vector /= norm
        return vector


    def featurize_smiles(self, smiles: str) -> np.ndarray:
        return self._hash_sequence(smiles, self.fingerprint_size)


    def featurize_sequence(self, sequence: str) -> np.ndarray:
        return self._hash_sequence(sequence, self.fingerprint_size // 2)


    def featurize_quantum_sample(self, sample: Dict[str, Any]) -> np.ndarray:
        orbital = np.array(sample.get("orbitalOccupations", [0.25, 0.25, 0.25, 0.25]), dtype=float)
        entropy = float(sample.get("entanglementEntropy", 0.1))
        binding = float(sample.get("bindingEnergy", -5.0))
        fidelity = float(sample.get("fidelity", 0.95))
        lambda_fp = np.asarray(sample.get("lambdaShellFingerprint", [0.0] * 7), dtype=float)
        descriptor = np.concatenate([
            np.array([binding, entropy, fidelity], dtype=float),
            orbital,
            lambda_fp[:7],
        ])
        return descriptor


    def featurize_pocket(self, pocket: Dict[str, Any]) -> np.ndarray:
        properties = pocket.get("properties", {})
        vector = np.array(
            [
                float(pocket.get("druggabilityScore", 0.0)),
                float(properties.get("volume", 1.0)),
                float(properties.get("hydrophobicity", 0.5)),
                float(properties.get("electrostaticPotential", -1.0)),
            ],
            dtype=float,
        )
        return vector


    def featurize_lambda_shells(self, descriptors: Iterable[Dict[str, Any]]) -> np.ndarray:
        vector: List[float] = []
        for entry in descriptors:
            vector.extend(
                [
                    float(entry.get("lambdaRadius", 0.0)),
                    float(entry.get("lambdaCurvature", 0.0)),
                    float(entry.get("lambdaEntropy", 0.0)),
                    float(entry.get("lambdaEnergyDensity", 0.0)),
                    float(entry.get("lambdaBhattacharyya", 0.0)),
                    float(entry.get("lambdaOccupancy", 0.0)),
                    float(entry.get("lambdaLeakage", 0.0)),
                ]
            )
        if not vector:
            vector = [0.0] * 7
        return np.array(vector, dtype=float)


    def combine_features(self, *features: np.ndarray) -> np.ndarray:
        if not features:
            return np.zeros(1, dtype=float)
        flattened = [np.atleast_1d(feature).astype(float) for feature in features]
        return np.concatenate(flattened)




@dataclass
class BenchmarkDatasetRecord:
    dataset: str
    task: str
    smiles: str
    label: float
    metadata: Dict[str, Any]




class BenchmarkDatasetUtility:
    """Downloads and preprocesses benchmark datasets into unified records."""


    SOURCES: Dict[str, Dict[str, Any]] = {
        "DUD-E": {
            "url": "https://raw.githubusercontent.com/deepchem/deepchem/master/examples/assets/dude.csv",
            "format": "csv",
            "columns": {"smiles": "smiles", "label": "label"},
        },
        "ChEMBL": {
            "url": "https://raw.githubusercontent.com/chembl/chembl_webresource_client/master/chembl_webresource_client/tests/resources/activity_sample.csv",
            "format": "csv",
            "columns": {"smiles": "canonical_smiles", "label": "standard_value"},
        },
        "ZINC15": {
            "url": "https://raw.githubusercontent.com/deepchem/deepchem/master/examples/assets/zinc15_sample.csv",
            "format": "csv",
            "columns": {"smiles": "smiles", "label": None},
        },
    }


    BINDING_BENCHMARK: List[Dict[str, Any]] = [
        {
            "protein": "FAK1",
            "ligand": "LIG-FAK-001",
            "smiles": "CC(C)Nc1ccc(cc1)C(=O)N",
            "pdb_id": "2J0J",
            "affinity_type": "Kd",
            "affinity_value": 18.0,
            "affinity_units": "nM",
            "temperature_K": 298.15,
        },
        {
            "protein": "CDK2",
            "ligand": "LIG-CDK-001",
            "smiles": "COc1cccc2c1CC(N)C(=O)N2",
            "pdb_id": "2VTA",
            "affinity_type": "Ki",
            "affinity_value": 210.0,
            "affinity_units": "nM",
            "temperature_K": 300.0,
        },
        {
            "protein": "MAPK14",
            "ligand": "LIG-MAPK14-001",
            "smiles": "CC1=CC(=C(C=C1Cl)NC(=O)C2=NC(=NC=N2)N)Cl",
            "pdb_id": "1KV1",
            "affinity_type": "Kd",
            "affinity_value": 0.09,
            "affinity_units": "nM",
            "temperature_K": 298.15,
        },
    ]


    def __init__(self, cache_dir: Path | None = None) -> None:
        self.cache_dir = cache_dir or Path("datasets")
        self.cache_dir.mkdir(parents=True, exist_ok=True)


    def _download(self, dataset: str) -> Optional[Path]:
        spec = self.SOURCES.get(dataset)
        if spec is None:
            return None
        target_path = self.cache_dir / f"{dataset.lower()}_raw.{spec['format']}"
        if target_path.exists():
            return target_path
        url = spec.get("url")
        if not url:
            return None
        try:
            with urlrequest.urlopen(url, timeout=30) as response:
                data = response.read()
            target_path.write_bytes(data)
            return target_path
        except Exception as exc:  # pragma: no cover - network best effort
            logging.warning("Failed to download %s dataset: %s", dataset, exc)
            return None


    def _load_csv(
        self,
        dataset: str,
        path: Path,
        columns: Dict[str, Optional[str]],
        limit: int,
    ) -> List[BenchmarkDatasetRecord]:
        records: List[BenchmarkDatasetRecord] = []
        label_column = columns.get("label")
        with path.open("r", encoding="utf-8", errors="ignore") as handle:
            reader = csv.DictReader(handle)
            for idx, row in enumerate(reader):
                if limit and idx >= limit:
                    break
                smiles = row.get(columns.get("smiles", "smiles"), "")
                if not smiles:
                    continue
                raw_label = float(row.get(label_column, 0.0)) if label_column else 0.0
                label = raw_label
                if dataset == "ChEMBL":
                    label = 1.0 if raw_label and raw_label < 1000 else 0.0
                elif dataset == "ZINC15":
                    label = 0.5  # availability only
                metadata = {"sourceRow": idx, "raw": row}
                records.append(
                    BenchmarkDatasetRecord(
                        dataset=dataset,
                        task=f"benchmark.{dataset.lower()}",
                        smiles=smiles,
                        label=float(label),
                        metadata=metadata,
                    )
                )
        return records


    def load(self, dataset: str, limit: int = 500) -> List[BenchmarkDatasetRecord]:
        spec = self.SOURCES.get(dataset)
        if spec is None:
            return []
        path = self._download(dataset)
        if path is not None and spec.get("format") == "csv":
            try:
                return self._load_csv(dataset, path, spec["columns"], limit)
            except Exception as exc:  # pragma: no cover - defensive
                logging.warning("Failed to parse %s dataset: %s", dataset, exc)
        logging.info("Falling back to synthetic %s benchmark records", dataset)
        rng = np.random.default_rng(DEFAULT_RANDOM_SEED)
        synthetic: List[BenchmarkDatasetRecord] = []
        for idx in range(limit):
            smiles = f"C{idx}H{idx}O{idx%3}"
            label = float(rng.random())
            synthetic.append(
                BenchmarkDatasetRecord(
                    dataset=dataset,
                    task=f"benchmark.{dataset.lower()}",
                    smiles=smiles,
                    label=label,
                    metadata={"synthetic": True, "index": idx},
                )
                )
        return synthetic


    @staticmethod
    def affinity_to_delta_g(affinity_value: float, units: str, temperature_K: float) -> float:
        R = 0.001987  # kcal/(mol*K)
        unit = units.lower()
        value_molar = affinity_value
        if unit in {"nm", "nmol", "nmolar", "nm"}:
            value_molar = affinity_value * 1e-9
        elif unit in {"um", "umol", "umolar"}:
            value_molar = affinity_value * 1e-6
        elif unit in {"mm", "mmol", "mmolar"}:
            value_molar = affinity_value * 1e-3
        delta_g = R * temperature_K * math.log(max(value_molar, 1e-30))
        return float(delta_g)


    def load_binding_benchmark(self, limit: int = 3) -> List[Dict[str, Any]]:
        selected = self.BINDING_BENCHMARK[:limit]
        enriched: List[Dict[str, Any]] = []
        for record in selected:
            delta_g = self.affinity_to_delta_g(
                record["affinity_value"], record["affinity_units"], record["temperature_K"]
            )
            enriched.append({**record, "delta_g_exp": delta_g})
        return enriched


@dataclass
class DatasetSplit:
    train_X: np.ndarray
    train_y: np.ndarray
    val_X: np.ndarray
    val_y: np.ndarray
    test_X: np.ndarray
    test_y: np.ndarray
    normalization: Dict[str, np.ndarray]
    metadata: Dict[str, Any]




class DatasetManager:
    """Curates datasets with normalization, augmentation, and splits."""


    def __init__(
        self,
        feature_extractor: FeatureExtractor,
        benchmark_utility: Optional[BenchmarkDatasetUtility] = None,
        random_seed: int = DEFAULT_RANDOM_SEED,
    ) -> None:
        self.feature_extractor = feature_extractor
        self.records: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
        self.splits: Dict[str, DatasetSplit] = {}
        self.task_types: Dict[str, str] = {}
        self.benchmark_metadata: Dict[str, Any] = {}
        self.random_seed = random_seed
        self.benchmark_utility = benchmark_utility or BenchmarkDatasetUtility()


    def register_record(self, task: str, features: np.ndarray, label: float, metadata: Dict[str, Any]) -> None:
        self.records[task].append({
            "features": np.asarray(features, dtype=float),
            "label": float(label),
            "metadata": metadata,
        })
        task_type = self.task_types.get(task)
        inferred = "classification" if float(label).is_integer() and label in (0.0, 1.0) else "regression"
        if task_type is None:
            self.task_types[task] = inferred
        elif task_type != inferred:
            self.task_types[task] = "mixed"


    def _normalize(self, X: np.ndarray) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:
        if X.size == 0:
            return X, {"mean": np.zeros(1), "std": np.ones(1)}
        mean = X.mean(axis=0)
        std = X.std(axis=0)
        std[std == 0] = 1.0
        normalized = (X - mean) / std
        return normalized, {"mean": mean, "std": std}


    def build_split(self, task: str, test_ratio: float = 0.2, val_ratio: float = 0.2) -> DatasetSplit:
        records = self.records.get(task, [])
        if not records:
            empty = np.zeros((0, 4))
            return DatasetSplit(empty, empty, empty, empty, empty, empty, {"mean": np.zeros(1), "std": np.ones(1)}, {"records": 0})
        features = np.stack([entry["features"] for entry in records])
        labels = np.array([entry["label"] for entry in records], dtype=float)
        idx = np.arange(len(records))
        rng = np.random.default_rng(self.random_seed)
        rng.shuffle(idx)
        features = features[idx]
        labels = labels[idx]
        n_test = max(1, int(len(records) * test_ratio)) if len(records) > 3 else max(0, len(records) - 2)
        n_val = max(1, int(len(records) * val_ratio)) if len(records) > 3 else 1
        n_train = max(1, len(records) - n_test - n_val)
        test_X, test_y = features[:n_test], labels[:n_test]
        val_X, val_y = features[n_test:n_test + n_val], labels[n_test:n_test + n_val]
        train_X, train_y = features[n_test + n_val:], labels[n_test + n_val:]
        norm_train_X, normalization = self._normalize(train_X)
        norm_val_X = (val_X - normalization["mean"]) / normalization["std"] if val_X.size else val_X
        norm_test_X = (test_X - normalization["mean"]) / normalization["std"] if test_X.size else test_X
        split = DatasetSplit(
            norm_train_X,
            train_y,
            norm_val_X,
            val_y,
            norm_test_X,
            test_y,
            normalization,
            {"records": len(records)},
        )
        self.splits[task] = split
        return split


    def get_split(self, task: str) -> Optional[DatasetSplit]:
        return self.splits.get(task)


    def get_task_type(self, task: str) -> str:
        return self.task_types.get(task, "regression")


    def augment_with_quantum_samples(self, task: str, samples: List[Dict[str, Any]], target_key: str) -> None:
        for sample in samples:
            features = self.feature_extractor.featurize_quantum_sample(sample)
            label = float(sample.get(target_key, 0.0))
            self.register_record(task, features, label, {"source": "quantum_reference", "ligandId": sample.get("ligandId")})


    def integrate_benchmark_dataset(
        self,
        dataset: str,
        context: QuantumContext,
        limit: int = 500,
    ) -> Dict[str, Any]:
        records = self.benchmark_utility.load(dataset, limit)
        lambda_fp = np.asarray(LambdaScalingToolkit.fingerprint(context.lambda_shells), dtype=float)
        lambda_shell_features = self.feature_extractor.featurize_lambda_shells(context.lambda_shells)
        ingested = 0
        last_task = f"benchmark.{dataset.lower()}"
        for record in records:
            smiles_feat = self.feature_extractor.featurize_smiles(record.smiles)
            feature_vec = self.feature_extractor.combine_features(smiles_feat, lambda_shell_features)
            feature_vec = self.feature_extractor.combine_features(feature_vec, lambda_fp)
            metadata = {"dataset": dataset, **record.metadata}
            self.register_record(record.task, feature_vec, record.label, metadata)
            ingested += 1
            last_task = record.task
        if ingested:
            split = self.build_split(last_task)
            normalization_summary: Dict[str, Any] = {}
            if split and isinstance(split.normalization, dict):
                normalization_summary = {
                    key: np.asarray(value).tolist()
                    for key, value in split.normalization.items()
                }
            self.benchmark_metadata[dataset] = {
                "records": ingested,
                "task": last_task,
                "taskType": self.get_task_type(last_task),
                "normalization": normalization_summary,
            }
        else:
            self.benchmark_metadata[dataset] = {"records": 0, "task": f"benchmark.{dataset.lower()}"}
        return self.benchmark_metadata[dataset]


    def prepare_benchmarks(
        self,
        datasets: Sequence[str],
        context: QuantumContext,
        limit: int = 500,
    ) -> Dict[str, Any]:
        summary: Dict[str, Any] = {}
        for name in datasets:
            summary[name] = self.integrate_benchmark_dataset(name, context, limit=limit)
        return summary




class BenchmarkEvaluator:
    """Compare computed binding energetics against experimental references."""


    @staticmethod
    def evaluate(predictions: List[BindingResult], references: List[Dict[str, Any]]) -> Dict[str, Any]:
        reference_map = {(ref["protein"], ref["ligand"]): ref for ref in references}
        residuals: List[float] = []
        per_target: Dict[str, List[float]] = defaultdict(list)
        for pred in predictions:
            metadata = pred.convergence_diagnostics.get("metadata", {})
            key = (metadata.get("protein"), metadata.get("ligand"))
            reference = reference_map.get(key)
            if not reference:
                continue
            delta_g_exp = float(reference.get("delta_g_exp", 0.0))
            residual = float(pred.delta_g_kcal_mol - delta_g_exp)
            residuals.append(residual)
            per_target[key[0]].append(residual)
        summary = {
            "count": len(residuals),
            "mean_residual": float(np.mean(residuals)) if residuals else 0.0,
            "rmse": float(np.sqrt(np.mean(np.square(residuals)))) if residuals else 0.0,
            "per_target": {k: {"rmse": float(np.sqrt(np.mean(np.square(v))))} for k, v in per_target.items()},
        }
        return summary




class StatisticalValidationEngine:
    """Computes statistical metrics and manages validation history."""


    def __init__(self, random_seed: int = DEFAULT_RANDOM_SEED) -> None:
        self.random_seed = random_seed
        self.history: List[Dict[str, Any]] = []


    @staticmethod
    def _bhattacharyya_divergence(p: np.ndarray, q: np.ndarray) -> float:
        p_sum = float(np.sum(p))
        q_sum = float(np.sum(q))
        if p_sum == 0 or q_sum == 0:
            return float("inf")
        p_norm = p / p_sum
        q_norm = q / q_sum
        coefficient = float(np.sum(np.sqrt(p_norm * q_norm)))
        coefficient = float(np.clip(coefficient, 1e-9, 1.0))
        return float(-math.log(coefficient))


    @staticmethod
    def _simple_auc(y_true: np.ndarray, scores: np.ndarray) -> float:
        order = np.argsort(scores)
        y_sorted = y_true[order]
        scores_sorted = scores[order]
        cum_pos = np.cumsum(y_sorted[::-1])[::-1]
        cum_neg = np.cumsum(1 - y_sorted[::-1])[::-1]
        total_pos = cum_pos[0] if cum_pos.size else 0.0
        total_neg = cum_neg[0] if cum_neg.size else 0.0
        if total_pos == 0 or total_neg == 0:
            return 0.5
        tpr = cum_pos / total_pos
        fpr = cum_neg / total_neg
        return float(np.trapz(tpr, fpr))


    def regression_metrics(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:
        if y_true.size == 0 or y_pred.size == 0:
            return {"mae": 0.0, "rmse": 0.0, "r2": 0.0, "bhattacharyya": 0.0}
        residuals = y_true - y_pred
        mae = float(np.mean(np.abs(residuals))) if residuals.size else float("nan")
        rmse = float(np.sqrt(np.mean(residuals ** 2))) if residuals.size else float("nan")
        if residuals.size:
            numerator = float(np.sum((y_true - y_pred) ** 2))
            denominator = float(np.sum((y_true - np.mean(y_true)) ** 2) + 1e-9)
            r2 = 1.0 - numerator / denominator
        else:
            r2 = float("nan")
        low = float(np.min(y_true)) if y_true.size else 0.0
        high = float(np.max(y_true)) if y_true.size else 1.0
        if math.isclose(low, high):
            high = low + 1.0
        distribution_true = np.histogram(y_true, bins=20, range=(low, high))[0]
        distribution_pred = np.histogram(y_pred, bins=20, range=(low, high))[0]
        bhatt = self._bhattacharyya_divergence(distribution_true.astype(float), distribution_pred.astype(float))
        metrics = {"mae": mae, "rmse": rmse, "r2": r2, "bhattacharyya": bhatt}
        return metrics


    def classification_metrics(
        self,
        y_true: np.ndarray,
        y_scores: np.ndarray,
        threshold: float = 0.5,
    ) -> Dict[str, float]:
        if y_true.size == 0:
            return {"accuracy": 0.0, "precision": 0.0, "recall": 0.0, "f1": 0.0, "auc": 0.5, "bhattacharyya": 0.0}
        probs = np.clip(y_scores, 0.0, 1.0)
        preds = (probs >= threshold).astype(int)
        accuracy = float(np.mean(preds == y_true)) if y_true.size else 0.0
        tp = float(np.sum((preds == 1) & (y_true == 1)))
        fp = float(np.sum((preds == 1) & (y_true == 0)))
        fn = float(np.sum((preds == 0) & (y_true == 1)))
        precision = tp / (tp + fp + 1e-9)
        recall = tp / (tp + fn + 1e-9)
        f1 = 2 * precision * recall / (precision + recall + 1e-9)
        if roc_auc_score is not None:
            auc = float(roc_auc_score(y_true, probs))
        else:
            auc = self._simple_auc(y_true.astype(float), probs.astype(float))
        distribution_true = np.array([np.mean(y_true == 0), np.mean(y_true == 1)], dtype=float)
        distribution_pred = np.array([np.mean(preds == 0), np.mean(preds == 1)], dtype=float)
        if distribution_true.sum() == 0:
            distribution_true = np.array([0.5, 0.5], dtype=float)
        if distribution_pred.sum() == 0:
            distribution_pred = np.array([0.5, 0.5], dtype=float)
        bhatt = self._bhattacharyya_divergence(distribution_true, distribution_pred)
        metrics = {
            "accuracy": accuracy,
            "precision": float(precision),
            "recall": float(recall),
            "f1": float(f1),
            "auc": float(auc),
            "bhattacharyya": float(bhatt),
        }
        if precision_recall_fscore_support is not None:
            precision_arr, recall_arr, f1_arr, _ = precision_recall_fscore_support(
                y_true,
                preds,
                average=None,
                zero_division=0,
            )
            metrics["precisionPerClass"] = precision_arr.tolist()
            metrics["recallPerClass"] = recall_arr.tolist()
            metrics["f1PerClass"] = f1_arr.tolist()
        return metrics


    def k_fold_cross_validation(
        self,
        model_factory: Callable[[], Any],
        X: np.ndarray,
        y: np.ndarray,
        folds: int = 5,
        task_type: str = "regression",
    ) -> Dict[str, Any]:
        if X.size == 0:
            return {"folds": [], "aggregate": {}}
        rng = np.random.default_rng(self.random_seed)
        indices = np.arange(len(y))
        rng.shuffle(indices)
        fold_indices = np.array_split(indices, max(1, folds))
        fold_results: List[Dict[str, float]] = []
        for fold_id, test_idx in enumerate(fold_indices):
            train_idx = np.setdiff1d(indices, test_idx)
            model = model_factory()
            X_train = X[train_idx]
            y_train = y[train_idx]
            X_test = X[test_idx]
            y_test = y[test_idx]
            if hasattr(model, "fit"):
                model.fit(X_train, y_train)
            elif isinstance(model, MLModelBase):  # pragma: no cover - unlikely branch
                mean = X_train.mean(axis=0) if X_train.size else np.zeros(X.shape[1])
                std = X_train.std(axis=0)
                std[std == 0] = 1.0
                norm_train = (X_train - mean) / std if X_train.size else X_train
                norm_test = (X_test - mean) / std if X_test.size else X_test
                split = DatasetSplit(
                    norm_train,
                    y_train,
                    norm_test,
                    y_test,
                    norm_test,
                    y_test,
                    {"mean": mean, "std": std},
                    {"records": int(len(y_train))},
                )
                model.train(split)
            else:
                continue
            if task_type == "classification":
                if hasattr(model, "predict_proba"):
                    scores = model.predict_proba(X_test)[:, -1]
                else:
                    scores = model.predict(X_test)
                metrics = self.classification_metrics(y_test, scores)
            else:
                preds = model.predict(X_test)
                metrics = self.regression_metrics(y_test, preds)
            metrics["fold"] = fold_id
            fold_results.append(metrics)
        aggregate: Dict[str, float] = {}
        if fold_results:
            keys = fold_results[0].keys()
            for key in keys:
                if key == "fold":
                    continue
                values = [entry[key] for entry in fold_results if isinstance(entry.get(key), (int, float))]
                if values:
                    aggregate[key] = float(np.mean(values))
        result = {"folds": fold_results, "aggregate": aggregate, "taskType": task_type}
        self.history.append({"type": "kfold", "result": result})
        return result


    def compare_model_variants(self, evaluations: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        summary: Dict[str, Any] = {"best": {}, "metrics": {}}
        metric_scores: Dict[str, List[Tuple[str, float]]] = defaultdict(list)
        for model_name, metrics in evaluations.items():
            for metric, value in metrics.items():
                if isinstance(value, (int, float)) and not math.isnan(value):
                    metric_scores[metric].append((model_name, float(value)))
        for metric, pairs in metric_scores.items():
            if not pairs:
                continue
            best_entry = max(pairs, key=lambda item: item[1])
            summary["best"][metric] = {"model": best_entry[0], "score": best_entry[1]}
            summary["metrics"][metric] = {name: score for name, score in pairs}
        self.history.append({"type": "comparison", "summary": summary})
        return summary


    def log_evaluation(self, tag: str, metrics: Dict[str, Any]) -> None:
        entry = {"tag": tag, "metrics": metrics, "timestamp": time.time()}
        self.history.append(entry)




class HyperparameterOptimizer:
    """Performs grid search and Bayesian-inspired random search for tuning."""


    def __init__(self, validation_engine: StatisticalValidationEngine, random_seed: int = DEFAULT_RANDOM_SEED) -> None:
        self.validation_engine = validation_engine
        self.random_seed = random_seed
        self.records: List[Dict[str, Any]] = []


    def grid_search(
        self,
        model_factory: Callable[[Dict[str, Any]], Any],
        param_grid: Dict[str, Sequence[Any]],
        split: DatasetSplit,
        task_type: str,
    ) -> Dict[str, Any]:
        best_score = -float("inf")
        best_params: Dict[str, Any] = {}
        best_metrics: Dict[str, Any] = {}
        param_iterator: Iterable[Dict[str, Any]]
        if ParameterGrid is not None:
            param_iterator = ParameterGrid(param_grid)
        else:
            keys = list(param_grid.keys())
            param_iterator = (
                {key: values[idx % len(values)] for idx, key in enumerate(keys)}
                for _ in range(max(1, len(keys)))
            )
        for params in param_iterator:
            model = model_factory(dict(params))
            if hasattr(model, "fit"):
                model.fit(split.train_X, split.train_y)
            elif isinstance(model, MLModelBase):
                model.train(split)
            else:
                continue
            if task_type == "classification":
                if hasattr(model, "predict_proba"):
                    scores = model.predict_proba(split.val_X)[:, -1] if split.val_X.size else model.predict_proba(split.train_X)[:, -1]
                else:
                    scores = model.predict(split.val_X if split.val_X.size else split.train_X)
                metrics = self.validation_engine.classification_metrics(split.val_y if split.val_y.size else split.train_y, scores)
                score = metrics.get("f1", -float("inf"))
            else:
                preds = model.predict(split.val_X) if split.val_X.size else model.predict(split.train_X)
                metrics = self.validation_engine.regression_metrics(split.val_y if split.val_y.size else split.train_y, preds)
                score = -metrics.get("rmse", float("inf"))
            self.records.append({"method": "grid", "params": dict(params), "metrics": metrics})
            if score > best_score:
                best_score = score
                best_params = dict(params)
                best_metrics = metrics
        return {"bestParams": best_params, "bestMetrics": best_metrics, "method": "grid"}


    def bayesian_search(
        self,
        model_factory: Callable[[Dict[str, Any]], Any],
        param_space: Dict[str, Tuple[float, float]],
        split: DatasetSplit,
        task_type: str,
        iterations: int = 15,
    ) -> Dict[str, Any]:
        rng = np.random.default_rng(self.random_seed)
        best_score = -float("inf")
        best_params: Dict[str, Any] = {}
        best_metrics: Dict[str, Any] = {}
        for _ in range(iterations):
            params = {key: float(rng.uniform(low, high)) for key, (low, high) in param_space.items()}
            model = model_factory(dict(params))
            if hasattr(model, "fit"):
                model.fit(split.train_X, split.train_y)
            elif isinstance(model, MLModelBase):
                model.train(split)
            else:
                continue
            if task_type == "classification":
                if hasattr(model, "predict_proba"):
                    scores = model.predict_proba(split.val_X)[:, -1] if split.val_X.size else model.predict_proba(split.train_X)[:, -1]
                else:
                    scores = model.predict(split.val_X if split.val_X.size else split.train_X)
                metrics = self.validation_engine.classification_metrics(split.val_y if split.val_y.size else split.train_y, scores)
                score = metrics.get("auc", -float("inf"))
            else:
                preds = model.predict(split.val_X) if split.val_X.size else model.predict(split.train_X)
                metrics = self.validation_engine.regression_metrics(split.val_y if split.val_y.size else split.train_y, preds)
                score = -metrics.get("rmse", float("inf"))
            record = {"method": "bayesian", "params": params, "metrics": metrics}
            self.records.append(record)
            if score > best_score:
                best_score = score
                best_params = dict(params)
                best_metrics = metrics
        return {"bestParams": best_params, "bestMetrics": best_metrics, "method": "bayesian"}




class TrainingVisualizationLogger:
    """Collects metrics and renders charts for quantum training telemetry."""


    def __init__(self, output_dir: Path | None = None) -> None:
        self.output_dir = output_dir or Path("outputs") / "visualizations"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.metric_history: Dict[str, List[Dict[str, Any]]] = defaultdict(list)


    def log_metrics(self, series: str, step: int, metrics: Dict[str, float]) -> Dict[str, Any]:
        entry = {"step": step, "metrics": metrics, "timestamp": time.time()}
        self.metric_history[series].append(entry)
        return entry


    def render(self) -> List[str]:
        generated: List[str] = []
        if MATPLOTLIB_AVAILABLE:
            matplotlib_module = importlib.import_module("matplotlib")
            matplotlib_module.use("Agg")
            plt = importlib.import_module("matplotlib.pyplot")
            for series, records in self.metric_history.items():
                if not records:
                    continue
                steps = [entry["step"] for entry in records]
                metrics = records[0]["metrics"].keys()
                fig, ax = plt.subplots(figsize=(8, 4))
                for metric in metrics:
                    values = [entry["metrics"].get(metric, float("nan")) for entry in records]
                    ax.plot(steps, values, label=metric)
                ax.set_title(f"{series} metrics")
                ax.set_xlabel("Step")
                ax.set_ylabel("Value")
                ax.legend()
                fig_path = self.output_dir / f"{series.replace(' ', '_')}.png"
                fig.tight_layout()
                fig.savefig(fig_path)
                plt.close(fig)
                generated.append(str(fig_path))
        elif PLOTLY_AVAILABLE:  # pragma: no cover - optional
            plotly_module = importlib.import_module("plotly.graph_objects")
            for series, records in self.metric_history.items():
                if not records:
                    continue
                steps = [entry["step"] for entry in records]
                fig = plotly_module.Figure()
                for metric in records[0]["metrics"].keys():
                    values = [entry["metrics"].get(metric, float("nan")) for entry in records]
                    fig.add_trace(plotly_module.Scatter(x=steps, y=values, mode="lines", name=metric))
                fig.update_layout(title=f"{series} metrics", xaxis_title="Step", yaxis_title="Value")
                fig_path = self.output_dir / f"{series.replace(' ', '_')}.html"
                fig.write_html(fig_path)
                generated.append(str(fig_path))
        return generated




class ExplainabilityEngine:
    """Generates feature attributions for lambda-aware models."""


    def __init__(self, random_seed: int = DEFAULT_RANDOM_SEED) -> None:
        self.random_seed = random_seed


    def explain(
        self,
        model: Any,
        features: np.ndarray,
        task_type: str,
        shell_size: int = 7,
    ) -> Dict[str, Any]:
        feature_array = np.atleast_2d(np.asarray(features, dtype=float))
        if feature_array.size == 0:
            return {"importance": [], "shellAttention": [], "method": "empty"}
        importance: np.ndarray
        method = "permutation"
        if SHAP_AVAILABLE:
            shap_module = importlib.import_module("shap")
            try:
                explainer = shap_module.Explainer(lambda x: model.predict(x))
                shap_values = explainer(feature_array)
                importance = np.mean(np.abs(shap_values.values), axis=0)
                method = "shap"
            except Exception:
                importance = np.zeros(feature_array.shape[1])
        elif hasattr(model, "feature_importances_"):
            importance = np.asarray(model.feature_importances_, dtype=float)
            method = "feature_importances"
        elif hasattr(model, "coef_"):
            importance = np.abs(np.asarray(model.coef_).reshape(-1))
            method = "coefficients"
        else:
            rng = np.random.default_rng(self.random_seed)
            baseline_pred = model.predict(feature_array)
            importance = np.zeros(feature_array.shape[1])
            for idx in range(feature_array.shape[1]):
                perturbed = feature_array.copy()
                rng.shuffle(perturbed[:, idx])
                perturbed_pred = model.predict(perturbed)
                diff = np.mean(np.abs(baseline_pred - perturbed_pred))
                importance[idx] = diff
        feature_dim = feature_array.shape[1]
        if importance.size < feature_dim:
            padded = np.zeros(feature_dim)
            padded[: importance.size] = importance
            importance = padded
        if importance.size:
            importance = importance / (np.sum(np.abs(importance)) + 1e-9)
        shell_attention: List[float] = []
        if importance.size:
            total_shells = max(1, feature_dim // shell_size)
            for shell_idx in range(total_shells):
                start = shell_idx * shell_size
                end = min(start + shell_size, importance.size)
                shell_attention.append(float(np.sum(importance[start:end])))
        explanation = {
            "importance": importance.tolist(),
            "shellAttention": shell_attention,
            "method": method,
            "taskType": task_type,
        }
        return explanation




class BaselineModelSuite:
    """Trains classical ML baselines for comparison with quantum agents."""


    def __init__(
        self,
        validation_engine: StatisticalValidationEngine,
        explainability: ExplainabilityEngine,
        random_seed: int = DEFAULT_RANDOM_SEED,
    ) -> None:
        self.validation_engine = validation_engine
        self.explainability = explainability
        self.random_seed = random_seed
        self.results: Dict[str, Any] = {}


    def _build_models(self, task_type: str) -> List[Tuple[str, Callable[[], Any]]]:
        models: List[Tuple[str, Callable[[], Any]]] = []
        if task_type == "classification":
            if RandomForestClassifier is not None:
                models.append(("random_forest_classifier", lambda: RandomForestClassifier(n_estimators=128, random_state=self.random_seed)))
            if LogisticRegression is not None:
                models.append(("logistic_regression", lambda: LogisticRegression(max_iter=200, solver="lbfgs")))
            if TORCH_AVAILABLE:
                models.append(("graph_surrogate_classifier", lambda: SimpleClassifier("baseline-graph")))
            else:
                models.append(("simple_classifier", lambda: SimpleClassifier("baseline-simple")))
        else:
            if RandomForestRegressor is not None:
                models.append(("random_forest_regressor", lambda: RandomForestRegressor(n_estimators=128, random_state=self.random_seed)))
            if MLPRegressor is not None:
                models.append(("mlp_regressor", lambda: MLPRegressor(hidden_layer_sizes=(128, 64), random_state=self.random_seed, max_iter=300)))
            models.append(("graph_surrogate_regressor", lambda: GraphSurrogateModel("baseline-graph")))
        return models


    def train_and_evaluate(self, dataset_manager: DatasetManager) -> Dict[str, Any]:
        for task, records in dataset_manager.records.items():
            split = dataset_manager.get_split(task) or dataset_manager.build_split(task)
            task_type = dataset_manager.get_task_type(task)
            models = self._build_models(task_type)
            evaluations: Dict[str, Dict[str, Any]] = {}
            explanations: Dict[str, Any] = {}
            for model_name, builder in models:
                model = builder()
                if hasattr(model, "fit"):
                    model.fit(split.train_X, split.train_y)
                elif isinstance(model, MLModelBase):
                    model.train(split)
                else:
                    continue
                if task_type == "classification":
                    if hasattr(model, "predict_proba"):
                        scores = model.predict_proba(split.test_X)[:, -1] if split.test_X.size else model.predict_proba(split.train_X)[:, -1]
                    else:
                        scores = model.predict(split.test_X if split.test_X.size else split.train_X)
                    metrics = self.validation_engine.classification_metrics(split.test_y if split.test_y.size else split.train_y, scores)
                else:
                    preds = model.predict(split.test_X) if split.test_X.size else model.predict(split.train_X)
                    metrics = self.validation_engine.regression_metrics(split.test_y if split.test_y.size else split.train_y, preds)
                evaluations[model_name] = metrics
                feature_sample = split.test_X if split.test_X.size else split.train_X
                explanation = self.explainability.explain(model, feature_sample if feature_sample.ndim > 1 else feature_sample.reshape(-1, feature_sample.shape[0]), task_type)
                explanations[model_name] = explanation
            comparison = self.validation_engine.compare_model_variants(evaluations)
            self.results[task] = {
                "evaluations": evaluations,
                "comparison": comparison,
                "explanations": explanations,
                "taskType": task_type,
            }
        return self.results


class MLModelBase:
    """Abstract base class for ML models in the simulation."""


    def __init__(self, name: str, task_type: str, architecture: str) -> None:
        self.name = name
        self.task_type = task_type
        self.architecture = architecture
        self.version = 1
        self.metrics: Dict[str, Any] = {}


    def train(self, split: DatasetSplit) -> Dict[str, Any]:  # pragma: no cover - overridden
        raise NotImplementedError


    def predict(self, features: np.ndarray) -> np.ndarray:  # pragma: no cover - overridden
        raise NotImplementedError


    def predict_with_uncertainty(self, features: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        preds = self.predict(features)
        return preds, np.full_like(preds, 0.1, dtype=float)


    def describe(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "taskType": self.task_type,
            "architecture": self.architecture,
            "version": self.version,
            "metrics": self.metrics,
        }




class SimpleRegressor(MLModelBase):
    def __init__(self, name: str, architecture: str = "BayesianLinear") -> None:
        super().__init__(name, "regression", architecture)
        self.weights: Optional[np.ndarray] = None
        self.noise_variance: float = 0.1


    def train(self, split: DatasetSplit) -> Dict[str, Any]:
        X = split.train_X
        y = split.train_y
        if X.size == 0:
            self.weights = None
            self.noise_variance = 0.5
            self.metrics = {"mae": float("nan"), "rmse": float("nan")}
            return self.metrics
        X_aug = np.concatenate([X, np.ones((len(X), 1))], axis=1)
        try:
            self.weights = np.linalg.lstsq(X_aug, y, rcond=None)[0]
        except np.linalg.LinAlgError:
            self.weights = np.zeros(X_aug.shape[1])
        train_pred = self._predict_internal(X)
        residuals = y - train_pred
        self.noise_variance = float(np.maximum(np.var(residuals), 1e-3))
        val_pred = self.predict(split.val_X) if split.val_X.size else np.array([])
        mae = float(np.mean(np.abs(split.val_y - val_pred))) if val_pred.size else float(np.mean(np.abs(residuals)))
        rmse = float(np.sqrt(np.mean((split.val_y - val_pred) ** 2))) if val_pred.size else float(np.sqrt(np.mean(residuals ** 2)))
        self.metrics = {"mae": mae, "rmse": rmse}
        return self.metrics


    def _predict_internal(self, X: np.ndarray) -> np.ndarray:
        if self.weights is None:
            return np.zeros(X.shape[0])
        X_aug = np.concatenate([X, np.ones((len(X), 1))], axis=1)
        return X_aug @ self.weights


    def predict(self, features: np.ndarray) -> np.ndarray:
        if features.size == 0:
            return np.zeros(0)
        return self._predict_internal(features)


    def predict_with_uncertainty(self, features: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        preds = self.predict(features)
        if features.size == 0:
            return preds, np.zeros(0)
        variances = np.full(preds.shape, self.noise_variance + 0.05)
        return preds, np.sqrt(variances)




class SimpleClassifier(MLModelBase):
    def __init__(self, name: str, architecture: str = "LogisticRegressionLite") -> None:
        super().__init__(name, "classification", architecture)
        self.weights: Optional[np.ndarray] = None


    def train(self, split: DatasetSplit) -> Dict[str, Any]:
        X = split.train_X
        y = split.train_y
        if X.size == 0:
            self.weights = None
            self.metrics = {"accuracy": float("nan")}
            return self.metrics
        X_aug = np.concatenate([X, np.ones((len(X), 1))], axis=1)
        weights = np.zeros(X_aug.shape[1])
        lr = 0.1
        for _ in range(200):
            logits = X_aug @ weights
            probs = 1.0 / (1.0 + np.exp(-logits))
            gradient = X_aug.T @ (probs - y) / len(y)
            weights -= lr * gradient
        self.weights = weights
        val_pred = self.predict(split.val_X) if split.val_X.size else np.array([])
        if val_pred.size:
            accuracy = float(np.mean((val_pred > 0.5) == split.val_y))
        else:
            train_pred = self.predict(split.train_X)
            accuracy = float(np.mean((train_pred > 0.5) == y))
        self.metrics = {"accuracy": accuracy}
        return self.metrics


    def predict(self, features: np.ndarray) -> np.ndarray:
        if self.weights is None or features.size == 0:
            return np.zeros(features.shape[0] if features.ndim else 1)
        X_aug = np.concatenate([features, np.ones((len(features), 1))], axis=1)
        logits = X_aug @ self.weights
        return 1.0 / (1.0 + np.exp(-logits))


    def predict_with_uncertainty(self, features: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        preds = self.predict(features)
        uncertainty = np.sqrt(preds * (1.0 - preds) + 1e-3)
        return preds, uncertainty




class GraphSurrogateModel(SimpleRegressor):
    """Message-passing inspired surrogate operating on aggregated graph features."""


    def __init__(self, name: str) -> None:
        super().__init__(name, architecture="MessagePassingSurrogate")




class MLModelRegistry:
    """Tracks model instances, metrics, and versioned training provenance."""


    def __init__(self) -> None:
        self.models: Dict[str, MLModelBase] = {}
        self.training_log: List[Dict[str, Any]] = []


    def register_model(self, task: str, model: MLModelBase, metrics: Dict[str, Any], dataset_meta: Dict[str, Any]) -> None:
        model.version = self.models.get(task, model).version + (1 if task in self.models else 0)
        self.models[task] = model
        self.training_log.append({
            "task": task,
            "version": model.version,
            "metrics": metrics,
            "dataset": dataset_meta,
        })


    def get_model(self, task: str) -> Optional[MLModelBase]:
        return self.models.get(task)


    def describe(self) -> Dict[str, Any]:
        return {
            "trainedModels": [model.describe() for model in self.models.values()],
            "trainingLog": list(self.training_log),
        }




class ActiveLearningCoordinator:
    """Implements active learning with uncertainty-driven sampling."""


    def __init__(self, threshold: float = 0.2) -> None:
        self.threshold = threshold
        self.pending_samples: List[Dict[str, Any]] = []
        self.completed_jobs: List[Dict[str, Any]] = []


    def evaluate_samples(
        self,
        task: str,
        features: Iterable[np.ndarray],
        predictions: Iterable[float],
        uncertainties: Iterable[float],
        metadata: Iterable[Dict[str, Any]],
    ) -> None:
        for feat, pred, unc, meta in zip(features, predictions, uncertainties, metadata):
            if float(unc) >= self.threshold:
                self.pending_samples.append({
                    "task": task,
                    "prediction": float(pred),
                    "uncertainty": float(unc),
                    "metadata": meta,
                    "featurePreview": np.asarray(feat, dtype=float)[:5].tolist(),
                })


    def schedule_retraining(self, task: str, registry: MLModelRegistry, dataset: DatasetManager) -> None:
        if not self.pending_samples:
            return
        job = {
            "task": task,
            "pending": len(self.pending_samples),
            "registrySize": len(registry.models),
            "datasetRecords": {key: len(val) for key, val in dataset.records.items()},
        }
        self.completed_jobs.append(job)
        self.pending_samples.clear()


    def describe(self) -> Dict[str, Any]:
        return {
            "threshold": self.threshold,
            "pending": list(self.pending_samples),
            "completed": list(self.completed_jobs),
        }




class MLInferenceAPI:
    """Lightweight registry for auditable ML inference endpoints."""


    def __init__(self) -> None:
        self.endpoints: Dict[str, Dict[str, Any]] = {}
        self.logs: deque = deque(maxlen=50)


    def register_endpoint(self, name: str, task: str, model_version: int) -> None:
        self.endpoints[name] = {
            "task": task,
            "modelVersion": model_version,
        }


    def log_call(self, endpoint: str, payload: Dict[str, Any], response: Dict[str, Any]) -> None:
        self.logs.appendleft({
            "endpoint": endpoint,
            "payload": payload,
            "response": response,
        })


    def describe(self) -> Dict[str, Any]:
        return {
            "endpoints": dict(self.endpoints),
            "recentCalls": list(self.logs),
        }




# ---------------------------------------------------------------------------
# Public data clients (with offline fallbacks)
# ---------------------------------------------------------------------------




class PublicDataClient:
    def __init__(self) -> None:
        pass


    def _http_get(self, url: str) -> Optional[bytes]:
        try:
            with urlrequest.urlopen(url, timeout=10) as response:  # nosec B310
                return response.read()
        except (urlerror.URLError, TimeoutError):
            return None


    def _http_post(self, url: str, payload: Dict[str, Any]) -> Optional[bytes]:
        try:
            data = json.dumps(payload).encode("utf-8")
            req = urlrequest.Request(url, data=data, headers={"Content-Type": "application/json"})
            with urlrequest.urlopen(req, timeout=10) as response:  # nosec B310
                return response.read()
        except (urlerror.URLError, TimeoutError):
            return None


    def fetch_pdb(self, pdb_id: str) -> str:
        url = f"https://files.rcsb.org/download/{pdb_id}.pdb"
        content = self._http_get(url)
        if content:
            try:
                return content.decode("utf-8")
            except UnicodeDecodeError:
                return content.decode("latin-1", errors="ignore")
        # Fallback: alpha helix snippet
        return textwrap.dedent(
            """
            ATOM      1  N   MET A   1      11.104  13.207   9.100  1.00 20.00           N
            ATOM      2  CA  MET A   1      12.560  13.320   9.300  1.00 20.00           C
            ATOM      3  C   MET A   1      13.080  14.740   8.900  1.00 20.00           C
            ATOM      4  O   MET A   1      12.540  15.780   9.300  1.00 20.00           O
            ATOM      5  CB  MET A   1      13.220  12.200  10.200  1.00 20.00           C
            ATOM      6  N   ALA A   2      14.180  14.860   8.100  1.00 20.00           N
            ATOM      7  CA  ALA A   2      14.820  16.170   7.700  1.00 20.00           C
            ATOM      8  C   ALA A   2      16.330  16.120   8.100  1.00 20.00           C
            ATOM      9  O   ALA A   2      17.090  15.170   7.800  1.00 20.00           O
            ATOM     10  CB  ALA A   2      14.600  16.430   6.200  1.00 20.00           C
            TER
            END
            """
        ).strip()


    def fetch_pubchem_candidates(self, query: str) -> List[Dict[str, Any]]:
        url = (
            "https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/"
            f"{query}/property/CanonicalSMILES,MolecularWeight,HBondDonorCount,HBondAcceptorCount/JSON"
        )
        content = self._http_get(url)
        if content:
            try:
                data = json.loads(content.decode("utf-8"))
                props = data.get("PropertyTable", {}).get("Properties", [])
                results = []
                for idx, prop in enumerate(props):
                    results.append(
                        {
                            "ligandId": f"pubchem-{query}-{idx}",
                            "smiles": prop.get("CanonicalSMILES", ""),
                            "molecularWeight": prop.get("MolecularWeight"),
                            "donors": prop.get("HBondDonorCount"),
                            "acceptors": prop.get("HBondAcceptorCount"),
                        }
                    )
                if results:
                    return results
            except json.JSONDecodeError:
                pass
        return [
            {
                "ligandId": "fallback-aspirin",
                "smiles": "CC(=O)OC1=CC=CC=C1C(=O)O",
                "molecularWeight": 180.16,
                "donors": 1,
                "acceptors": 4,
            }
        ]


    def fetch_uniprot_metadata(self, accession: str) -> Dict[str, Any]:
        url = f"https://rest.uniprot.org/uniprotkb/{accession}.json"
        content = self._http_get(url)
        if content:
            try:
                data = json.loads(content.decode("utf-8"))
                protein = data.get("proteinDescription", {}).get("recommendedName", {}).get("fullName", {}).get("value")
                organism = data.get("organism", {}).get("scientificName")
                return {"protein": protein, "organism": organism}
            except json.JSONDecodeError:
                pass
        return {"protein": "Cyclooxygenase-2", "organism": "Homo sapiens"}


    def fetch_patent_hits(self, query: str) -> List[Dict[str, Any]]:
        url = "https://api.patentsview.org/patents/query"
        payload = {
            "q": {"_text_any": {"patent_title": query}},
            "f": ["patent_number", "patent_title"],
            "o": {"per_page": 5},
        }
        content = self._http_post(url, payload)
        if content:
            try:
                data = json.loads(content.decode("utf-8"))
                patents = data.get("patents", [])
                return [
                    {
                        "patent": entry.get("patent_number"),
                        "title": entry.get("patent_title"),
                    }
                    for entry in patents
                ]
            except json.JSONDecodeError:
                pass
        return [
            {"patent": "US-12345-B2", "title": "Aspirin formulations with enhanced stability"},
            {"patent": "US-98765-C1", "title": "Novel COX-2 inhibitors"},
        ]




# ---------------------------------------------------------------------------
# Quantum analytics helpers
# ---------------------------------------------------------------------------




class LambdaScalingToolkit:
    """Utility collection for  -shell embeddings and diagnostics."""


    DEFAULT_SHELL_COUNT = 10


    @staticmethod
    def _bhattacharyya(p: float, q: float) -> float:
        p = float(np.clip(p, 1e-6, 1.0))
        q = float(np.clip(q, 1e-6, 1.0))
        return float(np.clip(math.sqrt(p * q), 0.0, 1.0))


    @classmethod
    def _as_descriptor(
        cls,
        index: int,
        radius: float,
        curvature: float,
        entropy: float,
        energy_density: float,
        occupancy: float,
        expected: float,
    ) -> LambdaShellDescriptor:
        overlap = cls._bhattacharyya(occupancy, expected)
        leakage = float(np.clip(abs(occupancy - expected), 0.0, 1.0))
        return LambdaShellDescriptor(
            shell_index=index,
            lambdaRadius=float(np.clip(radius, 1e-3, 1e3)),
            lambdaCurvature=float(np.clip(curvature, -200.0, 200.0)),
            lambdaEntropy=float(np.clip(entropy, 0.0, 10.0)),
            lambdaEnergyDensity=float(np.clip(energy_density, -500.0, 500.0)),
            lambdaBhattacharyya=overlap,
            lambdaOccupancy=float(np.clip(occupancy, 0.0, 2.0)),
            lambdaLeakage=leakage,
        )


    @classmethod
    def compute_base_descriptors(
        cls,
        curvature_profile: Iterable[float],
        lambda_modes: Iterable[float],
        entanglement_entropy: float,
        radii: Iterable[float],
        shells: Iterable[int],
        energy_stats: Dict[str, Any],
    ) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        curvature_list = list(curvature_profile) or [0.0]
        mode_list = list(lambda_modes) or [1.0]
        radii_array = np.asarray(list(radii) or [1.0], dtype=float)
        shells_array = np.asarray(list(shells) or [0], dtype=int)
        unique_shells = sorted(set(int(val) for val in shells_array.tolist()))
        if not unique_shells:
            unique_shells = list(range(cls.DEFAULT_SHELL_COUNT))
        shell_count = max(1, min(len(unique_shells), cls.DEFAULT_SHELL_COUNT))
        shell_indices = np.arange(shell_count, dtype=float)
        shell_positions = shell_indices / max(float(shell_count - 1), 1.0)
        radial_prior = np.exp(-shell_positions)
        curvature_array = np.abs(np.asarray(curvature_list[:shell_count] or [1.0], dtype=float))
        curvature_norm = np.max(curvature_array) or 1.0
        curvature_prior = 1.0 + (curvature_array / curvature_norm)
        shaped_prior_raw = radial_prior * curvature_prior
        denom = max(float(np.sum(shaped_prior_raw)), 1e-6)
        shaped_prior = shaped_prior_raw / denom
        base_radius = float(np.max(np.abs(radii_array)) or 1.0)
        descriptors: List[LambdaShellDescriptor] = []
        total_points = max(int(len(radii_array)), 1)
        entropy_base = max(float(entanglement_entropy), ENTROPY_FLOOR)
        for idx in range(shell_count):
            shell_id = unique_shells[idx]
            mask = shells_array == shell_id
            raw_occupancy = float(np.count_nonzero(mask) / total_points)
            occupancy = float(
                np.clip(
                    (1.0 - OCCUPANCY_PRIOR_WEIGHT) * raw_occupancy
                    + OCCUPANCY_PRIOR_WEIGHT * shaped_prior[idx],
                    0.0,
                    1.0,
                )
            )
            radius = base_radius / math.pow(LAMBDA_DILATION, idx)
            curvature = float(curvature_list[idx % len(curvature_list)])
            entropy_deviation = occupancy - shaped_prior[idx]
            entropy_shape = max(0.25, 1.0 + ENTROPY_SHAPE_STRENGTH * entropy_deviation)
            entropy = float(
                np.clip(
                    entropy_base * entropy_shape * (1.0 + 0.03 * idx),
                    ENTROPY_FLOOR,
                    ENTROPY_CEILING,
                )
            )
            energy_mode = mode_list[idx % len(mode_list)]
            energy_density = float(energy_mode / max(radius, 1e-3))
            descriptors.append(
                cls._as_descriptor(
                    idx,
                    radius,
                    curvature,
                    entropy,
                    energy_density,
                    occupancy,
                    float(shaped_prior[idx]),
                )
            )
        attractor_score = float(np.mean([d.lambdaBhattacharyya for d in descriptors])) if descriptors else 0.0
        entropy_gradient = (
            float(descriptors[-1].lambdaEntropy - descriptors[0].lambdaEntropy)
            if len(descriptors) > 1
            else 0.0
        )
        bhattacharyya_flux = float(np.std([d.lambdaBhattacharyya for d in descriptors])) if descriptors else 0.0
        basis = {
            "dilationFactor": LAMBDA_DILATION,
            "shellCount": len(descriptors),
            "lambdaAttractorScore": float(np.clip(attractor_score, 0.0, 1.0)),
            "lambdaEntropyGradient": float(np.clip(entropy_gradient, -5.0, 5.0)),
            "lambdaBhattacharyyaFlux": float(np.clip(bhattacharyya_flux, 0.0, 1.0)),
            "referenceEnergyMean": energy_stats.get("meanEnergy"),
        }
        return [descriptor.to_dict() for descriptor in descriptors], basis


    @staticmethod
    def fingerprint(descriptors: Iterable[Dict[str, Any]]) -> List[float]:
        vector: List[float] = []
        for entry in descriptors:
            vector.extend(
                [
                    float(entry.get("lambdaRadius", 0.0)),
                    float(entry.get("lambdaCurvature", 0.0)),
                    float(entry.get("lambdaEntropy", 0.0)),
                    float(entry.get("lambdaEnergyDensity", 0.0)),
                    float(entry.get("lambdaBhattacharyya", 0.0)),
                    float(entry.get("lambdaOccupancy", 0.0)),
                    float(entry.get("lambdaLeakage", 0.0)),
                ]
            )
        if not vector:
            vector = [0.0] * 7
        return vector


    @classmethod
    def analyze_coordinates(cls, coords: np.ndarray, context: QuantumContext) -> Dict[str, Any]:
        base_descriptors = context.lambda_shells or []
        if not len(base_descriptors):
            return {"descriptors": [], "fingerprint": [0.0] * 7, "summary": {}}
        center = np.mean(coords, axis=0)
        distances = np.linalg.norm(coords - center, axis=1)
        max_radius = float(np.max(distances) or 1.0)
        thresholds = [max_radius / math.pow(LAMBDA_DILATION, idx) for idx, _ in enumerate(base_descriptors)]
        descriptors: List[Dict[str, Any]] = []
        for idx, base in enumerate(base_descriptors):
            upper = thresholds[idx]
            lower = thresholds[idx + 1] if idx + 1 < len(thresholds) else 0.0
            mask = (distances <= upper) & (distances >= lower)
            occupancy = float(np.mean(mask)) if distances.size else 0.0
            expected = base.get("lambdaOccupancy", 1.0 / len(base_descriptors))
            curvature = base.get("lambdaCurvature", 0.0) * (1.0 + 0.05 * occupancy)
            entropy = base.get("lambdaEntropy", context.entanglement_entropy) * (1.0 + 0.02 * idx)
            energy_density = base.get("lambdaEnergyDensity", 0.0) * (1.0 + 0.03 * (occupancy - expected))
            descriptor = cls._as_descriptor(
                idx,
                radius=upper or max_radius,
                curvature=curvature,
                entropy=entropy,
                energy_density=energy_density,
                occupancy=occupancy,
                expected=expected,
            ).to_dict()
            descriptor["lambdaBhattacharyya"] = cls._bhattacharyya(occupancy, expected)
            descriptor["lambdaLeakage"] = float(np.clip(abs(occupancy - expected), 0.0, 1.0))
            descriptors.append(descriptor)
        fingerprint = cls.fingerprint(descriptors)
        summary = {
            "lambdaShellFingerprint": fingerprint,
            "lambdaBhattacharyyaFlux": float(np.std([d["lambdaBhattacharyya"] for d in descriptors]) if descriptors else 0.0),
            "lambdaEntropyGradient": float(
                (descriptors[-1]["lambdaEntropy"] - descriptors[0]["lambdaEntropy"]) if len(descriptors) > 1 else 0.0
            ),
            "scalingBasis": "lambda",
        }
        return {"descriptors": descriptors, "fingerprint": fingerprint, "summary": summary}


    @classmethod
    def analyze_ligand(
        cls,
        smiles: str,
        context: QuantumContext,
        quantum_reference: Dict[str, Any],
    ) -> Dict[str, Any]:
        base_descriptors = context.lambda_shells or []
        if not base_descriptors:
            return {"descriptors": [], "fingerprint": [0.0] * 7, "summary": {}}
        atom_counts = {atom: smiles.count(atom) for atom in ["C", "N", "O", "S", "P", "F", "Cl"]}
        total_atoms = float(sum(atom_counts.values()) or 1.0)
        descriptors: List[Dict[str, Any]] = []
        for idx, base in enumerate(base_descriptors):
            atom = ["C", "N", "O", "S", "P", "F", "Cl"][idx % 7]
            bias = atom_counts.get(atom, 0.0) / total_atoms
            expected = base.get("lambdaOccupancy", 1.0 / len(base_descriptors))
            occupancy = float(np.clip(expected * (1.0 + 0.5 * bias), 0.0, 2.0))
            entropy = base.get("lambdaEntropy", context.entanglement_entropy) * (1.0 + 0.1 * bias)
            energy_density = base.get("lambdaEnergyDensity", 0.0) * (1.0 + 0.05 * bias)
            descriptor = cls._as_descriptor(
                idx,
                radius=base.get("lambdaRadius", 1.0),
                curvature=base.get("lambdaCurvature", 0.0) * (1.0 + 0.05 * (bias - 0.2)),
                entropy=entropy,
                energy_density=energy_density,
                occupancy=occupancy,
                expected=expected,
            ).to_dict()
            descriptors.append(descriptor)
        fingerprint = cls.fingerprint(descriptors)
        mean_energy = quantum_reference.get("statistics", {}).get("meanEnergy", -8.0)
        summary = {
            "lambdaShellFingerprint": fingerprint,
            "lambdaMeanEnergyAlignment": float(
                np.clip(1.0 - abs(mean_energy) / (abs(mean_energy) + 10.0), 0.0, 1.0)
            ),
            "lambdaOccupancyMean": float(np.mean([d["lambdaOccupancy"] for d in descriptors]) if descriptors else 0.0),
            "scalingBasis": "lambda",
        }
        return {"descriptors": descriptors, "fingerprint": fingerprint, "summary": summary}




class QuantumMemoryAPI:
    """Compresses and restores lambda/phi scaled memory vectors."""


    def __init__(self) -> None:
        self.alpha = DUAL_SCALING_ALPHA
        self.storage: List[Dict[str, Any]] = []


    @staticmethod
    def _convert_basis(vector: np.ndarray, source: str, target: str, alpha: float) -> np.ndarray:
        if source == target:
            return vector
        safe = np.sign(vector) * np.power(np.abs(vector) + 1e-9, alpha if source == "lambda" else 1.0 / alpha)
        return safe


    @staticmethod
    def _geometric_params(vector: np.ndarray) -> Optional[Dict[str, Any]]:
        if vector.size < 3:
            return None
        non_zero = np.where(np.abs(vector) > 1e-8)[0]
        if non_zero.size < 2:
            return None
        ratios = []
        for idx in range(len(vector) - 1):
            if abs(vector[idx]) < 1e-8:
                continue
            ratios.append(vector[idx + 1] / vector[idx])
        if not ratios:
            return None
        ratio_mean = float(np.mean(ratios))
        if abs(ratio_mean - LAMBDA_DILATION) < 0.05:
            basis = "lambda"
        elif abs(ratio_mean - PHI_CONSTANT) < 0.05:
            basis = "phi"
        else:
            return None
        return {
            "basis": basis,
            "seed": float(vector[0]),
            "ratio": ratio_mean,
            "length": int(vector.size),
        }


    def serialize_memory(
        self,
        state_vector: Iterable[float],
        metadata: Optional[Dict[str, Any]] = None,
        canonical_basis: str = "phi",
    ) -> Dict[str, Any]:
        metadata = copy.deepcopy(metadata) if metadata else {}
        basis = metadata.get("scaling_basis", "lambda")
        array = np.asarray(list(state_vector), dtype=float)
        compression = self._geometric_params(array)
        entry: Dict[str, Any] = {
            "metadata": metadata,
            "basis": basis,
            "canonical_basis": canonical_basis,
        }
        if compression:
            entry["compressed"] = compression
            entry["metadata"]["compression"] = "geometric"
        else:
            entry["raw"] = array.tolist()
            entry["metadata"]["compression"] = "raw"
        entry["metadata"]["scaling_basis"] = basis
        entry["metadata"]["canonical_basis"] = canonical_basis
        self.storage.append(entry)
        return entry


    def deserialize_memory(self, entry: Dict[str, Any]) -> np.ndarray:
        basis = entry.get("basis", "lambda")
        canonical = entry.get("canonical_basis", "phi")
        if "compressed" in entry:
            comp = entry["compressed"]
            values = [comp["seed"] * (comp["ratio"] ** idx) for idx in range(comp.get("length", 0))]
            vector = np.asarray(values, dtype=float)
        else:
            vector = np.asarray(entry.get("raw", []), dtype=float)
        converted = self._convert_basis(vector, basis, canonical, self.alpha)
        return converted




class QuantumPhysicsEngine:
    def __init__(self, geometry: GeometryParams, field: FieldParams, ent_params: EntanglementParams):
        self.geometry = geometry
        self.field = field
        self.ent_params = ent_params


    def compute_quantum_context(self) -> QuantumContext:
        z, r, rho, curvature = integrate_profile(self.geometry)
        operator, _ = build_kg_operator(z, r, curvature, self.field)
        eigenvalues, _ = compute_modes(operator, k=min(5, len(z) - 2))
        curvature_profile = curvature.tolist()
        lambda_modes = [float(val) for val in eigenvalues]


        positions, radii, shells = build_geometry(self.ent_params)
        adjacency = build_adjacency(positions, radii, shells, self.ent_params)
        hamiltonian = build_hamiltonian(adjacency, radii, self.ent_params)
        # compute ground state entropy across first three shells
        evals, evecs = np.linalg.eigh(hamiltonian.toarray())
        ground_state = evecs[:, np.argmin(evals)]
        mask = shells < 3
        entropy = single_particle_entropy_for_cut(ground_state, mask)


        enhancement = float(np.clip(np.mean(curvature) * 1e-2 + statistics.mean(lambda_modes), 0.5, 5.0))
        lambda_shells, lambda_basis = LambdaScalingToolkit.compute_base_descriptors(
            curvature_profile,
            lambda_modes,
            float(entropy),
            radii,
            shells,
            {"meanEnergy": float(np.mean(lambda_modes)) if lambda_modes else None},
        )
        return QuantumContext(
            curvature_profile=curvature_profile,
            lambda_modes=lambda_modes,
            entanglement_entropy=float(entropy),
            enhancement_factor=enhancement,
            lambda_shells=lambda_shells,
            lambda_basis=lambda_basis,
        )




class QuantumCircuitEngine:
    """Generates quantum-consistent exemplars via lightweight circuit sampling."""


    def __init__(self, context: QuantumContext, seed: int = 314159) -> None:
        self.context = context
        self.rng = np.random.default_rng(seed)


    def _simulate_circuit(self, ligand_id: str) -> Dict[str, Any]:
        base_energy = -12.0 - 0.3 * self.context.enhancement_factor
        noise = self.rng.normal(0, 0.6)
        binding_energy = float(np.clip(base_energy + noise, -60.0, -0.5))
        entropy = float(
            np.clip(
                self.context.entanglement_entropy + self.rng.normal(0, 0.05),
                0.01,
                1.5 * max(0.1, self.context.entanglement_entropy),
            )
        )
        occupation = self.rng.dirichlet(np.ones(4))
        transition_probs = occupation.tolist()
        fidelity = float(np.clip(0.98 + self.rng.normal(0, 0.005), 0.85, 0.999))
        shell_fp = LambdaScalingToolkit.fingerprint(self.context.lambda_shells)
        return {
            "ligandId": ligand_id,
            "bindingEnergy": binding_energy,
            "entanglementEntropy": entropy,
            "orbitalOccupations": transition_probs,
            "fidelity": fidelity,
            "lambdaShellFingerprint": shell_fp,
        }


    def generate_reference_dataset(self, ligand_ids: List[str]) -> Dict[str, Any]:
        samples = [self._simulate_circuit(ligand_id) for ligand_id in ligand_ids]
        energies = [entry["bindingEnergy"] for entry in samples]
        entropies = [entry["entanglementEntropy"] for entry in samples]
        stats = {
            "energyRange": {"min": float(min(energies)), "max": float(max(energies))},
            "entropyRange": {"min": float(min(entropies)), "max": float(max(entropies))},
            "meanEnergy": float(np.mean(energies)),
            "meanEntropy": float(np.mean(entropies)),
        }
        self.context.lambda_basis.update(
            {
                "referenceEnergyMean": stats["meanEnergy"],
                "lambdaEntropyGradient": float(stats["meanEntropy"] - self.context.entanglement_entropy),
            }
        )
        return {"samples": samples, "statistics": stats}




class PhysicalValidator:
    """Applies physical constraints, uncertainty propagation, and rationale tracing."""


    def __init__(self, context: QuantumContext, reference_stats: Dict[str, Any]):
        self.context = context
        self.reference_stats = reference_stats
        self.rng = np.random.default_rng(2718)
        self.numeric_constraints = {
            "druggabilityScore": (0.0, 1.0),
            "hydrophobicity": (0.0, 1.0),
            "electrostaticPotential": (-20.0, 0.0),
            "bindingAffinityScore": (-60.0, -0.5),
            "bindingFreeEnergy": (-80.0, -0.5),
            "shapeComplementarity": (0.0, 1.0),
            "toxicityRiskScore": (0.0, 1.0),
            "bioavailability": (0.0, 1.0),
            "halfLife": (0.1, 240.0),
            "syntheticAccessibility": (1.0, 10.0),
            "noveltyScore": (0.0, 1.0),
            "confidence": (0.0, 1.0),
            "quantumCircuitFidelity": (0.0, 1.0),
            "lambdaEnhancement": (0.0, 10.0),
            "bindingEnergyRef": (-80.0, -0.5),
            "bindingEnergy": (-80.0, -0.5),
            "entanglementEntropyRef": (0.0, 5.0),
            "entanglementEntropy": (0.0, 5.0),
            "matchingScore": (0.0, 1.0),
            "meanEntanglementEntropy": (0.0, 5.0),
            "entropyStdDev": (0.0, 5.0),
            "canonicalBeta": (0.0, 200.0),
            "partitionFunction": (0.0, 1e4),
            "lambdaRadius": (0.0, 1e3),
            "lambdaCurvature": (-500.0, 500.0),
            "lambdaEntropy": (0.0, 10.0),
            "lambdaEnergyDensity": (-500.0, 500.0),
            "lambdaBhattacharyya": (0.0, 1.0),
            "lambdaOccupancy": (0.0, 2.0),
            "lambdaLeakage": (0.0, 1.0),
            "lambdaAttractorScore": (0.0, 1.0),
            "lambdaEntropyGradient": (-5.0, 5.0),
            "lambdaBhattacharyyaFlux": (0.0, 1.0),
        }


    def _estimate_sigma(self, key: str, value: float) -> float:
        baseline = 0.05 * max(1.0, abs(value))
        ent_scale = 0.02 * max(1.0, self.context.entanglement_entropy)
        ref = self.reference_stats.get("statistics", {})
        if "meanEnergy" in ref and key in {"bindingAffinityScore", "bindingFreeEnergy"}:
            baseline += 0.1 * abs(value - ref["meanEnergy"])
        return float(np.clip(baseline + ent_scale, 0.01, 5.0))


    def _credible_interval(self, mean: float, sigma: float) -> Tuple[float, float]:
        samples = self.rng.normal(mean, sigma, size=2000)
        lower, upper = np.percentile(samples, [5, 95])
        return float(lower), float(upper)


    def _coerce_value(self, key: str, value: float) -> Tuple[float, bool]:
        constraint = self.numeric_constraints.get(key)
        adjusted = False
        if constraint:
            min_val, max_val = constraint
            if value < min_val:
                value = min_val
                adjusted = True
            if value > max_val:
                value = max_val
                adjusted = True
        if key in {"bindingAffinityScore", "bindingFreeEnergy"}:
            ref = self.reference_stats.get("statistics", {})
            energy_range = ref.get("energyRange")
            if energy_range:
                if value < energy_range["min"]:
                    value = float(energy_range["min"])
                    adjusted = True
                if value > energy_range["max"]:
                    value = float(energy_range["max"])
                    adjusted = True
        return float(value), adjusted


    def validate(self, agent: str, payload: Dict[str, Any]) -> Dict[str, Any]:
        metadata: Dict[str, Any] = {"agent": agent, "adjustments": []}
        adjustment_deltas: List[float] = []


        root_holder: Dict[str, Any] = {"root": copy.deepcopy(payload)}


        def _locate(container: Any, key: str) -> Any:
            if key.startswith("["):
                index = int(key.strip("[]"))
                return container[index]
            return container[key]


        def _process(obj: Any, path: Tuple[str, ...]) -> Any:
            if isinstance(obj, dict):
                for key, value in list(obj.items()):
                    new_path = path + (key,)
                    obj[key] = _process(value, new_path)
                return obj
            if isinstance(obj, list):
                for idx, item in enumerate(obj):
                    obj[idx] = _process(item, path + (f"[{idx}]",))
                return obj
            if isinstance(obj, (int, float)):
                original_value = float(obj)
                corrected, adjusted = self._coerce_value(path[-1] if path else "", original_value)
                sigma = self._estimate_sigma(path[-1] if path else "", corrected)
                lower, upper = self._credible_interval(corrected, sigma)
                container: Any = root_holder["root"]
                for key in path[:-1]:
                    container = _locate(container, key)
                if isinstance(container, dict) and path:
                    container[f"{path[-1]}Uncertainty"] = {
                        "stdDev": sigma,
                        "credibleInterval": [lower, upper],
                    }
                if adjusted:
                    delta = abs(corrected - original_value)
                    adjustment_deltas.append(delta)
                    metadata["adjustments"].append(
                        {"path": ".".join(path), "reason": "Constraint enforcement", "delta": delta}
                    )
                return corrected
            return obj


        root_holder["root"] = _process(root_holder["root"], tuple())
        validated_payload = root_holder["root"]
        validated_payload.setdefault("validation", {}).update({
            "agent": agent,
            "adjustmentCount": len(metadata["adjustments"]),
            "referenceEnergyRange": self.reference_stats.get("statistics", {}).get("energyRange"),
        })
        if metadata["adjustments"]:
            validated_payload["validation"]["adjustments"] = metadata["adjustments"]
        validator_diag = {
            "adjustmentCount": len(metadata["adjustments"]),
            "meanClampDistance": float(np.mean(adjustment_deltas)) if adjustment_deltas else 0.0,
        }
        validated_payload.setdefault("validatorDiagnostics", {}).update(validator_diag)
        return validated_payload






# ---------------------------------------------------------------------------
# Golden Turing AI integration adapter
# ---------------------------------------------------------------------------




class GoldenTuringDDSAdapter:
    """Map Golden Turing AI recursive features onto the DDS pipeline."""


    def __init__(
        self,
        core_ai: Any,
        blackboard: QuantumBlackboard,
        validator: PhysicalValidator,
        quantum_reference: Dict[str, Any],
        memory_api: Optional[QuantumMemoryAPI] = None,
    ) -> None:
        self.core_ai = core_ai
        self.blackboard = blackboard
        self.validator = validator
        self.quantum_reference = quantum_reference
        self.memory_api = memory_api or QuantumMemoryAPI()
        self.state_potential = 0.62
        self.self_awareness = 0.72
        self.state_resonance = 0.28
        self.potential_awareness_boost_factor = 0.25
        self.entanglement_param_boost_factor = 1.5
        self.tunneling_state_shift_factor = 0.3
        self.memory_fidelity_noise_factor = 0.005
        self.simulation_param_variation_scale = 0.1
        self.simulation_multiverse_params = 3
        self.annealing_stability_threshold = 0.01
        self.annealing_lr_factor_stable = 0.9
        self.annealing_lr_factor_unstable = 1.1
        self.annealing_mutation_scale_factor_stable = 0.5
        self.annealing_mutation_scale_factor_unstable = 1.2
        self.interference_blend_factor_base = 0.05
        self.zeno_effect_trigger_count = 5
        self.zeno_effect_time_window = 60.0
        self.zeno_effect_dampening_factor = 0.1
        self.awareness_history: deque = deque([self.self_awareness], maxlen=200)
        self.awareness_changes: List[float] = []
        self.agent_roles: Dict[str, str] = {}
        self.action_log: List[Dict[str, Any]] = []
        self.pending_blackboard_posts: List[Dict[str, Any]] = []
        self.entanglement_records: List[Dict[str, Any]] = []
        self.annealing_records: List[Dict[str, Any]] = []
        self.tunneling_records: List[Dict[str, Any]] = []
        self.blend_records: List[Dict[str, Any]] = []
        self.simulation_reflections: List[Dict[str, Any]] = []
        self.meta_tuning_records: List[Dict[str, Any]] = []
        self.memory_noise_records: List[Dict[str, Any]] = []
        self.memory_cache: Dict[str, List[Dict[str, Any]]] = {"self": [], "adversary": []}
        self.agent_map: Dict[str, AgentBase] = {}
        self.binding_history: deque = deque(maxlen=60)
        self.pains_alert_counter = 0
        self.stagnation_counter = 0
        self.current_target_focus = "pocket-01"
        self.analysis_action_window: deque = deque()
        self.zeno_dampening_active = False


    def register_agent(self, agent: Any) -> None:
        self.agent_roles[agent.name] = getattr(agent.__class__, "__name__", agent.name)
        self.agent_map[agent.name] = agent


    def before_agent_run(self, agent_name: str) -> None:
        self._register_action_event("ACTION_ANALYZE_STATE", agent_name)


    def after_agent_report(
        self,
        agent_name: str,
        report: Dict[str, Any],
    ) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        integration_meta: Dict[str, Any] = {}
        awareness_delta = self._estimate_awareness_change(agent_name, report)
        if agent_name in {"LigandDiscoveryAgent", "QuantumSimulationAgent"}:
            self._record_binding_score(agent_name, report)
        if agent_name == "SafetyAgent":
            self._track_pains_alerts(report)
        superposition_meta = self._apply_superposition(agent_name, report)
        if superposition_meta:
            integration_meta["superposition"] = superposition_meta
        ent_meta = self._apply_entanglement_feedback(agent_name, awareness_delta)
        if ent_meta:
            integration_meta["entanglement"] = ent_meta
        awareness_change = self._update_awareness(awareness_delta)
        integration_meta["awarenessDelta"] = awareness_change
        annealing_meta = self._apply_adaptive_annealing()
        if annealing_meta:
            integration_meta["annealing"] = annealing_meta
        tunneling_meta = self._check_tunneling_conditions()
        if tunneling_meta:
            integration_meta["quantumTunneling"] = tunneling_meta
        if agent_name == "QuantumSimulationAgent":
            blend_meta = self._perform_state_blend()
            if blend_meta:
                integration_meta["interferenceBlend"] = blend_meta
        memory_meta = self._apply_memory_fidelity_noise(agent_name, report)
        if memory_meta:
            integration_meta["memoryFidelity"] = memory_meta
        self._register_memory_snapshot(agent_name, report)
        integration_meta.setdefault("lambdaScaling", {})
        integration_meta["lambdaScaling"].update(
            {
                "basis": self.validator.context.lambda_basis,
                "shellFingerprint": LambdaScalingToolkit.fingerprint(
                    self.validator.context.lambda_shells
                )[:7],
            }
        )
        return report, integration_meta


    def run_recursive_simulation(self) -> Dict[str, Any]:
        variations: List[Dict[str, Any]] = []
        base_reward = float(np.mean(self.binding_history)) if self.binding_history else -8.0
        for idx in range(self.simulation_multiverse_params):
            perturb = (idx - 1) * self.simulation_param_variation_scale
            success_rate = float(
                np.clip(
                    0.55
                    + 0.1 * random.random()
                    + 0.05 * (-base_reward / 10.0)
                    + perturb,
                    0.0,
                    1.0,
                )
            )
            variations.append(
                {
                    "paramSetId": f"mv-{idx}",
                    "ligandWeight": float(np.clip(0.6 + perturb, 0.1, 0.95)),
                    "toxicityWeight": float(np.clip(0.3 - perturb, 0.05, 0.9)),
                    "simulatedSuccessRate": success_rate,
                }
            )
        best = max(variations, key=lambda entry: entry["simulatedSuccessRate"])
        prompt = {
            "action": "RUN_SIMULATION",
            "payload": {
                "target_protein": self.current_target_focus,
                "iterations": 50,
                "levels": 5,
                "multiverse_count": self.simulation_multiverse_params,
                "strategy_focus": ["ligand_generation", "quantum_docking"],
                "param_variation_scale": self.simulation_param_variation_scale,
            },
        }
        self._queue_action("ACTION_RUN_SIMULATION", prompt)
        reflection = {
            "prompt": prompt,
            "variations": variations,
            "bestParamSetId": best["paramSetId"],
            "averageSuccessRate": float(
                np.mean([entry["simulatedSuccessRate"] for entry in variations])
            ),
            "awarenessBonus": 0.3,
        }
        self.simulation_reflections.append(reflection)
        self._update_awareness(0.03)
        return reflection


    def tune_analysis_parameters(self, avg_reward: float) -> Dict[str, Any]:
        tuning_payload = {
            "action": "TUNE_DDS_METRICS",
            "payload": {
                "tuning_target": "agent_thresholds",
                "recent_avg_reward": avg_reward,
                "tuning_rate": 0.12,
                "noise_factor": 0.02,
            },
        }
        self._queue_action("ACTION_TUNE_ANALYSIS", tuning_payload)
        meta = {
            "analysisWeights": {
                "prediction_error_impact": float(np.clip(1.0 + avg_reward, 0.5, 1.5)),
                "timing_penalty_factor": float(np.clip(0.8 - avg_reward * 0.1, 0.2, 1.2)),
            },
            "ruleThresholds": {
                "simulation_trigger_awareness": float(np.clip(self.self_awareness - 0.05, 0.1, 0.9)),
            },
            "prompt": tuning_payload,
        }
        self.meta_tuning_records.append(meta)
        return meta


    def analyze_memory(self) -> Dict[str, Any]:
        low_awareness_flag = self.self_awareness < 0.5
        payload = {
            "action": "ANALYZE_MEMORY_FIDELITY",
            "payload": {
                "memory_set": "Adversary" if self.memory_cache["adversary"] else "Self",
                "fidelity_noise_level": self.memory_fidelity_noise_factor,
                "low_awareness_flag": low_awareness_flag,
            },
        }
        self._queue_action("ACTION_ANALYZE_MEMORY", payload)
        reconstructed: List[float] = []
        if self.memory_cache["self"]:
            latest = self.memory_cache["self"][-1].get("lambdaMemory")
            if latest:
                reconstructed = self.memory_api.deserialize_memory(latest).tolist()
        meta = {
            "memorySummaries": {
                "self": len(self.memory_cache["self"]),
                "adversary": len(self.memory_cache["adversary"]),
            },
            "prompt": payload,
            "reconstructedCanonical": reconstructed[:10],
        }
        self.memory_noise_records.append(meta)
        return meta


    def mutate_params(self, mode: str) -> None:
        payload = {
            "action": "MUTATE_DDS_HEURISTICS",
            "payload": {
                "target_group": [
                    "analysis_weights",
                    "rule_thresholds",
                    "ligand_design_rates",
                ],
                "scale": (
                    self.annealing_mutation_scale_factor_unstable
                    if mode == "explore"
                    else self.annealing_mutation_scale_factor_stable
                ),
            },
        }
        self._queue_action("ACTION_MUTATE_PARAMS", payload)


    def _register_action_event(self, action: str, agent_name: str) -> None:
        now = time.time()
        self.analysis_action_window.append((now, action, agent_name))
        while self.analysis_action_window and (
            now - self.analysis_action_window[0][0]
        ) > self.zeno_effect_time_window:
            self.analysis_action_window.popleft()
        count = sum(1 for _, act, _ in self.analysis_action_window if act == action)
        self.zeno_dampening_active = count >= self.zeno_effect_trigger_count
        self.action_log.append({"action": action, "agent": agent_name, "timestamp": now})


    def _queue_action(self, action_type: str, payload: Dict[str, Any]) -> None:
        entry = {"action": action_type, "timestamp": time.time(), "payload": payload}
        self.action_log.append(entry)
        self.pending_blackboard_posts.append(entry)


    def _estimate_awareness_change(self, agent_name: str, report: Dict[str, Any]) -> float:
        if agent_name == "LigandDiscoveryAgent":
            affinity = None
            if isinstance(report, dict):
                affinity = report.get("affinity", {}).get("bindingFreeEnergy")
            if affinity is not None:
                reference = self.quantum_reference.get("statistics", {}).get("meanEnergy", -8.0)
                return 0.06 if affinity < reference else -0.02
            return 0.0
        if agent_name == "QuantumSimulationAgent":
            affinity = None
            if isinstance(report, dict):
                affinity = report.get("affinity", {}).get("bindingFreeEnergy")
            if affinity is not None:
                reference = self.quantum_reference.get("statistics", {}).get("meanEnergy", -8.0)
                return 0.05 if affinity < reference else 0.01
            return 0.0
        if agent_name == "SafetyAgent":
            toxicity = None
            if isinstance(report, dict):
                toxicity = report.get("admet", {}).get("toxicityRiskScore")
            if toxicity is not None:
                return -0.06 if toxicity > 0.25 else 0.03
            return 0.0
        return 0.015


    def _apply_superposition(self, agent_name: str, report: Dict[str, Any]) -> Dict[str, Any]:
        meta: Dict[str, Any] = {}
        if agent_name == "LigandDiscoveryAgent" and isinstance(report, dict):
            tolerance = float(0.1 + 0.2 * self.state_potential)
            affinity_report = report.get("affinity", {})
            reference_mean = self.quantum_reference.get("statistics", {}).get("meanEnergy")
            credible = None
            if isinstance(affinity_report, dict):
                credible = affinity_report.get("bindingFreeEnergyUncertainty", {}).get("credibleInterval")
            accepted = False
            if reference_mean is not None and credible:
                accepted = bool(credible[0] <= reference_mean <= credible[1])
                affinity_report["superpositionTolerance"] = {
                    "statePotential": self.state_potential,
                    "tolerance": tolerance,
                    "referenceWithinInterval": accepted,
                }
            meta = {
                "statePotential": self.state_potential,
                "tolerance": tolerance,
                "referenceWithinInterval": accepted,
            }
        if agent_name == "JobStatusAgent" and isinstance(report, dict):
            priority = float(1.0 + max(0.0, self.state_potential - 0.5) * 0.5)
            report.setdefault("resourceUtilization", {})["fidelityPriority"] = priority
            meta = {"fidelityPriority": priority, "statePotential": self.state_potential}
        return meta


    def _apply_entanglement_feedback(
        self,
        agent_name: str,
        awareness_delta: float,
    ) -> Dict[str, Any]:
        if abs(awareness_delta) < 0.05:
            return {}
        target = "SafetyAgent" if awareness_delta < 0 else "LigandDiscoveryAgent"
        record = {
            "target": target,
            "learningRateScale": self.entanglement_param_boost_factor,
            "awarenessChange": awareness_delta,
        }
        self.entanglement_records.append(record)
        return record


    def _update_awareness(self, delta: float) -> float:
        boost = 1.0
        if self.state_potential > 0.5:
            boost += self.potential_awareness_boost_factor
        if self.zeno_dampening_active:
            boost *= self.zeno_effect_dampening_factor
        adjusted = delta * boost
        self.self_awareness = float(np.clip(self.self_awareness + adjusted, 0.0, 1.0))
        self.awareness_history.append(self.self_awareness)
        self.awareness_changes.append(adjusted)
        return adjusted


    def _apply_adaptive_annealing(self) -> Dict[str, Any]:
        if len(self.awareness_history) < 5:
            return {}
        window = list(self.awareness_history)[-20:]
        std = statistics.pstdev(window) if len(window) > 1 else 0.0
        mode = "exploit" if std <= self.annealing_stability_threshold else "explore"
        lr_scale = (
            self.annealing_lr_factor_stable
            if mode == "exploit"
            else self.annealing_lr_factor_unstable
        )
        mutation_scale = (
            self.annealing_mutation_scale_factor_stable
            if mode == "exploit"
            else self.annealing_mutation_scale_factor_unstable
        )
        record = {
            "mode": mode,
            "awarenessStd": std,
            "learningRateScale": lr_scale,
            "mutationScale": mutation_scale,
        }
        if not self.annealing_records or self.annealing_records[-1] != record:
            self.annealing_records.append(record)
            if mode == "explore":
                self.mutate_params(mode)
        return record


    def _check_tunneling_conditions(self) -> Dict[str, Any]:
        if self.stagnation_counter >= 5 or self.pains_alert_counter >= 3:
            if self.self_awareness >= 0.7 and self.state_potential >= 0.3 and self.state_resonance < 0.4:
                return self._perform_quantum_tunnel()
        return {}


    def _perform_quantum_tunnel(self) -> Dict[str, Any]:
        noise = np.random.normal(0, self.tunneling_state_shift_factor, size=getattr(self.core_ai, "state_dim", 32))
        if hasattr(self.core_ai, "state"):
            self.core_ai.state = np.asarray(self.core_ai.state, dtype=float) + noise
        new_focus = f"{self.current_target_focus}-lambda-shift-{len(self.tunneling_records) + 1}"
        payload = {
            "reason": "Awareness Stagnation detected; low Resonance Score in state space.",
            "shift_magnitude": self.tunneling_state_shift_factor,
            "new_hypothesis_directive": "Prioritize scaffold hopping into lambda-toroidal sites.",
        }
        self.current_target_focus = new_focus
        self.tunneling_records.append({"newFocus": new_focus, "rewardBonus": 0.5, "payload": payload})
        self._queue_action("ACTION_QUANTUM_TUNNEL", payload)
        return {"newFocus": new_focus, "rewardBonus": 0.5, "payload": payload}


    def _perform_state_blend(self) -> Dict[str, Any]:
        random_state = np.random.normal(0, 1.0, size=getattr(self.core_ai, "state_dim", 32))
        current = np.asarray(getattr(self.core_ai, "state", np.zeros_like(random_state)), dtype=float)
        diff_norm = float(np.linalg.norm(current - random_state))
        scale = min(1.0, diff_norm / max(1.0, np.sqrt(random_state.size)))
        blend_factor = self.interference_blend_factor_base * (1.0 + scale)
        blended = (1 - blend_factor) * current + blend_factor * random_state
        if hasattr(self.core_ai, "state"):
            self.core_ai.state = blended
        payload = {
            "differenceNorm": diff_norm,
            "blendFactor": blend_factor,
        }
        self.blend_records.append(payload)
        self._queue_action("ACTION_BLEND_STATE", payload)
        return payload


    def _apply_memory_fidelity_noise(
        self,
        agent_name: str,
        report: Dict[str, Any],
    ) -> Dict[str, Any]:
        noise_scale = self.memory_fidelity_noise_factor * (
            1.0 + max(0.0, 0.5 - self.self_awareness) * 5.0
        )
        if noise_scale <= 0:
            return {}
        applied = False
        if isinstance(report, dict):
            target_keys: List[Tuple[Dict[str, Any], str]] = []
            if agent_name == "SafetyAgent":
                target_keys.append((report.get("admet", {}), "toxicityRiskScore"))
            elif agent_name == "LigandDiscoveryAgent":
                target_keys.append((report.get("affinity", {}), "bindingFreeEnergy"))
            elif agent_name == "QuantumSimulationAgent":
                target_keys.append((report.get("affinity", {}), "bindingFreeEnergy"))
            for container, key in target_keys:
                if isinstance(container, dict) and key in container:
                    memory_tag = container.setdefault(f"{key}MemoryInflation", {})
                    memory_tag["noiseScale"] = noise_scale
                    memory_tag["awareness"] = self.self_awareness
                    applied = True
        if applied:
            record = {"agent": agent_name, "noiseScale": noise_scale}
            self.memory_noise_records.append(record)
            return record
        return {}


    def _record_binding_score(self, agent_name: str, report: Dict[str, Any]) -> None:
        affinity = None
        if isinstance(report, dict):
            affinity = report.get("affinity", {}).get("bindingFreeEnergy")
        if affinity is None:
            return
        if self.binding_history and abs(affinity - min(self.binding_history)) < 0.05:
            self.stagnation_counter += 1
        else:
            self.stagnation_counter = max(0, self.stagnation_counter - 1)
        self.binding_history.append(float(affinity))


    def _track_pains_alerts(self, report: Dict[str, Any]) -> None:
        admet = report.get("admet") if isinstance(report, dict) else None
        if not isinstance(admet, dict):
            return
        if any(alert == "PAINS" for alert in admet.get("alerts", [])):
            self.pains_alert_counter += 1


    def _register_memory_snapshot(self, agent_name: str, report: Dict[str, Any]) -> None:
        summary = list(report.keys()) if isinstance(report, dict) else []
        entry = {"agent": agent_name, "summary": summary}
        target = "adversary" if agent_name == "SafetyAgent" else "self"
        agent_ref = self.agent_map.get(agent_name)
        if agent_ref and agent_ref.observation_state.get("lambdaLatentVector") is not None:
            latent_vector = agent_ref.observation_state.get("lambdaLatentVector", [])
            serialized = self.memory_api.serialize_memory(
                latent_vector,
                metadata={"agent": agent_name, "summary": summary, "scaling_basis": "lambda"},
            )
            entry["lambdaMemory"] = serialized
        self.memory_cache[target].append(entry)


    async def flush_blackboard(self) -> None:
        while self.pending_blackboard_posts:
            entry = self.pending_blackboard_posts.pop(0)
            payload = {
                "reportId": f"gtai-action-{len(self.action_log)}",
                "entry": entry,
            }
            await self.blackboard.post("gtaiActions", payload)


    def compile_summary(self) -> Dict[str, Any]:
        awareness_std = (
            statistics.pstdev(self.awareness_history)
            if len(self.awareness_history) > 1
            else 0.0
        )
        return {
            "state": {
                "statePotential": self.state_potential,
                "selfAwareness": self.self_awareness,
                "stateResonance": self.state_resonance,
                "awarenessStd": awareness_std,
                "awarenessHistoryTail": list(self.awareness_history)[-10:],
            },
            "actions": self.action_log,
            "entanglement": self.entanglement_records,
            "annealing": self.annealing_records,
            "tunneling": self.tunneling_records,
            "interference": self.blend_records,
            "simulations": self.simulation_reflections,
            "metaAnalysis": self.meta_tuning_records,
            "memory": self.memory_noise_records,
        }


# ---------------------------------------------------------------------------
# Agent definitions
# ---------------------------------------------------------------------------




class AgentBase:
    ACTION_SPACE: Dict[str, Tuple[float, float]] = {}


    def __init__(
        self,
        name: str,
        blackboard: QuantumBlackboard,
        context: QuantumContext,
        validator: PhysicalValidator,
        ml_registry: Optional[MLModelRegistry] = None,
        dataset_manager: Optional[DatasetManager] = None,
        feature_extractor: Optional[FeatureExtractor] = None,
        active_learning: Optional[ActiveLearningCoordinator] = None,
        ml_api: Optional[MLInferenceAPI] = None,
        **kwargs: Any,
    ):
        self.name = name
        self.blackboard = blackboard
        self.context = context
        self.validator = validator
        self.ml_registry = ml_registry
        self.dataset_manager = dataset_manager
        self.feature_extractor = feature_extractor
        self.active_learning = active_learning
        self.ml_api = ml_api
        extra_kwargs = dict(kwargs)
        self.config = extra_kwargs.pop("config", {}) or {}
        self.ml_models = load_pretrained_models(self.config)
        self._ml_warning_flags: Set[str] = set()
        self.kwargs = extra_kwargs
        self.observation_state: Dict[str, Any] = {}
        self.last_action_vector: Dict[str, float] = {}
        self.reward_history: List[float] = []
        self.quality_history: deque = deque(maxlen=32)
        self.max_quality: float = float("-inf")
        self.last_entropy_signal: float = 0.0
        self.last_energy_signal: float = 0.0


    async def run(self) -> Dict[str, Any]:
        raise NotImplementedError


    def _log_ml_fallback(self, model_key: str) -> None:
        if model_key in self._ml_warning_flags:
            return
        self._ml_warning_flags.add(model_key)
        logger.warning("%s: %s model not loaded, using heuristic fallback", self.name, model_key)


    def _score_pretrained_model(self, model_key: str, identifier: str) -> Optional[float]:
        model = self.ml_models.get(model_key)
        if model is None:
            self._log_ml_fallback(model_key)
            return None
        return model.score(identifier)


    def _heuristic_model_score(self, model_key: str, identifier: str) -> float:
        token = f"heuristic::{self.name}::{model_key}::{identifier}"
        return _deterministic_score(token)


    def encode_lambda_latent(self, state: Dict[str, Any]) -> np.ndarray:
        """Convert lambda-shell descriptors into a tensorial latent."""


        descriptors: List[Dict[str, Any]] = []
        if "descriptors" in state:
            descriptors = list(state.get("descriptors", []))
        elif "lambdaShellDiagnostics" in state:
            descriptors = list(state["lambdaShellDiagnostics"].get("descriptors", []))
        elif state.get("lambdaShellDiagnostics"):
            diag = state.get("lambdaShellDiagnostics")
            descriptors = list(diag.get("descriptors", []))
        if not descriptors:
            descriptors = list(self.context.lambda_shells)
        tensor_rows: List[List[float]] = []
        for descriptor in descriptors or []:
            tensor_rows.append(
                [
                    float(descriptor.get("lambdaRadius", 0.0)),
                    float(descriptor.get("lambdaCurvature", 0.0)),
                    float(descriptor.get("lambdaEntropy", 0.0)),
                    float(descriptor.get("lambdaEnergyDensity", 0.0)),
                    float(descriptor.get("lambdaBhattacharyya", 0.0)),
                    float(descriptor.get("lambdaOccupancy", 0.0)),
                    float(descriptor.get("lambdaLeakage", 0.0)),
                ]
            )
        if not tensor_rows:
            tensor_rows = [[0.0] * 7]
        tensor = np.asarray(tensor_rows, dtype=float)
        self.observation_state["lambdaLatentTensor"] = tensor
        self.observation_state["lambdaLatentVector"] = tensor.flatten()
        return tensor


    def _prepare_action_vector(
        self, action_vector: Optional[Dict[str, float]] = None
    ) -> Dict[str, float]:
        prepared: Dict[str, float] = {}
        if not self.ACTION_SPACE:
            if action_vector:
                prepared = {key: float(value) for key, value in action_vector.items()}
            self.observation_state["actionVector"] = prepared
            self.last_action_vector = prepared
            return prepared
        for key, bounds in self.ACTION_SPACE.items():
            low, high = bounds
            midpoint = (low + high) / 2.0
            value = midpoint
            if action_vector and key in action_vector:
                value = action_vector[key]
            value = float(np.clip(value, low, high))
            prepared[key] = value
        self.observation_state["actionVector"] = prepared
        self.last_action_vector = prepared
        return prepared


    def _reward_baseline(self) -> Dict[str, Any]:
        prev_quality = self.quality_history[-1] if self.quality_history else 0.0
        if self.max_quality == float("-inf"):
            self.max_quality = prev_quality
        quality_window = list(self.quality_history)
        prev_entropy = self.last_entropy_signal
        prev_energy = self.last_energy_signal
        return {
            "prev_quality": prev_quality,
            "max_quality": self.max_quality,
            "quality_window": quality_window,
            "prev_entropy": prev_entropy,
            "prev_energy": prev_energy,
        }


    def _record_quality(self, quality: float, entropy_signal: float, energy_signal: float) -> None:
        self.quality_history.append(quality)
        self.max_quality = max(self.max_quality, quality)
        self.last_entropy_signal = entropy_signal
        self.last_energy_signal = energy_signal


    def compute_reward(self, primitives: Dict[str, Any]) -> float:
        """Default reward for agents that have not defined a policy."""


        baseline = self._reward_baseline()
        validator = primitives.get("validatorDiagnostics", {})
        reward = RewardPrimitives.R_validator(
            int(validator.get("adjustmentCount", 0)),
            float(validator.get("meanClampDistance", 0.0)),
            lambda_adj=0.05,
            lambda_clamp=0.01,
        )
        entropy_signal = float(primitives.get("entropy_mean", 0.0))
        energy_signal = float(primitives.get("energy_signal", 0.0))
        self._record_quality(reward, entropy_signal, energy_signal)
        self.reward_history.append(reward)
        return reward
 
 
class StructuralAnalysisAgent(AgentBase):
    ACTION_SPACE = {
        "lambda_smoothing": (0.5, 2.0),
        "curvature_regularization": (0.25, 2.5),
    }


    BINDING_BENCHMARK: List[Dict[str, Any]] = [
        {
            "protein": "FAK1",
            "ligand": "LIG-FAK-001",
            "smiles": "CC(C)Nc1ccc(cc1)C(=O)N",
            "pdb_id": "2J0J",
            "affinity_type": "Kd",
            "affinity_value": 18.0,
            "affinity_units": "nM",
            "temperature_K": 298.15,
        },
        {
            "protein": "CDK2",
            "ligand": "LIG-CDK-001",
            "smiles": "COc1cccc2c1CC(N)C(=O)N2",
            "pdb_id": "2VTA",
            "affinity_type": "Ki",
            "affinity_value": 210.0,
            "affinity_units": "nM",
            "temperature_K": 300.0,
        },
    ]
    def __init__(
        self,
        blackboard: QuantumBlackboard,
        context: QuantumContext,
        validator: PhysicalValidator,
        data_client: PublicDataClient,
        pdb_id: str,
        ml_registry: Optional[MLModelRegistry] = None,
        dataset_manager: Optional[DatasetManager] = None,
        feature_extractor: Optional[FeatureExtractor] = None,
        active_learning: Optional[ActiveLearningCoordinator] = None,
        ml_api: Optional[MLInferenceAPI] = None,
    ):
        super().__init__(
            "StructuralAnalysisAgent",
            blackboard,
            context,
            validator,
            ml_registry=ml_registry,
            dataset_manager=dataset_manager,
            feature_extractor=feature_extractor,
            active_learning=active_learning,
            ml_api=ml_api,
        )
        self.data_client = data_client
        self.pdb_id = pdb_id


    def embed_lambda_shells(
        self,
        molecule_structure: np.ndarray,
        action_params: Optional[Dict[str, float]] = None,
    ) -> Dict[str, Any]:
        if molecule_structure.size == 0:
            return {"descriptors": [], "tensor": np.zeros((1, 7)), "shellFeatures": {}}
        actions = action_params or {}
        smoothing = float(actions.get("lambda_smoothing", 1.0))
        curvature_reg = float(actions.get("curvature_regularization", 1.0))
        center = np.mean(molecule_structure, axis=0)
        distances = np.linalg.norm(molecule_structure - center, axis=1)
        max_distance = float(np.max(distances) or 1.0)
        shell_count = int(self.context.lambda_basis.get("shellCount") or LambdaScalingToolkit.DEFAULT_SHELL_COUNT)
        shell_count = max(1, min(shell_count, LambdaScalingToolkit.DEFAULT_SHELL_COUNT))
        scaled_distance = distances / max(max_distance / LAMBDA_DILATION, 1e-6)
        shell_indices = np.clip(np.floor(scaled_distance * smoothing), 0, shell_count - 1).astype(int)
        curvature_profile = self.context.curvature_profile or [0.0]
        lambda_modes = self.context.lambda_modes or [1.0]
        ent_base = max(float(self.context.entanglement_entropy), ENTROPY_FLOOR)
        shell_features: Dict[int, Dict[str, float]] = {
            idx: {
                "count": 0.0,
                "shell_curvature": 0.0,
                "entanglement_density": 0.0,
@@ -3301,414 +3477,414 @@ class StructuralAnalysisAgent(AgentBase):
                "shell_curvature": shell_features[idx]["shell_curvature"],
                "entanglement_density": shell_features[idx]["entanglement_density"],
                "local_energy": shell_features[idx]["local_energy"],
            }
            for idx in range(shell_count)
        }
        embedding = {"descriptors": descriptors, "tensor": tensor, "shellFeatures": serialized_shell_features}
        self.observation_state["lambdaShellEmbedding"] = tensor
        self.observation_state["lambdaShellFeatures"] = descriptors
        per_shell_obs = [
            {
                "shellIndex": entry["shellIndex"],
                "lambdaEntropy": entry["lambdaEntropy"],
                "lambdaOccupancy": entry["lambdaOccupancy"],
                "lambdaLeakage": entry["lambdaLeakage"],
            }
            for entry in descriptors
        ]
        global_obs = {
            "lambdaAttractorScore": float(np.mean([entry["lambdaBhattacharyya"] for entry in descriptors]) if descriptors else 0.0),
            "lambdaEntropyGradient": float(
                (descriptors[-1]["lambdaEntropy"] - descriptors[0]["lambdaEntropy"]) if len(descriptors) > 1 else 0.0
            ),
            "lambdaBhattacharyyaFlux": float(np.std([entry["lambdaBhattacharyya"] for entry in descriptors]) if descriptors else 0.0),
        }
        self.observation_state["lambdaObservables"] = {"perShell": per_shell_obs, "global": global_obs}
        return embedding
 
    def _parse_atoms(self, pdb_text: str) -> np.ndarray: 
        coords: List[Tuple[float, float, float]] = [] 
        for line in pdb_text.splitlines(): 
            if line.startswith("ATOM"): 
                try: 
                    x = float(line[30:38]) 
                    y = float(line[38:46]) 
                    z = float(line[46:54]) 
                    coords.append((x, y, z)) 
                except ValueError: 
                    continue 
        if not coords: 
            coords.append((0.0, 0.0, 0.0)) 
        return np.array(coords) 
 
    def _detect_pockets( 
        self, 
        coords: np.ndarray, 
        shell_embedding: Optional[Dict[str, Any]] = None, 
    ) -> List[Dict[str, Any]]: 
        center = np.mean(coords, axis=0) 
        distances = np.linalg.norm(coords - center, axis=1) 
        threshold = np.percentile(distances, 60) 
        pocket_atoms = coords[distances < threshold] 
        volume = float(np.ptp(pocket_atoms[:, 0]) * np.ptp(pocket_atoms[:, 1]) * np.ptp(pocket_atoms[:, 2]) or 1.0) 
        hydrophobicity = float(np.clip(0.5 + 0.1 * random.random(), 0.0, 1.0)) 
        electrostatic = float(-1.0 * (1.0 + 0.1 * random.random())) 
        curvature_bias = statistics.mean(self.context.curvature_profile[:10]) if self.context.curvature_profile else -1.0 
        if shell_embedding and shell_embedding.get("shellFeatures"): 
            inner_shell = shell_embedding["shellFeatures"].get("0") 
            if inner_shell: 
                hydrophobicity = float(np.clip(hydrophobicity + 0.05 * inner_shell.get("entanglement_density", 0.0), 0.0, 1.0)) 
                curvature_bias = float(inner_shell.get("shell_curvature", curvature_bias)) 
        druggability = float(np.clip(0.7 + 0.05 * hydrophobicity + 0.01 * curvature_bias, 0.0, 1.0)) 
        return [ 
            { 
                "pocketId": "pocket-01", 
                "druggabilityScore": druggability, 
                "rank": 1, 
                "properties": { 
                    "size": volume, 
                    "shape": "ellipsoidal", 
                    "volume": volume, 
                    "hydrophobicity": hydrophobicity, 
                    "electrostaticPotential": electrostatic, 
                    "residueComposition": ["LEU:45", "VAL:48", "TYR:88"], 
                }, 
            } 
        ] 
 
    def _classify_waters(self, coords: np.ndarray) -> List[Dict[str, Any]]: 
        rng = np.random.default_rng(42) 
        entries = [] 
        for idx in range(3): 
            classification = rng.choice(["displaceable", "bridging", "stabilizing"], p=[0.4, 0.4, 0.2]) 
            entry: Dict[str, Any] = {"waterId": f"HOH-{300+idx}", "classification": classification} 
            if classification == "displaceable": 
                entry["displacementEnergy"] = float(-2.0 + rng.random()) 
            else: 
                partners = rng.choice(["ASP:25", "LIG:C4", "GLU:120", "HOH:410"], size=2, replace=False) 
                entry["bridgingPartners"] = partners.tolist() 
            entries.append(entry) 
        return entries 
 
    async def run(self, action_vector: Optional[Dict[str, float]] = None) -> Dict[str, Any]:
        actions = self._prepare_action_vector(action_vector)
        pdb_text = self.data_client.fetch_pdb(self.pdb_id)
        coords = self._parse_atoms(pdb_text)
        lambda_embedding = self.embed_lambda_shells(coords, actions)
        pockets = self._detect_pockets(coords, lambda_embedding)
        waters = self._classify_waters(coords)
        lambda_analysis = LambdaScalingToolkit.analyze_coordinates(coords, self.context)
        lambda_analysis.setdefault("summary", {})["scalingBasis"] = "lambda" 
        quantum_patterns = { 
            "lambdaCurvatureMean": float(np.mean(self.context.curvature_profile[:20] or [0.0])), 
            "emergingSiteClasses": ["lambda-toroidal", "quantum-anchored hydrophobic cavity"], 
            "patternRationale": "Patterns mined using quantum-enhanced pocket analysis per roadmap directive.", 
            "lambdaShellAnalysis": { 
                "descriptors": lambda_analysis["descriptors"], 
                "summary": {**lambda_analysis["summary"], **self.context.lambda_basis}, 
            }, 
            "lambdaShellEmbedding": { 
                "tensor": lambda_embedding["tensor"].tolist(), 
                "descriptors": lambda_embedding["descriptors"], 
            }, 
        } 
        ml_section: Dict[str, Any] = {} 
        if self.feature_extractor and self.dataset_manager and self.ml_registry: 
            task_name = "structural.druggability" 
            features_list: List[np.ndarray] = [] 
            metadata_bundle: List[Dict[str, Any]] = [] 
            for pocket in pockets: 
                feat = self.feature_extractor.featurize_pocket(pocket) 
                pocket.setdefault("lambdaShellDiagnostics", lambda_analysis) 
                pocket["lambdaShellEmbedding"] = { 
                    "tensor": lambda_embedding["tensor"].tolist(), 
                    "descriptors": lambda_embedding["descriptors"], 
                    "shellFeatures": lambda_embedding["shellFeatures"], 
                } 
                lambda_feat = self.feature_extractor.featurize_lambda_shells(lambda_analysis["descriptors"]) 
                combined_feat = self.feature_extractor.combine_features(feat, lambda_feat) 
                features_list.append(combined_feat) 
                metadata = {"pocketId": pocket.get("pocketId"), "source": "structural_analysis"} 
                metadata_bundle.append(metadata) 
                self.dataset_manager.register_record( 
                    task_name, 
                    combined_feat, 
                    pocket.get("druggabilityScore", 0.0), 
                    {**metadata, "reportId": f"pocket-rep-{self.pdb_id}"}, 
                ) 
            split = self.dataset_manager.build_split(task_name) 
            model = self.ml_registry.get_model(task_name) 
            if model is None and split.train_X.size: 
                model = SimpleRegressor(f"{task_name}-reg", architecture="GradientBoostedProxy") 
                metrics = model.train(split) 
                self.ml_registry.register_model(task_name, model, metrics, split.metadata) 
                training_record = lambda_shell_training_hook( 
                    self.name, 
                    self.context, 
                    lambda_analysis, 
                ) 
                self.observation_state.setdefault("trainingLogs", []).append(training_record) 
            if model and features_list: 
                normalization = split.normalization if split else {"mean": np.zeros_like(features_list[0]), "std": np.ones_like(features_list[0])} 
                stacked = np.stack(features_list) 
                norm = ( 
                    (stacked - normalization["mean"]) / normalization["std"] 
                    if isinstance(normalization, dict) 
                    else stacked 
                ) 
                preds, uncert = model.predict_with_uncertainty(norm) 
                ml_section = { 
                    "task": task_name, 
                    "model": model.describe(), 
                    "dataset": split.metadata if split else {"records": 0}, 
                    "predictions": [ 
                        { 
                            "pocketId": meta["pocketId"], 
                            "mlDruggability": float(pred), 
                            "uncertainty": float(unc), 
                        } 
                        for meta, pred, unc in zip(metadata_bundle, preds, uncert) 
                    ], 
                } 
                if self.active_learning: 
                    self.active_learning.evaluate_samples(task_name, features_list, preds, uncert, metadata_bundle) 
                if self.ml_api: 
                    self.ml_api.register_endpoint("structural/druggability", task_name, model.version) 
                    self.ml_api.log_call( 
                        "structural/druggability", 
                        {"pockets": [meta["pocketId"] for meta in metadata_bundle]}, 
                        {"predictions": ml_section["predictions"]}, 
                    ) 
        report = { 
            "reportId": f"pocket-rep-{self.pdb_id}", 
            "sourcePdbId": self.pdb_id, 
            "pockets": pockets, 
            "waterAnalysis": {"waterMolecules": waters}, 
            "quantumPocketInsights": quantum_patterns, 
            "mlAugmentation": ml_section, 
        } 
        validated = self.validator.validate(self.name, report)
        await self.blackboard.post("binding", validated)
        return validated


    def compute_reward(self, primitives: Dict[str, Any]) -> float:
        baseline = self._reward_baseline()
        entropy = primitives.get("entropy_per_shell") or [self.context.entanglement_entropy]
        leakage = primitives.get("leakage") or [0.0]
        curvature_gradient = float(primitives.get("curvature_gradient", 0.0))
        entropy_mean = float(primitives.get("entropy_mean", np.mean(entropy)))
        energy_signal = float(primitives.get("energy_signal", self.context.enhancement_factor))
        occ_curr = primitives.get("occupancy")
        if occ_curr is None:
            occ_curr = []
        occ_prev = primitives.get("occupancy_prev")
        if occ_prev is None:
            occ_prev = []
        shell_delta = float(primitives.get("shellEntropyDelta", 0.0))
        compress = RewardPrimitives.R_compress(
            bool(primitives.get("is_compressed", False)),
            float(primitives.get("compression_ratio", 0.0)),
            bool(primitives.get("basis_mismatch", False)),
            k_c=0.3,
            k_b=0.2,
        )
        lambda_term = RewardPrimitives.R_lambda(entropy, curvature_gradient, leakage)
        flow_term = RewardPrimitives.R_lambda_flow(occ_curr, occ_prev, shell_delta)
        Q_struct = 0.7 * lambda_term + 0.2 * flow_term + 0.1 * compress
        R_dd = RewardPrimitives.R_dd(Q_struct, baseline["max_quality"], lambda_dd=0.1)
        R_stag = RewardPrimitives.R_stagnation(
            Q_struct,
            baseline["prev_quality"],
            entropy_mean,
            baseline["prev_entropy"],
            energy_signal,
            baseline["prev_energy"],
            lambda_stag=0.2,
        )
        validator = primitives.get("validatorDiagnostics", {})
        R_val = RewardPrimitives.R_validator(
            int(validator.get("adjustmentCount", 0)),
            float(validator.get("meanClampDistance", 0.0)),
            lambda_adj=0.05,
            lambda_clamp=0.02,
        )
        total = float(Q_struct + R_dd + R_stag + R_val)
        self._record_quality(Q_struct, entropy_mean, energy_signal)
        self.reward_history.append(total)
        return total
 
 
class LigandDiscoveryAgent(AgentBase):
    ACTION_SPACE = {
        "exploration_temperature": (0.1, 5.0),
        "mutation_rate": (0.05, 0.95),
        "novelty_bias": (0.0, 1.0),
    }
    def __init__( 
        self, 
        blackboard: QuantumBlackboard, 
        context: QuantumContext, 
        validator: PhysicalValidator, 
        data_client: PublicDataClient, 
        llm: LightweightLLM, 
        target_query: str, 
        quantum_reference: Dict[str, Any], 
        ml_registry: Optional[MLModelRegistry] = None, 
        dataset_manager: Optional[DatasetManager] = None, 
        feature_extractor: Optional[FeatureExtractor] = None,
        active_learning: Optional[ActiveLearningCoordinator] = None,
        ml_api: Optional[MLInferenceAPI] = None,
        config: Optional[Dict[str, Any]] = None,
    ):
        super().__init__(
            "LigandDiscoveryAgent",
            blackboard,
            context,
            validator,
            ml_registry=ml_registry,
            dataset_manager=dataset_manager,
            feature_extractor=feature_extractor,
            active_learning=active_learning,
            ml_api=ml_api,
            config=config,
        )
        self.data_client = data_client
        self.llm = llm
        self.target_query = target_query
        self.quantum_reference = quantum_reference
        surrogate_seed = int(hashlib.sha1(target_query.encode("utf-8")).hexdigest(), 16) % 997  # nosec B303
        self.surrogate_model = LightweightGNN(random_state=surrogate_seed)
        self.inverse_engine: Optional[InverseDesignEngine] = None
        self._engine_context_id: Optional[str] = None


    def _derive_seed_smiles(self, seed_ligands: Optional[Sequence[Dict[str, Any]]]) -> List[str]:
        if seed_ligands:
            smiles = [entry.get("smiles") or entry.get("ligandId", "") for entry in seed_ligands]
            return [item for item in smiles if item]
        scaffold_library = [
            "c1ccccc1",
            "CC(=O)O",
            "CCN(CC)CC",
            "COC(=O)N",
        ]
        return scaffold_library


    def _estimate_novelty(self, smiles: str, seed_smiles: Sequence[str]) -> float:
        if not seed_smiles:
            return 0.8
        base_set = set(smiles)
        penalties = []
        for seed in seed_smiles:
            seed_set = set(seed)
            overlap = len(base_set & seed_set)
            union = max(len(base_set | seed_set), 1)
            penalties.append(overlap / union)
        similarity = float(np.mean(penalties)) if penalties else 0.0
        return float(np.clip(1.0 - similarity, 0.0, 1.0))
 
    def compute_shell_entropy_curvature_map(self, ligand: Dict[str, Any]) -> Dict[str, Any]: 
        diagnostics = ligand.get("lambdaShellDiagnostics") or {} 
        descriptors = diagnostics.get("descriptors", []) or self.context.lambda_shells 
        if not descriptors: 
            descriptors = [] 
        curvature_vector: List[float] = [] 
        entropy_vector: List[float] = [] 
        shell_map: List[Dict[str, Any]] = [] 
        for descriptor in descriptors: 
            curvature = float(descriptor.get("lambdaCurvature", 0.0)) 
            entropy = float(descriptor.get("lambdaEntropy", self.context.entanglement_entropy)) 
            shell_index = int(descriptor.get("shellIndex", len(shell_map))) 
            curvature_vector.append(curvature) 
            entropy_vector.append(entropy) 
            shell_map.append( 
                { 
                    "shellIndex": shell_index, 
                    "curvature": curvature, 
                    "entropy": entropy, 
                    "curvatureEntropyProduct": curvature * entropy, 
                } 
            ) 
        tensor = self.encode_lambda_latent({"descriptors": descriptors}) 
        map_payload = { 
            "shellMap": shell_map, 
            "curvatureVector": curvature_vector, 
            "entropyVector": entropy_vector, 
            "tensor": tensor.tolist(), 
        } 
        ligand["lambdaShellMap"] = map_payload 
        self.observation_state.setdefault("ligandShellMaps", []).append(map_payload) 
        return map_payload 
 
    def _compute_candidate_metrics(self, candidate: Dict[str, Any]) -> Dict[str, Any]:
        diagnostics = candidate.get("lambdaShellDiagnostics", {})
        descriptors = diagnostics.get("descriptors", []) or self.context.lambda_shells
        stats = QuantumContext.shell_statistics(descriptors)
        lambda_context = {
            "entropyMean": stats.get("entropyMean", 0.5),
            "curvatureMean": stats.get("curvatureMean", 0.0),
        }
        surrogate = self.inverse_engine.surrogate_model if self.inverse_engine else self.surrogate_model
        surrogate_affinity = surrogate.score(candidate.get("smiles", ""), lambda_context=lambda_context) if surrogate else 0.0
        surrogate_norm = 0.5 * (surrogate_affinity + 1.0)
        novelty = float(candidate.get("noveltyScore", 0.5))
        shell_alignment = float(stats.get("bhattacharyyaMean", 0.5))
        attractor = float(
            np.clip(
                0.2
                + 0.4 * shell_alignment
                + 0.2 * novelty
                + 0.2 * surrogate_norm,
                0.0,
                1.0,
            )
        )
        curvature_mean = float(stats.get("curvatureMean", 0.0))
        dilation = float(
            np.clip(
                0.95 + 0.02 * curvature_mean + 0.05 * (novelty - 0.5),
                0.85,
                1.15,
            )
        )
        reference_base = float(self.quantum_reference.get("statistics", {}).get("meanEnergy", -7.0))
        reference_energy = float(reference_base - 0.5 * surrogate_norm - 0.25 * novelty)
        metrics = {
            "lambdaAttractorScore": attractor,
            "dilationFactor": dilation,
            "referenceEnergyMean": reference_energy,
            "lambdaShellStats": stats,
        }
        return metrics


    def _passes_acceptance_thresholds(self, metrics: Dict[str, Any]) -> bool:
        return (
            metrics.get("lambdaAttractorScore", 0.0) > 0.25
            and 0.9 <= float(metrics.get("dilationFactor", 0.0)) <= 1.1
            and float(metrics.get("referenceEnergyMean", 0.0)) < -6.5
        )
 
    async def run(
        self,
        context_override: Optional[QuantumContext] = None,
        seed_ligands: Optional[Sequence[Dict[str, Any]]] = None,
        beam_width: int = 12,
        action_vector: Optional[Dict[str, float]] = None,
    ) -> Dict[str, Any]:
        actions = self._prepare_action_vector(action_vector)
        context_in_use = context_override or self.context
        population_size = max(int(beam_width * 1.5), beam_width + 2)
        context_identifier = f"{id(context_in_use)}:{context_in_use.entanglement_entropy:.3f}"
        if (
            self.inverse_engine is None
            or self.inverse_engine.population_size != population_size
            or context_identifier != self._engine_context_id
        ):
            self.inverse_engine = InverseDesignEngine(
                context_in_use,
                surrogate_model=self.surrogate_model,
                population_size=population_size,
                random_state=int(population_size + DEFAULT_RANDOM_SEED),
            )
            self._engine_context_id = context_identifier
        binding_report = await self.blackboard.read("binding")
        pocket_id = binding_report["pockets"][0]["pocketId"] if binding_report else "pocket-01"
@@ -3803,164 +3979,164 @@ class LigandDiscoveryAgent(AgentBase):
                    "lambdaEntropy": float(entry.get("lambdaEntropy", 0.0)),
                    "lambdaOccupancy": float(entry.get("lambdaOccupancy", 0.0)),
                    "lambdaLeakage": float(entry.get("lambdaLeakage", 0.0)),
                }
                for idx, entry in enumerate(descriptor_source)
            ]
            global_obs = {
                "lambdaAttractorScore": float(
                    np.mean([entry.get("lambdaBhattacharyya", 0.0) for entry in descriptor_source])
                ),
                "lambdaEntropyGradient": float(
                    descriptor_source[-1].get("lambdaEntropy", 0.0) - descriptor_source[0].get("lambdaEntropy", 0.0)
                    if len(descriptor_source) > 1
                    else 0.0
                ),
                "lambdaBhattacharyyaFlux": float(
                    np.std([entry.get("lambdaBhattacharyya", 0.0) for entry in descriptor_source])
                ),
            }
            self.observation_state["lambdaObservables"] = {"perShell": per_shell_obs, "global": global_obs}
        if self.feature_extractor and self.dataset_manager and self.ml_registry and all_candidates:
            task_name = "ligand.bindingAffinity"
            features = []
            metadata_bundle = []
            for candidate in all_candidates:
                feat = self.feature_extractor.featurize_smiles(candidate.get("smiles", "")) 
                lambda_feat = self.feature_extractor.featurize_lambda_shells( 
                    candidate.get("lambdaShellDiagnostics", {}).get("descriptors", []) 
                ) 
                shell_tensor = np.asarray(candidate.get("lambdaShellMap", {}).get("tensor", []), dtype=float).flatten() 
                combined_feat = self.feature_extractor.combine_features(feat, lambda_feat) 
                if shell_tensor.size: 
                    combined_feat = self.feature_extractor.combine_features(combined_feat, shell_tensor) 
                features.append(combined_feat) 
                metadata = { 
                    "ligandId": candidate.get("ligandId"), 
                    "source": "ligand_agent", 
                } 
                metadata_bundle.append(metadata) 
                label = candidate.get("drugLikeness") or candidate.get("noveltyScore") or 0.5 
                self.dataset_manager.register_record( 
                    task_name, combined_feat, label, {**metadata, "labelType": "heuristic"} 
                ) 
            split = self.dataset_manager.build_split(task_name) 
            model = self.ml_registry.get_model(task_name) 
            if model is None and split.train_X.size: 
                model = GraphSurrogateModel(f"{task_name}-gnn")
                metrics = model.train(split)
                self.ml_registry.register_model(task_name, model, metrics, split.metadata)
                training_record = lambda_shell_training_hook(
                    self.name,
                    self.context,
                    ligand_lambda_diag or {"descriptors": self.context.lambda_shells}, 
                ) 
                self.observation_state.setdefault("trainingLogs", []).append(training_record) 
            risk_task = "ligand.offTargetRisk" 
            if features:
                for candidate, feat in zip(all_candidates, features):
                    flag = 0.0
                    self.dataset_manager.register_record(
                        risk_task,
                        feat,
                        flag,
                        {"ligandId": candidate.get("ligandId"), "source": "ligand_agent"},
                    ) 
            risk_split = self.dataset_manager.build_split(risk_task) 
            risk_model = self.ml_registry.get_model(risk_task) 
            if risk_model is None and risk_split.train_X.size: 
                risk_model = SimpleClassifier(f"{risk_task}-clf", architecture="SVMProxy") 
                risk_metrics = risk_model.train(risk_split) 
                self.ml_registry.register_model(risk_task, risk_model, risk_metrics, risk_split.metadata) 
                training_record = lambda_shell_training_hook( 
                    f"{self.name}-risk", 
                    self.context, 
                    ligand_lambda_diag or {"descriptors": self.context.lambda_shells}, 
                ) 
                self.observation_state.setdefault("trainingLogs", []).append(training_record) 
            if model and features: 
                normalization = split.normalization if split else {"mean": np.zeros_like(features[0]), "std": np.ones_like(features[0])} 
                stacked = np.stack(features) 
                norm_features = ( 
                    (stacked - normalization["mean"]) / normalization["std"] 
                    if isinstance(normalization, dict) 
                    else stacked 
                ) 
                preds, uncert = model.predict_with_uncertainty(norm_features) 
                ranking = sorted( 
                    [ 
                        { 
                            "ligandId": meta["ligandId"], 
                            "predictedAffinityScore": float(pred), 
                            "uncertainty": float(unc), 
                        } 
                        for meta, pred, unc in zip(metadata_bundle, preds, uncert) 
                    ], 
                    key=lambda item: item["predictedAffinityScore"], 
                    reverse=True, 
                ) 
                risk_predictions: List[Dict[str, Any]] = [] 
                if risk_model: 
                    risk_norm = ( 
                        (stacked - risk_split.normalization["mean"]) / risk_split.normalization["std"] 
                        if risk_split and isinstance(risk_split.normalization, dict) and risk_split.train_X.size 
                        else norm_features 
                    ) 
                    risk_scores, risk_unc = risk_model.predict_with_uncertainty(risk_norm) 
                    risk_predictions = [ 
                        { 
                            "ligandId": meta["ligandId"], 
                            "riskScore": float(score), 
                            "uncertainty": float(u), 
                        } 
                        for meta, score, u in zip(metadata_bundle, risk_scores, risk_unc) 
                    ] 
                    if self.active_learning: 
                        self.active_learning.evaluate_samples(risk_task, features, risk_scores, risk_unc, metadata_bundle) 
                ml_section = { 
                    "affinityModel": model.describe(), 
                    "riskModel": risk_model.describe() if risk_model else None, 
                    "rankedCandidates": ranking, 
                    "riskPredictions": risk_predictions, 
                    "datasets": { 
                        "affinity": split.metadata if split else {"records": 0}, 
                        "risk": risk_split.metadata if risk_split else {"records": 0}, 
                    }, 
                } 
                if self.active_learning: 
                    self.active_learning.evaluate_samples(task_name, features, preds, uncert, metadata_bundle) 
                if self.ml_api: 
                    self.ml_api.register_endpoint("ligand/affinity", task_name, model.version) 
                    self.ml_api.log_call( 
                        "ligand/affinity", 
                        {"ligands": [meta["ligandId"] for meta in metadata_bundle]}, 
                        {"rankedCandidates": ranking[:3]}, 
                    ) 
                    if risk_model: 
                        self.ml_api.register_endpoint("ligand/risk", risk_task, risk_model.version) 
                        self.ml_api.log_call( 
                            "ligand/risk", 
                        {"ligands": [meta["ligandId"] for meta in metadata_bundle]},
                        {"riskPredictions": risk_predictions},
                    )
        combined["mlAugmentation"] = ml_section
        pretrained_meta: Dict[str, Any] = {}
        if generated_ligands:
            affinity_model = self.ml_models.get("affinity")
            if affinity_model:
                pretrained_meta["affinity"] = affinity_model.describe()
                for candidate in generated_ligands:
                    smiles = candidate.get("smiles") or candidate.get("ligandId", "")
                    score = affinity_model.score(smiles)
                    candidate["mlAffinityScore"] = float(-5.0 - 6.0 * score)
            else:
                self._log_ml_fallback("affinity")
                for candidate in generated_ligands:
                    smiles = candidate.get("smiles") or candidate.get("ligandId", "")
                    score = self._heuristic_model_score("affinity", smiles)
                    candidate["mlAffinityScore"] = float(-5.0 - 6.0 * score)
            synth_model = self.ml_models.get("synthesis")
            if synth_model:
                pretrained_meta["synthesis"] = synth_model.describe()
                for candidate in generated_ligands:
                    score = synth_model.score(candidate.get("ligandId", ""))
                    candidate["mlSynthesisFeasibility"] = float(np.clip(score, 0.0, 1.0))
@@ -4027,500 +4203,409 @@ class LigandDiscoveryAgent(AgentBase):
            + 0.03 * R_div
        )
        R_dd = RewardPrimitives.R_dd(Q_ligand, baseline["max_quality"], lambda_dd=0.3)
        window = baseline["quality_window"] + [Q_ligand]
        R_vol = RewardPrimitives.R_vol(window, lambda_vol=0.3)
        R_stag = RewardPrimitives.R_stagnation(
            Q_ligand,
            baseline["prev_quality"],
            entropy_mean,
            baseline["prev_entropy"],
            energy_signal,
            baseline["prev_energy"],
            lambda_stag=0.4,
        )
        validator = primitives.get("validatorDiagnostics", {})
        R_val = RewardPrimitives.R_validator(
            int(validator.get("adjustmentCount", 0)),
            float(validator.get("meanClampDistance", 0.0)),
            lambda_adj=0.05,
            lambda_clamp=0.02,
        )
        total = float(Q_ligand + R_dd + R_vol + R_stag + R_val)
        self._record_quality(Q_ligand, entropy_mean, energy_signal)
        self.reward_history.append(total)
        return total




class PhysicsEngineAdapters:
    """Deterministic adapters standing in for external MD/QM engines."""


    def __init__(self, md_config: Optional[MDConfig] = None) -> None:
        self.md_config = md_config or MDConfig()
        self.precomputed_data: Dict[Tuple[str, str], Dict[str, Any]] = {
            ("FAK1", "LIG-FAK-001"): {
                "docking": {"score": -9.4, "pose": "docked_fak1_001.pdbqt"},
                "md": {
                    "rmsd": [1.2, 1.1, 1.05],
                    "rmsf": [0.8, 0.9, 1.0],
                    "hydrogen_bonds": [3, 4, 4],
                    "contact_map_counts": {"res45": 12, "res100": 9},
                    "potential_energy": [-1123.2, -1122.1, -1123.7],
                    "temperature": [299.5, 300.1, 299.9],
                    "key_distances": {"lig_res45": [3.2, 3.1, 3.0]},
                },
                "free_energy": {
                    "delta_g": -10.6,
                    "error": 0.6,
                    "md_windows": 16,
                    "force_field": "AMBER14SB",
                    "water_model": "TIP3P",
                },
                "qm": {
                    "method": "B3LYP/def2-SVP",
                    "total_energy": -1523.124,
                    "interaction_energy": -0.034,
                    "partial_charges": {"LIG": -0.12, "ASP564": -0.41},
                    "per_residue": {"ASP564": -0.018, "LYS579": -0.010},
                },
            },
            ("CDK2", "LIG-CDK-001"): {
                "docking": {"score": -8.7, "pose": "docked_cdk2_001.pdbqt"},
                "md": {
                    "rmsd": [1.5, 1.4, 1.35],
                    "rmsf": [1.1, 1.0, 0.95],
                    "hydrogen_bonds": [2, 3, 3],
                    "contact_map_counts": {"res82": 10, "res146": 7},
                    "potential_energy": [-1043.1, -1042.5, -1043.0],
                    "temperature": [300.2, 299.9, 300.0],
                    "key_distances": {"lig_res82": [3.6, 3.4, 3.3]},
                },
                "free_energy": {
                    "delta_g": -9.1,
                    "error": 0.7,
                    "md_windows": 12,
                    "force_field": "AMBER14SB",
                    "water_model": "TIP3P",
                },
                "qm": {
                    "method": "PBE0/def2-SVP",
                    "total_energy": -1288.774,
                    "interaction_energy": -0.027,
                    "partial_charges": {"LIG": -0.08, "GLU81": -0.36},
                    "per_residue": {"GLU81": -0.012, "ASP86": -0.009},
                },
            },
            ("MAPK14", "LIG-MAPK14-001"): {
                "docking": {"score": -10.2, "pose": "docked_mapk14_001.pdbqt"},
                "md": {
                    "rmsd": [1.0, 0.95, 0.9],
                    "rmsf": [0.7, 0.75, 0.8],
                    "hydrogen_bonds": [4, 5, 5],
                    "contact_map_counts": {"res70": 14, "res106": 11},
                    "potential_energy": [-1322.4, -1321.8, -1322.1],
                    "temperature": [298.8, 299.5, 299.7],
                    "key_distances": {"lig_res70": [3.0, 2.9, 2.8]},
                },
                "free_energy": {
                    "delta_g": -13.5,
                    "error": 0.4,
                    "md_windows": 20,
                    "force_field": "AMBER14SB",
                    "water_model": "TIP3P",
                },
                "qm": {
                    "method": "B3LYP/def2-TZVP",
                    "total_energy": -1684.552,
                    "interaction_energy": -0.042,
                    "partial_charges": {"LIG": -0.15, "ASP168": -0.39},
                    "per_residue": {"ASP168": -0.020, "LYS53": -0.011},
                },
            },
        }


    def run_docking(self, protein: str, ligand: str) -> Dict[str, Any]:
        data = self.precomputed_data[(protein, ligand)]["docking"]
        return {"score": data["score"], "pose": data["pose"], "engine": "vina"}


    def run_md(self, protein: str, ligand: str) -> MDTrajectorySummary:
        data = self.precomputed_data[(protein, ligand)]["md"]
        return MDTrajectorySummary(
            rmsd=data["rmsd"],
            rmsf=data["rmsf"],
            hydrogen_bonds=data["hydrogen_bonds"],
            contact_map_counts=data["contact_map_counts"],
            potential_energy=data["potential_energy"],
            temperature=data["temperature"],
            key_distances=data["key_distances"],
        )


    def compute_free_energy(self, protein: str, ligand: str, experimental_delta_g: float) -> BindingResult:
        free_energy = self.precomputed_data[(protein, ligand)]["free_energy"]
        diagnostics = {
            "lambda_schedule": list(np.linspace(0, 1, free_energy["md_windows"])),
            "block_error": free_energy["error"],
            "metadata": {"protein": protein, "ligand": ligand},
        }
        return BindingResult(
            delta_g_kcal_mol=float(free_energy["delta_g"]),
            temperature_kelvin=self.md_config.temperature_kelvin,
            standard_state="1 atm",
            force_field=free_energy["force_field"],
            water_model=free_energy["water_model"],
            md_windows=int(free_energy["md_windows"]),
            convergence_diagnostics=diagnostics,
            error_kcal_mol=float(free_energy["error"]),
            experimental_delta_g=float(experimental_delta_g),
        )


    def run_qm(self, protein: str, ligand: str, qm_region: List[str]) -> QMResult:
        qm_data = self.precomputed_data[(protein, ligand)]["qm"]
        return QMResult(
            method=qm_data["method"],
            qm_region=qm_region,
            total_energy_hartree=float(qm_data["total_energy"]),
            interaction_energy_hartree=float(qm_data["interaction_energy"]),
            partial_charges=qm_data["partial_charges"],
            per_residue_energies=qm_data.get("per_residue"),
        )




class QuantumSimulationAgent(AgentBase):
    ACTION_SPACE = {
        "accuracy_vs_speed": (0.0, 1.0),
        "sampling_density": (0.25, 2.5),
    }
    def __init__(
        self,
        blackboard: QuantumBlackboard,
        context: QuantumContext,
        validator: PhysicalValidator,
        uniprot_meta: Dict[str, Any],
        quantum_reference: Dict[str, Any],
        ml_registry: Optional[MLModelRegistry] = None,
        dataset_manager: Optional[DatasetManager] = None,
        feature_extractor: Optional[FeatureExtractor] = None,
        active_learning: Optional[ActiveLearningCoordinator] = None,
        ml_api: Optional[MLInferenceAPI] = None,
        quantum_config: Optional[Dict[str, Any]] = None,
        md_config: Optional[MDConfig] = None,
    ):
        super().__init__(
            "QuantumSimulationAgent",
            blackboard,
            context,
            validator, 
            ml_registry=ml_registry, 
            dataset_manager=dataset_manager,
            feature_extractor=feature_extractor,
            active_learning=active_learning,
            ml_api=ml_api,
        )
        self.uniprot_meta = uniprot_meta
        self.quantum_reference = quantum_reference
        self.md_config = md_config or MDConfig()
        self.physics = PhysicsEngineAdapters(self.md_config)
        self.quantum_config = quantum_config or {}
        self.experimental_mode = bool(self.quantum_config.get("experimental_mode", False))
        self.benchmark_limit = int(self.quantum_config.get("benchmark_limit", 1))
        proteins = self.quantum_config.get("benchmark_proteins") or []
        self.benchmark_proteins: Set[str] = set(proteins)


    def compute_mmff_energy(self, smiles: str) -> float:
        baseline = -6.0 - 0.4 * self.context.enhancement_factor
        descriptor = _deterministic_score(f"mmff:{smiles}")
        return float(baseline - 2.0 * (descriptor - 0.5))


    def compute_pm6_energy(self, smiles: str, mmff_energy: Optional[float] = None) -> float:
        mmff = mmff_energy if mmff_energy is not None else self.compute_mmff_energy(smiles)
        descriptor = _deterministic_score(f"pm6:{smiles}")
        return float(mmff - 0.8 - 0.6 * descriptor)


    def apply_lambda_shell_correction(
        self, energy: float, lambda_stats: Optional[Dict[str, Any]]
    ) -> float:
        stats = lambda_stats or {}
        entropy = float(stats.get("entropyMean", self.context.entanglement_entropy))
        curvature = float(stats.get("curvatureMean", 0.0))
        correction = -0.15 * entropy + 0.05 * curvature
        return float(energy + correction)
        self.quantum_config = {
            "alpha_calibration": 0.3,
            "enable_pm6": True,
            "mmff_pre_screen_threshold": -3.0,
        }
        if quantum_config:
            self.quantum_config.update(quantum_config)
 
    def simulate_quantum_state(
        self,
        binding_site: Optional[Dict[str, Any]],
        ligand_diag: Optional[Dict[str, Any]],
        sampling_density: float = 1.0,
    ) -> Dict[str, Any]:
        epsilon = 0.01 * sampling_density
        scales = [1.0, max(LAMBDA_DILATION - epsilon, 0.1), LAMBDA_DILATION + epsilon]
        base_descriptors = []
        if binding_site and binding_site.get("pockets"):
            base_descriptors = binding_site["pockets"][0].get("lambdaShellDiagnostics", {}).get("descriptors", [])
        if not base_descriptors and ligand_diag:
            base_descriptors = ligand_diag.get("descriptors", [])
        if not base_descriptors:
            base_descriptors = self.context.lambda_shells
        shell_count = max(len(base_descriptors), 1)
        shell_probabilities: List[List[float]] = []
        for scale in scales:
            probs: List[float] = []
            total = 0.0
            for descriptor in base_descriptors:
                occupancy = float(descriptor.get("lambdaOccupancy", 1.0 / shell_count))
                shell_index = float(descriptor.get("shellIndex", len(probs)))
                prob = float(np.clip(occupancy * (scale ** (-shell_index)), 1e-6, 1.0))
                probs.append(prob)
                total += prob
            if total > 0:
                probs = [p / total for p in probs]
            else:
                probs = [1.0 / shell_count] * shell_count
            shell_probabilities.append(probs)
        baseline = shell_probabilities[0]
        overlaps: Dict[str, float] = {}
        bhattacharyya_scores: List[float] = []
        for idx, perturbed in enumerate(shell_probabilities[1:], start=1):
            overlap = float(
                np.mean(
                    [
                        LambdaScalingToolkit._bhattacharyya(base, pert)
                        for base, pert in zip(baseline, perturbed)
                    ]
                )
            )
            overlaps[f"scale_{idx}"] = overlap
            bhattacharyya_scores.append(overlap)
        stability = float(np.mean(bhattacharyya_scores)) if bhattacharyya_scores else 1.0
        diagnostics = {
            "scales": scales,
            "shellProbabilities": shell_probabilities,
            "bhattacharyyaOverlap": overlaps,
            "lambdaShiftStabilityScore": stability,
        }
        self.observation_state["lambdaShiftDiagnostics"] = diagnostics
        return diagnostics


    def _simulate_pose(self, ligand_id: str, lambda_diag: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        base_affinity = -8.5 - 0.5 * self.context.enhancement_factor
        affinity = base_affinity + random.uniform(-0.8, 0.3)
        shape = float(np.clip(0.7 + 0.1 * random.random(), 0.0, 1.0))
        pose = {
            "poseId": f"pose-{ligand_id}",
            "bindingAffinityScore": affinity,
            "shapeComplementarity": shape,
            "keyInteractions": ["H-bond:SER:530", "salt-bridge:ARG:513"],
            "ensembleStatistics": {
                "canonicalBeta": 1.0 / max(0.1, 298.0 * 0.001987),
                "partitionFunction": float(
                    np.exp(-affinity / max(0.1, abs(self.quantum_reference["statistics"]["meanEnergy"])) )
                ),
            },
        }
        if lambda_diag:
            pose["lambdaShellDiagnostics"] = lambda_diag
            pose["lambdaShellFingerprint"] = lambda_diag.get("summary", {}).get(
                "lambdaShellFingerprint", lambda_diag.get("fingerprint", [])
            )
        return pose


    def _binding_affinity(
        self, ligand_id: str, pose: Dict[str, Any], lambda_diag: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        electro = -5.0 - 0.2 * self.context.enhancement_factor
        dispersion = -4.0 + 0.1 * random.random()
        hydrogen = -3.0 - 0.1 * random.random()
        free_energy = pose["bindingAffinityScore"] - 0.5 * self.context.entanglement_entropy
        reference_energy = self.quantum_reference.get("statistics", {}).get("meanEnergy", free_energy)
        energy_bounds = self.quantum_reference.get("statistics", {}).get("energyRange", {"min": -60.0, "max": -0.5})
        report = {
            "reportId": f"qm-rep-{ligand_id}",
            "sourceLigandId": ligand_id,
            "bindingFreeEnergy": float(free_energy),
            "confidence": float(np.clip(0.85 + 0.05 * random.random(), 0.0, 1.0)),
            "energyDecomposition": {
                "electrostatics": float(electro),
                "dispersion": float(dispersion),
                "hydrogenBonding": float(hydrogen),
            },
            "target": self.uniprot_meta,
            "referenceComparison": {
                "deltaFromQuantumMean": float(free_energy - reference_energy),
                "withinReferenceBounds": bool(energy_bounds["min"] <= free_energy <= energy_bounds["max"]),
            },
        }
        if lambda_diag:
            report["lambdaShellDiagnostics"] = lambda_diag
            report["lambdaShellFingerprint"] = lambda_diag.get("summary", {}).get(
                "lambdaShellFingerprint", lambda_diag.get("fingerprint", [])
            )
        return report




    async def run(
        self,
        context_override: Optional[QuantumContext] = None,
        ligand_report: Optional[Dict[str, Any]] = None,
        action_vector: Optional[Dict[str, float]] = None,
    ) -> Dict[str, Any]:
        if self.experimental_mode:
            raise RuntimeError("experimental_mode is disabled for production runs")


        benchmark_records = (
            self.dataset_manager.benchmark_utility.load_binding_benchmark(limit=self.benchmark_limit)
            if self.dataset_manager
            else BenchmarkDatasetUtility().load_binding_benchmark(limit=self.benchmark_limit)
        )
        if self.benchmark_proteins:
            benchmark_records = [rec for rec in benchmark_records if rec["protein"] in self.benchmark_proteins]
        if not benchmark_records:
            raise RuntimeError("No benchmark records available for the requested configuration")
        binding_results: List[BindingResult] = []
        qm_results: List[QMResult] = []
        trajectory_summaries: List[MDTrajectorySummary] = []
        for record in benchmark_records:
            protein = record["protein"]
            ligand = record["ligand"]
            docking = self.physics.run_docking(protein, ligand)
            trajectory = self.physics.run_md(protein, ligand)
            binding = self.physics.compute_free_energy(protein, ligand, record["delta_g_exp"])
            qm = self.physics.run_qm(protein, ligand, [protein, ligand])
            binding.convergence_diagnostics.setdefault("docking", docking)
            trajectory_summaries.append(trajectory)
            binding_results.append(binding)
            qm_results.append(qm)
            await self.blackboard.post("docking", docking)
            await self.blackboard.post("trajectory", asdict(trajectory))
        best_binding = min(binding_results, key=lambda b: b.delta_g_kcal_mol)
        evaluation = BenchmarkEvaluator.evaluate(binding_results, benchmark_records)
        report = {
            "best": asdict(best_binding),
            "bindingResults": [asdict(result) for result in binding_results],
            "qmResults": [asdict(result) for result in qm_results],
            "trajectorySummaries": [asdict(summary) for summary in trajectory_summaries],
            "mdConfig": asdict(self.md_config),
            "evaluation": evaluation,
        }
        await self.blackboard.post("quantum", report["best"])
        return report


    def compute_reward(self, primitives: Dict[str, Any]) -> float:
        baseline = self._reward_baseline()
        binding_energy = float(primitives.get("binding_energy", -8.0))
        reference_energy = float(primitives.get("reference_energy", -7.0))
        entropy = primitives.get("entropy_per_shell") or [self.context.entanglement_entropy]
        leakage = primitives.get("leakage") or [0.0]
        curvature_gradient = float(primitives.get("curvature_gradient", 0.0))
        occ_curr = primitives.get("occupancy")
        if occ_curr is None:
            occ_curr = []
        occ_prev = primitives.get("occupancy_prev")
        if occ_prev is None:
            occ_prev = []
        shell_delta = float(primitives.get("shellEntropyDelta", 0.0))
        mmff_energy = float(primitives.get("mmff_energy", binding_energy))
        lambda_corr = float(primitives.get("lambda_correction", 0.0))
        phys_term = float(
            np.tanh(
                max(0.0, 1.0 - 0.1 * abs(mmff_energy - binding_energy))
                + max(0.0, 1.0 - 0.1 * abs(lambda_corr))
            )
        )
        R_bind = RewardPrimitives.R_bind(binding_energy, reference_energy)
        R_lambda = RewardPrimitives.R_lambda(entropy, curvature_gradient, leakage)
@@ -4534,83 +4619,83 @@ class QuantumSimulationAgent(AgentBase):
        )
        Q_quantum = 0.5 * phys_term + 0.2 * R_bind + 0.1 * R_lambda + 0.1 * R_flow + 0.1 * R_comp
        entropy_mean = float(primitives.get("entropy_mean", np.mean(entropy)))
        energy_signal = binding_energy
        R_dd = RewardPrimitives.R_dd(Q_quantum, baseline["max_quality"], lambda_dd=0.2)
        R_stag = RewardPrimitives.R_stagnation(
            Q_quantum,
            baseline["prev_quality"],
            entropy_mean,
            baseline["prev_entropy"],
            energy_signal,
            baseline["prev_energy"],
            lambda_stag=0.3,
        )
        validator = primitives.get("validatorDiagnostics", {})
        R_val = RewardPrimitives.R_validator(
            int(validator.get("adjustmentCount", 0)),
            float(validator.get("meanClampDistance", 0.0)),
            lambda_adj=0.1,
            lambda_clamp=0.03,
        )
        total = float(Q_quantum + R_dd + R_stag + R_val)
        self._record_quality(Q_quantum, entropy_mean, energy_signal)
        self.reward_history.append(total)
        return total
 
 
class SynthesisPlannerAgent(AgentBase):
    ACTION_SPACE = {
        "retrosynthesis_aggressiveness": (0.5, 2.5),
    }
    def __init__( 
        self, 
        blackboard: QuantumBlackboard, 
        context: QuantumContext, 
        validator: PhysicalValidator, 
        llm: LightweightLLM, 
        ml_registry: Optional[MLModelRegistry] = None, 
        dataset_manager: Optional[DatasetManager] = None, 
        feature_extractor: Optional[FeatureExtractor] = None,
        active_learning: Optional[ActiveLearningCoordinator] = None,
        ml_api: Optional[MLInferenceAPI] = None,
        config: Optional[Dict[str, Any]] = None,
    ):
        super().__init__(
            "SynthesisPlannerAgent",
            blackboard,
            context,
            validator,
            ml_registry=ml_registry,
            dataset_manager=dataset_manager,
            feature_extractor=feature_extractor,
            active_learning=active_learning,
            ml_api=ml_api,
            config=config,
        )
        self.llm = llm 
 
    async def run(
        self,
        context_override: Optional[QuantumContext] = None,
        ligand_report: Optional[Dict[str, Any]] = None,
        quantum_report: Optional[Dict[str, Any]] = None,
        action_vector: Optional[Dict[str, float]] = None,
    ) -> Dict[str, Any]:
        actions = self._prepare_action_vector(action_vector)
        aggressiveness = float(actions.get("retrosynthesis_aggressiveness", 1.0))
        quantum_payload = quantum_report or await self.blackboard.read("quantum")
        report_payload = ligand_report or await self.blackboard.read("ProposedLigands")
        if not report_payload:
            report_payload = await self.blackboard.read("ligands")
        candidate_pool = (report_payload or {}).get("generatedLigands") or (report_payload or {}).get("finalLigands") or []
        ligand_lambda = candidate_pool[0].get("lambdaShellDiagnostics") if candidate_pool else None
        if ligand_lambda is None and quantum_payload and quantum_payload.get("best", {}).get("lambdaShellDiagnostics"):
            ligand_lambda = quantum_payload["best"].get("lambdaShellDiagnostics")
        context_in_use = context_override or self.context
        prompt = textwrap.dedent(
            """
            Provide a concise lambda-aware synthesis outline balancing novelty with practical chemistry.
            Emphasize solvent and catalyst choices compatible with inverse-designed ligands.
            """
        )
        plan_text = self.llm.complete(prompt)
@@ -4688,77 +4773,77 @@ class SynthesisPlannerAgent(AgentBase):
            )
            combined_vec = self.feature_extractor.combine_features(feature_vec, lambda_feat)
            combined_vec = self.feature_extractor.combine_features(combined_vec, lambda_latent.flatten())
            combined_vec = np.asarray(combined_vec, dtype=float).flatten()
            target_dim = 64
            if combined_vec.size < target_dim:
                combined_vec = np.pad(combined_vec, (0, target_dim - combined_vec.size))
            else:
                combined_vec = combined_vec[:target_dim]
            task_name = "synthesis.successProbability"
            existing = self.dataset_manager.records.get(task_name, [])
            for record in existing:
                vec = np.asarray(record["features"], dtype=float).flatten()
                if vec.size < target_dim:
                    vec = np.pad(vec, (0, target_dim - vec.size))
                elif vec.size > target_dim:
                    vec = vec[:target_dim]
                record["features"] = vec
            label = 1.0 if not flags else 0.5
            self.dataset_manager.register_record(
                task_name,
                combined_vec,
                label,
                {"ligandId": primary_ligand_id, "source": "synthesis_agent"},
            )
            split = self.dataset_manager.build_split(task_name) 
            model = self.ml_registry.get_model(task_name) 
            if model is None and split.train_X.size: 
                model = SimpleClassifier(f"{task_name}-clf", architecture="GradientBoostingProxy") 
                metrics = model.train(split) 
                self.ml_registry.register_model(task_name, model, metrics, split.metadata) 
                training_record = lambda_shell_training_hook( 
                    self.name, 
                    self.context, 
                    ligand_lambda or {"descriptors": self.context.lambda_shells}, 
                ) 
                self.observation_state.setdefault("trainingLogs", []).append(training_record) 
            if model: 
                normalization = split.normalization if split else {"mean": np.zeros_like(combined_vec), "std": np.ones_like(combined_vec)} 
                norm_vec = ( 
                    (combined_vec - normalization["mean"]) / normalization["std"] 
                    if isinstance(normalization, dict) 
                    else combined_vec 
                ) 
                probs, uncert = model.predict_with_uncertainty(norm_vec.reshape(1, -1)) 
                ml_section = { 
                    "successProbability": float(probs[0]), 
                    "uncertainty": float(uncert[0]), 
                    "model": model.describe(), 
                    "dataset": split.metadata if split else {"records": 0}, 
                } 
                report["mlAugmentation"] = ml_section 
                if self.active_learning:
                    self.active_learning.evaluate_samples(
                        task_name,
                        [feature_vec],
                        probs,
                        uncert,
                        [{"ligandId": primary_ligand_id}],
                    )
                if self.ml_api:
                    self.ml_api.register_endpoint("synthesis/success", task_name, model.version)
                    self.ml_api.log_call(
                        "synthesis/success",
                        {"ligandId": primary_ligand_id},
                        {"successProbability": ml_section["successProbability"]},
                    )
        pretrained_meta: Dict[str, Any] = {}
        synthesis_model = self.ml_models.get("synthesis")
        synthesis_identifier = " ".join(plan)
        if synthesis_model:
            pretrained_meta["synthesis"] = synthesis_model.describe()
            score = synthesis_model.score(synthesis_identifier)
        else:
            self._log_ml_fallback("synthesis")
            score = self._heuristic_model_score("synthesis", synthesis_identifier)
        report.setdefault("feasibilityAssessment", {})["pretrainedSynthesisScore"] = float(np.clip(score, 0.0, 1.0))
@@ -4785,84 +4870,84 @@ class SynthesisPlannerAgent(AgentBase):
            k_c=0.2,
            k_b=0.1,
        )
        Q_synth = 0.6 * R_synth + 0.2 * R_safety + 0.2 * R_comp
        R_dd = RewardPrimitives.R_dd(Q_synth, baseline["max_quality"], lambda_dd=0.2)
        R_stag = RewardPrimitives.R_stagnation(
            Q_synth,
            baseline["prev_quality"],
            entropy_mean,
            baseline["prev_entropy"],
            energy_signal,
            baseline["prev_energy"],
            lambda_stag=0.2,
        )
        validator = primitives.get("validatorDiagnostics", {})
        R_val = RewardPrimitives.R_validator(
            int(validator.get("adjustmentCount", 0)),
            float(validator.get("meanClampDistance", 0.0)),
            lambda_adj=0.05,
            lambda_clamp=0.02,
        )
        total = float(Q_synth + R_dd + R_stag + R_val)
        self._record_quality(Q_synth, entropy_mean, energy_signal)
        self.reward_history.append(total)
        return total
 
 
class ScreeningAgent(AgentBase):
    ACTION_SPACE = {
        "hit_threshold": (0.5, 0.95),
        "borderline_exploration": (0.0, 1.0),
    }
    def __init__( 
        self, 
        blackboard: QuantumBlackboard, 
        context: QuantumContext, 
        validator: PhysicalValidator, 
        quantum_reference: Dict[str, Any], 
        ml_registry: Optional[MLModelRegistry] = None, 
        dataset_manager: Optional[DatasetManager] = None, 
        feature_extractor: Optional[FeatureExtractor] = None,
        active_learning: Optional[ActiveLearningCoordinator] = None,
        ml_api: Optional[MLInferenceAPI] = None,
        config: Optional[Dict[str, Any]] = None,
    ):
        super().__init__(
            "ScreeningAgent",
            blackboard,
            context,
            validator,
            ml_registry=ml_registry,
            dataset_manager=dataset_manager,
            feature_extractor=feature_extractor,
            active_learning=active_learning,
            ml_api=ml_api,
            config=config,
        )
        self.quantum_reference = quantum_reference 
 
    async def run(
        self,
        context_override: Optional[QuantumContext] = None,
        ligand_report: Optional[Dict[str, Any]] = None,
        quantum_report: Optional[Dict[str, Any]] = None,
        synthesis_report: Optional[Dict[str, Any]] = None,
        action_vector: Optional[Dict[str, float]] = None,
    ) -> Dict[str, Any]:
        actions = self._prepare_action_vector(action_vector)
        hit_threshold = float(actions.get("hit_threshold", 0.8))
        borderline_exploration = float(actions.get("borderline_exploration", 0.5))
        quantum_payload = quantum_report or await self.blackboard.read("quantum")
        report_payload = ligand_report or await self.blackboard.read("ProposedLigands")
        if not report_payload:
            report_payload = await self.blackboard.read("ligands")
        ligand_id = "lig-novel-001"
        ligand_lambda = None
        candidate_pool = (report_payload or {}).get("generatedLigands") or (report_payload or {}).get("finalLigands") or []
        implausible_set = set((synthesis_report or {}).get("implausibleLigands", []))
        filtered_candidates = [cand for cand in candidate_pool if cand.get("ligandId") not in implausible_set]
        working_pool = filtered_candidates or candidate_pool
        if working_pool:
            ligand_id = working_pool[0].get("ligandId", ligand_id)
            ligand_lambda = working_pool[0].get("lambdaShellDiagnostics")
        if ligand_lambda is None and quantum_payload and quantum_payload.get("best", {}).get("lambdaShellDiagnostics"):
@@ -4879,106 +4964,106 @@ class ScreeningAgent(AgentBase):
                {"hitId": "ZINC12345", "matchingScore": float(np.clip(0.85 + 0.05 * random.random(), 0.0, 1.0))},
                {"hitId": "ZINC98765", "matchingScore": float(np.clip(0.82 + 0.05 * random.random(), 0.0, 1.0))},
            ],
            "pharmacophoreTrendAnalysis": {
                "meanEntanglementEntropy": trend,
                "trendRationale": "Derived from quantum-generated pose libraries to extend beyond primary screening.",
            },
            "lambdaLatentTensor": lambda_latent.tolist(),
        }
        if implausible_set:
            report["consistencyChecks"] = {"filteredImplausible": sorted(implausible_set)}
        hits = sorted(report["topHits"], key=lambda hit: hit["matchingScore"], reverse=True)
        filtered_hits = [hit for hit in hits if hit["matchingScore"] >= hit_threshold]
        if not filtered_hits:
            borderline_count = max(1, int(math.ceil(borderline_exploration * len(hits)))) if hits else 0
            filtered_hits = hits[:borderline_count] if hits else []
        report["topHits"] = filtered_hits or hits
        if ligand_lambda:
            report["lambdaShellAlignment"] = {
                "descriptors": ligand_lambda.get("descriptors", []),
                "summary": ligand_lambda.get("summary", {}),
            }
        if self.feature_extractor and self.dataset_manager and self.ml_registry:
            task_name = "screening.matchingScore"
            features = []
            metadata_bundle = [] 
            for hit in report["topHits"]: 
                lambda_feat = self.feature_extractor.featurize_lambda_shells( 
                    (ligand_lambda or {}).get("descriptors", []) 
                ) 
                base_vec = np.array([hit["matchingScore"], trend, self.context.enhancement_factor], dtype=float) 
                feature_vec = self.feature_extractor.combine_features(base_vec, lambda_feat) 
                feature_vec = self.feature_extractor.combine_features(feature_vec, lambda_latent.flatten()) 
                features.append(feature_vec) 
                metadata = {"hitId": hit["hitId"], "ligandId": ligand_id} 
                metadata_bundle.append(metadata) 
                self.dataset_manager.register_record( 
                    task_name, 
                    feature_vec, 
                    hit["matchingScore"], 
                    {**metadata, "source": "screening_agent"}, 
                ) 
            split = self.dataset_manager.build_split(task_name) 
            model = self.ml_registry.get_model(task_name) 
            if model is None and split.train_X.size: 
                model = SimpleRegressor(f"{task_name}-reg", architecture="RandomForestProxy") 
                metrics = model.train(split) 
                self.ml_registry.register_model(task_name, model, metrics, split.metadata) 
                training_record = lambda_shell_training_hook( 
                    self.name, 
                    self.context, 
                    ligand_lambda or {"descriptors": self.context.lambda_shells}, 
                ) 
                self.observation_state.setdefault("trainingLogs", []).append(training_record) 
            ml_section: Dict[str, Any] = {} 
            if model and features: 
                normalization = split.normalization if split else {"mean": np.zeros_like(features[0]), "std": np.ones_like(features[0])} 
                stacked = np.stack(features) 
                norm_features = ( 
                    (stacked - normalization["mean"]) / normalization["std"] 
                    if isinstance(normalization, dict) 
                    else stacked 
                ) 
                preds, uncert = model.predict_with_uncertainty(norm_features) 
                ml_section = { 
                    "model": model.describe(), 
                    "predictions": [ 
                        { 
                            "hitId": meta["hitId"], 
                            "score": float(pred), 
                            "uncertainty": float(u), 
                        } 
                        for meta, pred, u in zip(metadata_bundle, preds, uncert) 
                    ], 
                    "dataset": split.metadata if split else {"records": 0}, 
                } 
                report["mlAugmentation"] = ml_section 
                if self.active_learning: 
                    self.active_learning.evaluate_samples(task_name, features, preds, uncert, metadata_bundle) 
                if self.ml_api: 
                    self.ml_api.register_endpoint("screening/matching", task_name, model.version) 
                    self.ml_api.log_call(
                        "screening/matching",
                        {"ligandId": ligand_id},
                        {"predictions": ml_section["predictions"]},
                    )
        pretrained_meta: Dict[str, Any] = {}
        affinity_model = self.ml_models.get("affinity")
        if affinity_model:
            pretrained_meta["affinity"] = affinity_model.describe()
            for hit in report["topHits"]:
                identifier = f"{ligand_id}:{hit['hitId']}"
                score = affinity_model.score(identifier)
                hit["mlAffinityScore"] = float(-4.0 - 4.0 * score)
        else:
            if report["topHits"]:
                self._log_ml_fallback("affinity")
            for hit in report["topHits"]:
                identifier = f"{ligand_id}:{hit['hitId']}"
                score = self._heuristic_model_score("affinity", identifier)
                hit["mlAffinityScore"] = float(-4.0 - 4.0 * score)
        if pretrained_meta:
            report.setdefault("mlAugmentation", {}).setdefault("pretrainedModels", {}).update(pretrained_meta)
        validated = self.validator.validate(self.name, report)
        await self.blackboard.post("screening", validated)
        return validated
@@ -5016,105 +5101,105 @@ class ScreeningAgent(AgentBase):
            + 0.2 * R_accept
            + 0.05 * R_div
            + 0.05 * R_comp
        )
        R_dd = RewardPrimitives.R_dd(Q_screen, baseline["max_quality"], lambda_dd=0.3)
        R_stag = RewardPrimitives.R_stagnation(
            Q_screen,
            baseline["prev_quality"],
            entropy_mean,
            baseline["prev_entropy"],
            energy_signal,
            baseline["prev_energy"],
            lambda_stag=0.3,
        )
        validator = primitives.get("validatorDiagnostics", {})
        R_val = RewardPrimitives.R_validator(
            int(validator.get("adjustmentCount", 0)),
            float(validator.get("meanClampDistance", 0.0)),
            lambda_adj=0.05,
            lambda_clamp=0.02,
        )
        total = float(Q_screen + R_dd + R_stag + R_val)
        self._record_quality(Q_screen, entropy_mean, energy_signal)
        self.reward_history.append(total)
        return total
 
 
class SafetyAgent(AgentBase):
    ACTION_SPACE = {
        "toxicity_weight": (0.5, 2.0),
        "uncertainty_tradeoff": (0.0, 1.0),
    }
    def __init__( 
        self, 
        blackboard: QuantumBlackboard, 
        context: QuantumContext, 
        validator: PhysicalValidator, 
        quantum_reference: Dict[str, Any], 
        ml_registry: Optional[MLModelRegistry] = None, 
        dataset_manager: Optional[DatasetManager] = None, 
        feature_extractor: Optional[FeatureExtractor] = None,
        active_learning: Optional[ActiveLearningCoordinator] = None,
        ml_api: Optional[MLInferenceAPI] = None,
        config: Optional[Dict[str, Any]] = None,
    ):
        super().__init__(
            "SafetyAgent",
            blackboard,
            context,
            validator,
            ml_registry=ml_registry,
            dataset_manager=dataset_manager,
            feature_extractor=feature_extractor,
            active_learning=active_learning,
            ml_api=ml_api,
            config=config,
        )
        self.quantum_reference = quantum_reference 
 
    def detect_lambda_anomalies(self, ligand_embedding: np.ndarray) -> Dict[str, Any]: 
        reference_tensor = self.encode_lambda_latent({"descriptors": self.context.lambda_shells}) 
        reference_vector = reference_tensor.flatten() 
        ligand_vector = ligand_embedding.flatten() if ligand_embedding.size else np.zeros_like(reference_vector) 
        ref_abs = np.abs(reference_vector) + 1e-9 
        ligand_abs = np.abs(ligand_vector) + 1e-9 
        ref_prob = ref_abs / np.sum(ref_abs) 
        ligand_prob = ligand_abs / np.sum(ligand_abs) 
        kl_divergence = float(np.sum(ligand_prob * np.log(ligand_prob / ref_prob))) 
        shell_jump = float(np.max(np.abs(np.diff(ligand_prob)))) if ligand_prob.size > 1 else 0.0 
        anomaly_flag = bool(kl_divergence > 0.5 or shell_jump > 0.3) 
        record = { 
            "klDivergence": kl_divergence, 
            "maxShellJump": shell_jump, 
            "flagged": anomaly_flag, 
        } 
        self.observation_state["lambdaLatentTensor"] = ligand_embedding 
        self.observation_state["lambdaLatentVector"] = ligand_vector 
        self.observation_state.setdefault("lambdaSafetyDiagnostics", []).append(record) 
        return record 
 
    async def run(
        self,
        context_override: Optional[QuantumContext] = None,
        ligand_report: Optional[Dict[str, Any]] = None,
        screening_report: Optional[Dict[str, Any]] = None,
        synthesis_report: Optional[Dict[str, Any]] = None,
        action_vector: Optional[Dict[str, float]] = None,
    ) -> Dict[str, Any]:
        actions = self._prepare_action_vector(action_vector)
        toxicity_weight = float(actions.get("toxicity_weight", 1.0))
        uncertainty_tradeoff = float(actions.get("uncertainty_tradeoff", 0.5))
        report_payload = ligand_report or await self.blackboard.read("ProposedLigands")
        if not report_payload:
            report_payload = await self.blackboard.read("ligands")
        candidate_pool = (report_payload or {}).get("generatedLigands") or (report_payload or {}).get("finalLigands") or []
        context_in_use = context_override or self.context
        entropy_values = [sample["entanglementEntropy"] for sample in self.quantum_reference.get("samples", [])]
        variability = float(np.std(entropy_values)) if entropy_values else 0.1
        variability *= 1.0 + 0.3 * (uncertainty_tradeoff - 0.5)
        binding_lookup = {}
        steps_lookup = {}
        for route in (synthesis_report or {}).get("perLigandRoutes", []):
            binding_lookup[route.get("ligandId")] = route.get("bindingFreeEnergy")
            steps_lookup[route.get("ligandId")] = route.get("syntheticSteps")
        default_lambda = {"descriptors": context_in_use.lambda_shells}
@@ -5222,77 +5307,77 @@ class SafetyAgent(AgentBase):
            if self.feature_extractor:
                feature_vec = self.feature_extractor.combine_features(
                    feature_vec, np.asarray(primary["lambdaLatentTensor"], dtype=float).flatten()
                )
            feature_vec = np.asarray(feature_vec, dtype=float).flatten()
            safety_dim = 32
            if feature_vec.size < safety_dim:
                feature_vec = np.pad(feature_vec, (0, safety_dim - feature_vec.size))
            else:
                feature_vec = feature_vec[:safety_dim]
            existing = self.dataset_manager.records.get(task_name, [])
            for record in existing:
                vec = np.asarray(record["features"], dtype=float).flatten()
                if vec.size < safety_dim:
                    vec = np.pad(vec, (0, safety_dim - vec.size))
                elif vec.size > safety_dim:
                    vec = vec[:safety_dim]
                record["features"] = vec
            label = 1.0 if "PAINS" in admet_report["alerts"] else 0.0
            self.dataset_manager.register_record(
                task_name,
                feature_vec,
                label,
                {"ligandId": primary["ligandId"], "source": "safety_agent"},
            )
            split = self.dataset_manager.build_split(task_name) 
            model = self.ml_registry.get_model(task_name) 
            if model is None and split.train_X.size: 
                model = SimpleClassifier(f"{task_name}-clf", architecture="DeepNNProxy") 
                metrics = model.train(split) 
                self.ml_registry.register_model(task_name, model, metrics, split.metadata) 
                training_lambda = admet_report.get("lambdaShellDiagnostics") or default_lambda
                training_record = lambda_shell_training_hook(
                    self.name,
                    self.context,
                    training_lambda,
                )
                self.observation_state.setdefault("trainingLogs", []).append(training_record) 
            if model: 
                normalization = split.normalization if split else {"mean": np.zeros_like(feature_vec), "std": np.ones_like(feature_vec)} 
                norm_vec = ( 
                    (feature_vec - normalization["mean"]) / normalization["std"] 
                    if isinstance(normalization, dict) 
                    else feature_vec 
                ) 
                probs, uncert = model.predict_with_uncertainty(norm_vec.reshape(1, -1)) 
                ml_section = { 
                    "toxicityProbability": float(probs[0]), 
                    "uncertainty": float(uncert[0]), 
                    "model": model.describe(), 
                    "dataset": split.metadata if split else {"records": 0}, 
                } 
                if self.active_learning:
                    self.active_learning.evaluate_samples(
                        task_name,
                        [feature_vec],
                        probs,
                        uncert,
                        [{"ligandId": primary["ligandId"]}],
                    )
                if self.ml_api:
                    self.ml_api.register_endpoint("safety/toxicity", task_name, model.version)
                    self.ml_api.log_call(
                        "safety/toxicity",
                        {"ligandId": primary["ligandId"]},
                        {"toxicityProbability": ml_section.get("toxicityProbability")},
                    )
        if pretrained_meta:
            ml_section.setdefault("pretrainedModels", {}).update(pretrained_meta)
        payload = {
            "admet": admet_report,
            "offTarget": off_target_report,
            "mlAugmentation": ml_section,
            "perLigandAssessments": per_assessments,
        }
        skepticism_ids = [entry["ligandId"] for entry in per_assessments if entry["skepticismFlag"]]
        if skepticism_ids:
@@ -5317,86 +5402,86 @@ class SafetyAgent(AgentBase):
            k_c=0.15,
            k_b=0.1,
        )
        Q_safety = 0.6 * R_safety + 0.2 * R_screen + 0.2 * R_comp
        R_dd = RewardPrimitives.R_dd(Q_safety, baseline["max_quality"], lambda_dd=0.2)
        R_stag = RewardPrimitives.R_stagnation(
            Q_safety,
            baseline["prev_quality"],
            entropy_mean,
            baseline["prev_entropy"],
            energy_signal,
            baseline["prev_energy"],
            lambda_stag=0.3,
        )
        validator = primitives.get("validatorDiagnostics", {})
        R_val = RewardPrimitives.R_validator(
            int(validator.get("adjustmentCount", 0)),
            float(validator.get("meanClampDistance", 0.0)),
            lambda_adj=0.05,
            lambda_clamp=0.02,
        )
        total = float(Q_safety + R_dd + R_stag + R_val)
        self._record_quality(Q_safety, entropy_mean, energy_signal)
        self.reward_history.append(total)
        return total
 
 
class IPAgent(AgentBase):
    ACTION_SPACE = {
        "novelty_weight": (0.0, 1.0),
        "prior_art_bias": (0.0, 1.0),
    }
    def __init__( 
        self, 
        blackboard: QuantumBlackboard, 
        context: QuantumContext, 
        validator: PhysicalValidator, 
        data_client: PublicDataClient, 
        query: str, 
        ml_registry: Optional[MLModelRegistry] = None, 
        dataset_manager: Optional[DatasetManager] = None, 
        feature_extractor: Optional[FeatureExtractor] = None,
        active_learning: Optional[ActiveLearningCoordinator] = None,
        ml_api: Optional[MLInferenceAPI] = None,
        config: Optional[Dict[str, Any]] = None,
    ):
        super().__init__(
            "IPAgent",
            blackboard,
            context,
            validator,
            ml_registry=ml_registry,
            dataset_manager=dataset_manager,
            feature_extractor=feature_extractor,
            active_learning=active_learning,
            ml_api=ml_api,
            config=config,
        )
        self.data_client = data_client 
        self.query = query 
 
    async def run(
        self,
        context_override: Optional[QuantumContext] = None,
        ligand_report: Optional[Dict[str, Any]] = None,
        screening_report: Optional[Dict[str, Any]] = None,
        synthesis_report: Optional[Dict[str, Any]] = None,
        action_vector: Optional[Dict[str, float]] = None,
    ) -> Dict[str, Any]:
        actions = self._prepare_action_vector(action_vector)
        novelty_weight = float(actions.get("novelty_weight", 0.5))
        prior_art_bias = float(actions.get("prior_art_bias", 0.5))
        report_payload = ligand_report or await self.blackboard.read("ProposedLigands")
        if not report_payload:
            report_payload = await self.blackboard.read("ligands")
        candidate_pool = (report_payload or {}).get("generatedLigands") or (report_payload or {}).get("finalLigands") or []
        ligand_id = candidate_pool[0].get("ligandId", "lig-novel-001") if candidate_pool else "lig-novel-001"
        ligand_lambda = candidate_pool[0].get("lambdaShellDiagnostics") if candidate_pool else None
        context_in_use = context_override or self.context
        if ligand_lambda is None and screening_report and screening_report.get("lambdaShellAlignment"):
            ligand_lambda = screening_report["lambdaShellAlignment"]
        steps_lookup = {route.get("ligandId"): route.get("syntheticSteps") for route in (synthesis_report or {}).get("perLigandRoutes", [])}
        novelty_lookup = {route.get("ligandId"): route.get("noveltyScore") for route in (synthesis_report or {}).get("perLigandRoutes", [])}
        hits = self.data_client.fetch_patent_hits(self.query)
        lambda_latent = self.encode_lambda_latent(ligand_lambda or {"descriptors": context_in_use.lambda_shells})
        synthetic_steps = steps_lookup.get(ligand_id, 2)
@@ -5410,103 +5495,103 @@ class IPAgent(AgentBase):
            "generativeGraphCrosslinks": [
                {
                    "graphId": "gen-graph-001",
                    "description": "Quantum-derived scaffold library cross-linked with WIPO dataset",
                }
            ],
            "lambdaLatentTensor": lambda_latent.tolist(),
        }
        novelty_metric = novelty_score * (0.5 + novelty_weight)
        report["noveltyAssessment"] = "High" if novelty_metric > 0.6 else "Moderate"
        freedom_score = float(np.clip(1.0 - novelty_metric + 0.3 * prior_art_bias, 0.0, 1.0))
        report["freedomToOperateRiskScore"] = freedom_score
        report["freedomToOperateRisk"] = "Elevated" if freedom_score > 0.6 else "Low"
        report["consistencyChecks"] = {
            "syntheticSteps": synthetic_steps,
            "noveltyScore": novelty_score,
            "noveltyWeight": novelty_weight,
        }
        if ligand_lambda:
            report["lambdaShellDiagnostics"] = ligand_lambda
        if self.dataset_manager and self.ml_registry:
            task_name = "ip.novelty"
            lambda_feat = self.feature_extractor.featurize_lambda_shells(
                (ligand_lambda or {}).get("descriptors", [])
            ) if self.feature_extractor else np.zeros(7)
            base_vec = np.array( 
                [len(hits), self.context.enhancement_factor, len(report["generativeGraphCrosslinks"])], 
                dtype=float, 
            ) 
            feature_vec = ( 
                self.feature_extractor.combine_features(base_vec, lambda_feat) 
                if self.feature_extractor 
                else base_vec 
            ) 
            if self.feature_extractor: 
                feature_vec = self.feature_extractor.combine_features(feature_vec, lambda_latent.flatten()) 
            label = 1.0 if report["noveltyAssessment"] == "High" else 0.5 
            self.dataset_manager.register_record( 
                task_name, 
                feature_vec, 
                label, 
                {"ligandId": ligand_id, "source": "ip_agent"},
            ) 
            split = self.dataset_manager.build_split(task_name) 
            model = self.ml_registry.get_model(task_name) 
            if model is None and split.train_X.size: 
                model = SimpleRegressor(f"{task_name}-reg", architecture="XGBoostProxy") 
                metrics = model.train(split) 
                self.ml_registry.register_model(task_name, model, metrics, split.metadata) 
                training_record = lambda_shell_training_hook( 
                    self.name, 
                    self.context, 
                    ligand_lambda or {"descriptors": self.context.lambda_shells}, 
                ) 
                self.observation_state.setdefault("trainingLogs", []).append(training_record) 
            if model: 
                normalization = split.normalization if split else {"mean": np.zeros_like(feature_vec), "std": np.ones_like(feature_vec)} 
                norm_vec = ( 
                    (feature_vec - normalization["mean"]) / normalization["std"] 
                    if isinstance(normalization, dict) 
                    else feature_vec 
                ) 
                preds, uncert = model.predict_with_uncertainty(norm_vec.reshape(1, -1)) 
                ml_section = { 
                    "model": model.describe(), 
                    "noveltyScore": float(preds[0]), 
                    "uncertainty": float(uncert[0]), 
                    "dataset": split.metadata if split else {"records": 0}, 
                } 
                report["mlAugmentation"] = ml_section 
                if self.active_learning: 
                    self.active_learning.evaluate_samples( 
                        task_name, 
                        [feature_vec], 
                        preds, 
                        uncert, 
                        [{"ligandId": ligand_id}], 
                    ) 
                if self.ml_api:
                    self.ml_api.register_endpoint("ip/novelty", task_name, model.version)
                    self.ml_api.log_call(
                        "ip/novelty",
                        {"ligandId": ligand_id},
                        {"noveltyScore": ml_section["noveltyScore"]},
                    )
        pretrained_meta: Dict[str, Any] = {}
        affinity_model = self.ml_models.get("affinity")
        if affinity_model:
            pretrained_meta["affinity"] = affinity_model.describe()
            risk_score = affinity_model.score(ligand_id)
        else:
            self._log_ml_fallback("affinity")
            risk_score = self._heuristic_model_score("affinity", ligand_id)
        report["freedomToOperateRiskScore"] = float(np.clip(1.0 - risk_score, 0.0, 1.0))
        if synthetic_steps <= 2 and novelty_score > 0.8:
            report.setdefault("flags", []).append(
                {
                    "type": "Skepticism",
                    "message": "Highly novel ligand with trivial synthesis flagged for IP review",
                }
            )
        if pretrained_meta:
            report.setdefault("mlAugmentation", {}).setdefault("pretrainedModels", {}).update(pretrained_meta)
@@ -5537,492 +5622,692 @@ class IPAgent(AgentBase):
            k_c=0.2,
            k_b=0.1,
        )
        Q_ip = 0.5 * R_ip + 0.15 * R_bind + 0.15 * R_safety + 0.10 * R_synth + 0.10 * R_comp
        R_dd = RewardPrimitives.R_dd(Q_ip, baseline["max_quality"], lambda_dd=0.2)
        R_stag = RewardPrimitives.R_stagnation(
            Q_ip,
            baseline["prev_quality"],
            entropy_mean,
            baseline["prev_entropy"],
            energy_signal,
            baseline["prev_energy"],
            lambda_stag=0.3,
        )
        validator = primitives.get("validatorDiagnostics", {})
        R_val = RewardPrimitives.R_validator(
            int(validator.get("adjustmentCount", 0)),
            float(validator.get("meanClampDistance", 0.0)),
            lambda_adj=0.05,
            lambda_clamp=0.02,
        )
        total = float(Q_ip + R_dd + R_stag + R_val)
        self._record_quality(Q_ip, entropy_mean, energy_signal)
        self.reward_history.append(total)
        return total
 
 
class JobStatusAgent(AgentBase): 
    def __init__( 
        self, 
        blackboard: QuantumBlackboard, 
        context: QuantumContext, 
        validator: PhysicalValidator, 
        ml_registry: Optional[MLModelRegistry] = None, 
        dataset_manager: Optional[DatasetManager] = None, 
        feature_extractor: Optional[FeatureExtractor] = None, 
        active_learning: Optional[ActiveLearningCoordinator] = None, 
        ml_api: Optional[MLInferenceAPI] = None, 
    ): 
        super().__init__( 
            "JobStatusAgent", 
            blackboard, 
            context, 
            validator, 
            ml_registry=ml_registry, 
            dataset_manager=dataset_manager, 
            feature_extractor=feature_extractor, 
            active_learning=active_learning, 
            ml_api=ml_api, 
        ) 
 
    async def run(
        self,
        context_override: Optional[QuantumContext] = None,
        ligand_report: Optional[Dict[str, Any]] = None,
        quantum_report: Optional[Dict[str, Any]] = None,
        synthesis_report: Optional[Dict[str, Any]] = None,
        screening_report: Optional[Dict[str, Any]] = None,
        safety_report: Optional[Dict[str, Any]] = None,
        ip_report: Optional[Dict[str, Any]] = None,
        action_vector: Optional[Dict[str, float]] = None,
    ) -> Dict[str, Any]:
        context_in_use = context_override or self.context
        report = {
            "jobId": "qm-sim-job-1",
            "status": "COMPLETED",
            "resourceUtilization": {
                "simulationTime": "1800s",
                "quantumCircuitFidelity": float(np.clip(0.998 + 0.001 * random.random(), 0.0, 1.0)),
                "lambdaEnhancement": context_in_use.enhancement_factor,
            },
            "retrainMetrics": {
                "datasetsConsumed": 3,
                "lastRetrain": "scheduled",
            },
            "lambdaScaling": {
                "basis": context_in_use.lambda_basis,
                "shellDescriptors": context_in_use.lambda_shells,
            },
        }
        report["generationSummary"] = {
            "ligandCount": len((ligand_report or {}).get("generatedLigands", [])),
            "implausible": len((synthesis_report or {}).get("implausibleLigands", [])),
        }
        if self.dataset_manager and self.ml_registry:
            task_name = "operations.runtime"
            simulation_seconds = 1800.0
            feature_vec = np.array(
                [
                    simulation_seconds,
                    report["resourceUtilization"]["quantumCircuitFidelity"],
                    report["resourceUtilization"]["lambdaEnhancement"],
                    context_in_use.entanglement_entropy,
                ],
                dtype=float,
            )
            self.dataset_manager.register_record( 
                task_name, 
                feature_vec, 
                simulation_seconds, 
                {"jobId": report["jobId"], "source": "status_agent"}, 
            ) 
            split = self.dataset_manager.build_split(task_name) 
            model = self.ml_registry.get_model(task_name) 
            if model is None and split.train_X.size: 
                model = SimpleRegressor(f"{task_name}-reg", architecture="TemporalCNNProxy") 
                metrics = model.train(split) 
                self.ml_registry.register_model(task_name, model, metrics, split.metadata) 
                training_record = lambda_shell_training_hook( 
                    self.name, 
                    self.context, 
                    {"descriptors": self.context.lambda_shells}, 
                ) 
                self.observation_state.setdefault("trainingLogs", []).append(training_record) 
            if model: 
                normalization = split.normalization if split else {"mean": np.zeros_like(feature_vec), "std": np.ones_like(feature_vec)} 
                norm_vec = ( 
                    (feature_vec - normalization["mean"]) / normalization["std"] 
                    if isinstance(normalization, dict) 
                    else feature_vec 
                ) 
                preds, uncert = model.predict_with_uncertainty(norm_vec.reshape(1, -1)) 
                ml_section = { 
                    "model": model.describe(), 
                    "runtimeForecast": float(preds[0]), 
                    "uncertainty": float(uncert[0]), 
                    "dataset": split.metadata if split else {"records": 0}, 
                } 
                report["mlAugmentation"] = ml_section 
                if self.active_learning:
                    self.active_learning.evaluate_samples(
                        task_name,
                        [feature_vec],
                        preds,
                        uncert,
                        [{"jobId": report["jobId"]}],
                    )
                if self.ml_api:
                    self.ml_api.register_endpoint("operations/runtime", task_name, model.version)
                    self.ml_api.log_call(
                        "operations/runtime",
                        {"jobId": report["jobId"]}, 
                        {"runtimeForecast": ml_section["runtimeForecast"]}, 
                    ) 
        validated = self.validator.validate(self.name, report) 
        await self.blackboard.post("status", validated) 
        return validated 
 
 
# --------------------------------------------------------------------------- 
# Orchestration layer built on Golden Turing AI 
# --------------------------------------------------------------------------- 
 
 
class DrugDiscoverySimulation: 
    def __init__( 
        self, 
        pdb_id: str, 
        target_query: str, 
        uniprot_accession: str, 
        llm_model_path: Path, 
        random_seed: int = DEFAULT_RANDOM_SEED, 
    ) -> None: 
        self.pdb_id = pdb_id 
        self.target_query = target_query 
        self.uniprot_accession = uniprot_accession 
        self.llm_model_path = llm_model_path 
        self.random_seed = random_seed 
        set_global_random_seed(self.random_seed) 
        self.data_client = PublicDataClient() 
        self.geometry = GeometryParams() 
        self.field = FieldParams() 
        self.ent_params = EntanglementParams() 
        self.quantum_engine = QuantumPhysicsEngine(self.geometry, self.field, self.ent_params) 
        self.context = self.quantum_engine.compute_quantum_context() 
        self.blackboard = QuantumBlackboard() 
        self.llm = LightweightLLM(llm_model_path) 
        self.GoldenTuringAI = load_golden_turing_ai() 
        self.core_ai = self.GoldenTuringAI(config={"ai_state_dim": 64}) 
        self.core_ai.inject_blackboard_interface(self.blackboard) 
        self.quantum_circuit_engine = QuantumCircuitEngine(self.context) 
        self.memory_api = QuantumMemoryAPI() 
        seed_ligands = [f"{self.target_query}-seed-{idx}" for idx in range(3)] + ["lig-novel-001"] 
        try: 
            self.quantum_reference = self.quantum_circuit_engine.generate_reference_dataset(seed_ligands) 
        except Exception as exc:  # pragma: no cover - defensive fallback 
            self.quantum_reference = { 
                "samples": [], 
                "statistics": {"energyRange": {"min": -40.0, "max": -2.0}, "meanEnergy": -12.0, "meanEntropy": 0.4}, 
                "error": str(exc), 
            } 
        self.validator = PhysicalValidator(self.context, self.quantum_reference) 
        self.feature_extractor = FeatureExtractor() 
        self.dataset_manager = DatasetManager( 
            self.feature_extractor, 
            random_seed=self.random_seed, 
        ) 
        self.ml_registry = MLModelRegistry()
        self.active_learning = ActiveLearningCoordinator()
        self.ml_api = MLInferenceAPI()
        shared_model_cfg = {
            "affinityModelPath": os.getenv("DDS_AFFINITY_MODEL_PATH"),
            "toxModelPath": os.getenv("DDS_TOX_MODEL_PATH"),
            "synthModelPath": os.getenv("DDS_SYNTH_MODEL_PATH"),
        }
        self.agent_model_configs = {
            "LigandDiscoveryAgent": dict(shared_model_cfg),
            "ScreeningAgent": dict(shared_model_cfg),
            "SafetyAgent": dict(shared_model_cfg),
            "SynthesisPlannerAgent": dict(shared_model_cfg),
            "IPAgent": dict(shared_model_cfg),
        }
        self.quantum_agent_config = {
            "alpha_calibration": 0.3,
            "enable_pm6": True,
            "mmff_pre_screen_threshold": -3.0,
        }
        self.validation_engine = StatisticalValidationEngine(random_seed=self.random_seed)
        self.explainability = ExplainabilityEngine(random_seed=self.random_seed)
        self.baseline_suite = BaselineModelSuite( 
            self.validation_engine, 
            self.explainability, 
            random_seed=self.random_seed, 
        ) 
        self.hyperparameter_optimizer = HyperparameterOptimizer( 
            self.validation_engine, 
            random_seed=self.random_seed, 
        ) 
        self.visualizer = TrainingVisualizationLogger()
        self.cross_validation_results: Dict[str, Any] = {}
        self.benchmark_summary: Dict[str, Any] = {}
        self.baseline_results: Dict[str, Any] = {}
        self.hyperparameter_results: Dict[str, Any] = {}
        self.visualization_artifacts: List[str] = []
        self.gtai_adapter = GoldenTuringDDSAdapter(
            self.core_ai,
            self.blackboard,
            self.validator,
            self.quantum_reference,
            memory_api=self.memory_api,
        )
        self._bootstrap_ml_datasets()
        self.quantum_reports_buffer: List[Dict[str, Any]] = []
        self.agent_action_history: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
        self.per_agent_rewards: Dict[str, List[float]] = defaultdict(list)
        self._lambda_flow_cache: Dict[str, Dict[str, Any]] = {}
        self.gnn_pretrainer: Optional[QuantumPretrainer] = None
        self.orchestration_directives = {
            "physicalRealism": "Enhance physical realism and chemical accuracy using quantum chemistry and ensemble modeling",
            "additionalFunctions": "Extend agents to ligand library generation, combinatorial synthesis, pharmacophore mining, IP audits",
            "quantumData": "Integrate quantum circuit engine outputs for training and constraint enforcement",
        }


    @staticmethod
    def default_verification_configs() -> List[VerificationConfig]:
        return [
            VerificationConfig(
                name="fak1_tip3p_langevin",
                md_config=MDConfig(),
                benchmark_limit=1,
                benchmark_proteins=["FAK1"],
                description="FAK1 inhibitor (PDB 2J0J) with TIP3P water and Langevin thermostat",
            ),
            VerificationConfig(
                name="cdk2_nvt_nose",
                md_config=MDConfig(
                    thermostat="Nose-Hoover",
                    barostat="Parrinello-Rahman",
                    total_time_ns=3.0,
                    cutoff_angstrom=9.0,
                    pme_grid_spacing=1.1,
                ),
                benchmark_limit=2,
                benchmark_proteins=["CDK2"],
                description="CDK2 complex (PDB 2VTA) with tightened cutoffs and extended sampling",
            ),
            VerificationConfig(
                name="mapk14_npt_long",
                md_config=MDConfig(
                    thermostat="Langevin",
                    barostat="MonteCarlo",
                    total_time_ns=5.0,
                    time_step_fs=2.0,
                    constraints="all-bonds",
                ),
                benchmark_limit=3,
                benchmark_proteins=["MAPK14"],
                description="MAPK14/BIRB796 (PDB 1KV1) long NPT run with full bond constraints",
            ),
        ]


    async def run_verification_suite(
        self,
        configs: Optional[Sequence[VerificationConfig]] = None,
        output_filename: str = "verification_suite.json",
        generated_at: Optional[str] = None,
    ) -> Dict[str, Any]:
        configs = list(configs) if configs is not None else self.default_verification_configs()
        output_dir = Path("outputs")
        output_dir.mkdir(parents=True, exist_ok=True)
        reports: List[Dict[str, Any]] = []
        uniprot_meta = self.data_client.fetch_uniprot_metadata(self.uniprot_accession)
        for cfg in configs:
            context_copy = QuantumContext.from_snapshot(self.context.to_snapshot())
            validator = PhysicalValidator(context_copy, self.quantum_reference)
            agent = QuantumSimulationAgent(
                QuantumBlackboard(),
                context_copy,
                validator,
                uniprot_meta,
                self.quantum_reference,
                ml_registry=self.ml_registry,
                dataset_manager=self.dataset_manager,
                feature_extractor=self.feature_extractor,
                active_learning=self.active_learning,
                ml_api=self.ml_api,
                quantum_config={
                    **self.quantum_agent_config,
                    "benchmark_limit": cfg.benchmark_limit,
                    "benchmark_proteins": cfg.benchmark_proteins,
                },
                md_config=cfg.md_config,
            )
            result = await agent.run(context_copy)
            reports.append({"config": asdict(cfg), "result": result})
        suite_report = {
            "generatedAt": (generated_at or datetime.utcnow().isoformat() + "Z"),
            "configs": [asdict(cfg) for cfg in configs],
            "results": reports,
        }
        output_path = output_dir / output_filename
        output_path.write_text(json.dumps(self._sanitize_for_json(suite_report), indent=2))
        return {"report": suite_report, "output": str(output_path)}


    async def run_reproducibility_test(
        self,
        config: Optional[VerificationConfig] = None,
    ) -> Dict[str, Any]:
        """Run the verification suite twice and compare outputs for reproducibility."""


        base_config = config or VerificationConfig(
            name="fak1_repro_langevin",
            md_config=MDConfig(
                thermostat="Langevin",
                barostat="MonteCarlo",
                time_step_fs=2.0,
                total_time_ns=2.0,
                constraints="h-bonds",
                cutoff_angstrom=10.0,
                pme_grid_spacing=1.0,
                solvent_model="TIP3P",
                ion_concentration_molar=0.15,
                temperature_kelvin=300.0,
                pressure_atm=1.0,
            ),
            benchmark_limit=1,
            benchmark_proteins=["FAK1"],
            description="Reproducibility test for FAK1 (PDB 2J0J) using deterministic seeds",
        )
        output_dir = Path("outputs")
        output_dir.mkdir(parents=True, exist_ok=True)
        fixed_timestamp = datetime.utcfromtimestamp(self.random_seed).isoformat() + "Z"


        def _reset_seeds() -> None:
            random.seed(self.random_seed)
            np.random.seed(self.random_seed)


        run_artifacts: List[Dict[str, Any]] = []
        for idx in (1, 2):
            _reset_seeds()
            run_artifacts.append(
                await self.run_verification_suite(
                    [base_config],
                    output_filename=f"verification_suite_run{idx}.json",
                    generated_at=fixed_timestamp,
                )
            )


        first_path = Path(run_artifacts[0]["output"])
        second_path = Path(run_artifacts[1]["output"])
        first_json = json.loads(first_path.read_text())
        second_json = json.loads(second_path.read_text())


        first_dump = json.dumps(first_json, indent=2, sort_keys=True).splitlines()
        second_dump = json.dumps(second_json, indent=2, sort_keys=True).splitlines()
        diff_lines = list(
            difflib.unified_diff(
                first_dump,
                second_dump,
                fromfile=str(first_path.name),
                tofile=str(second_path.name),
                lineterm="",
            )
        )
        diff_path = output_dir / "diff_output.txt"
        diff_path.write_text("\n".join(diff_lines))


        expected_delta_g = -10.564635333531966
        try:
            predicted_delta_g = (
                first_json.get("results", [])[0]
                .get("result", {})
                .get("bindingResults", [{}])[0]
                .get("delta_g_kcal_mol")
            )
        except IndexError:
            predicted_delta_g = None
        residual = None if predicted_delta_g is None else float(predicted_delta_g - expected_delta_g)
        rmse = None if residual is None else math.sqrt(residual ** 2)
        validation_lines = [
            "# Reproducibility Validation Report",
            "",
            "## Summary",
            f"- Deterministic seed: {self.random_seed}",
            f"- JSON outputs identical: {'Yes' if not diff_lines else 'No'}",
            f"- Expected  G (FAK1 literature): {expected_delta_g:.2f} kcal/mol",
            f"- Simulated  G: {predicted_delta_g:.2f} kcal/mol" if predicted_delta_g is not None else "- Simulated  G: unavailable",
            f"- RMSE vs literature: {rmse:.3f} kcal/mol" if rmse is not None else "- RMSE vs literature: unavailable",
            "",
            "## Run Comparisons",
            f"- Run 1: {first_path}",
            f"- Run 2: {second_path}",
            f"- Diff file: {diff_path}",
            "",
            "## Metric Validity",
            "| Metric | Simulated | Literature | Residual | Threshold |",
            "| --- | --- | --- | --- | --- |",
            (
                f"|  G_binding (kcal/mol) | {predicted_delta_g:.2f} | {expected_delta_g:.2f} | {residual:.3f} | =0.20 |"
                if predicted_delta_g is not None and residual is not None
                else "|  G_binding (kcal/mol) | n/a | n/a | n/a | =0.20 |"
            ),
            (
                f"| RMSE (kcal/mol) | {rmse:.3f} | {0.0:.2f} | {rmse:.3f} | =0.20 |"
                if rmse is not None
                else "| RMSE (kcal/mol) | n/a | 0.00 | n/a | =0.20 |"
            ),
            "",
            "## Conclusion",
            "- Reproducible outputs with deterministic seeds and configuration" if not diff_lines else "- Discrepancies detected between runs; investigate non-deterministic components.",
        ]
        validation_report_path = output_dir / "validation_report.md"
        validation_report_path.write_text("\n".join(validation_lines))


        return {
            "runs": [first_json, second_json],
            "diff": str(diff_path),
            "validation_report": str(validation_report_path),
            "residual": residual,
            "rmse": rmse,
            "identical": not diff_lines,
        }


    def _bootstrap_ml_datasets(self) -> None:
        samples = self.quantum_reference.get("samples", [])
        if samples:
            stats = self.quantum_reference.get("statistics", {})
            mean_energy = stats.get("meanEnergy", -8.0)
            for sample in samples:
                quantum_feat = self.feature_extractor.featurize_quantum_sample(sample)
                smiles_feat = self.feature_extractor.featurize_smiles(sample.get("ligandId", ""))
                lambda_feat = self.feature_extractor.featurize_lambda_shells(self.context.lambda_shells)
                combined_feat = self.feature_extractor.combine_features(quantum_feat, smiles_feat, lambda_feat)
                self.dataset_manager.register_record(
                    "quantum.bindingEnergy",
                    combined_feat,
                    sample.get("bindingEnergy", -8.0),
                    {"ligandId": sample.get("ligandId"), "source": "bootstrap"},
                )
                label = 1.0 if sample.get("bindingEnergy", 0.0) < mean_energy else 0.0
                self.dataset_manager.register_record(
                    "quantum.highAffinity",
                    combined_feat,
                    label,
                    {"ligandId": sample.get("ligandId"), "source": "bootstrap"},
                )
                lambda_latent = np.asarray(
                    LambdaScalingToolkit.fingerprint(self.context.lambda_shells),
                    dtype=float,
                )
                ligand_feat = self.feature_extractor.combine_features(smiles_feat, lambda_feat)
                ligand_feat = self.feature_extractor.combine_features(ligand_feat, lambda_latent)
                self.dataset_manager.register_record(
                    "ligand.bindingAffinity",
                    ligand_feat,
                    sample.get("bindingEnergy", -8.0),
                    {"ligandId": sample.get("ligandId"), "source": "bootstrap"},
                )
            binding_split = self.dataset_manager.build_split("quantum.bindingEnergy")
            if binding_split.train_X.size:
                binding_model = GraphSurrogateModel("quantum.bindingEnergy-bootstrap")
                metrics = binding_model.train(binding_split)
                self.ml_registry.register_model("quantum.bindingEnergy", binding_model, metrics, binding_split.metadata)
                self.ml_api.register_endpoint("bootstrap/quantumBinding", "quantum.bindingEnergy", binding_model.version)
                self.validation_engine.log_evaluation("bootstrap.quantum.bindingEnergy", metrics)
                step = len(self.visualizer.metric_history["bootstrap.quantum.bindingEnergy"])
                self.visualizer.log_metrics("bootstrap.quantum.bindingEnergy", step, metrics)
            high_split = self.dataset_manager.build_split("quantum.highAffinity")
            if high_split.train_X.size:
                high_classifier = SimpleClassifier("quantum.highAffinity-bootstrap", architecture="EnsembleProxy")
                metrics = high_classifier.train(high_split)
                self.ml_registry.register_model("quantum.highAffinity", high_classifier, metrics, high_split.metadata)
                self.ml_api.register_endpoint("bootstrap/highAffinity", "quantum.highAffinity", high_classifier.version)
                self.validation_engine.log_evaluation("bootstrap.quantum.highAffinity", metrics)
                step = len(self.visualizer.metric_history["bootstrap.quantum.highAffinity"])
                self.visualizer.log_metrics("bootstrap.quantum.highAffinity", step, metrics)
        # Seed safety dataset with conservative priors
        for idx in range(3):
            base_vec = np.array(
                [
                    0.2 + 0.1 * idx,
                    0.55 + 0.05 * idx,
                    4.0 + idx,
                    0.1 + 0.02 * idx,
                    0.0,
                    0.0,
                ],
                dtype=float,
            )
            lambda_feat = self.feature_extractor.featurize_lambda_shells(self.context.lambda_shells)
            lambda_latent = np.asarray(
                LambdaScalingToolkit.fingerprint(self.context.lambda_shells),
                dtype=float,
            )
            feature_vec = self.feature_extractor.combine_features(base_vec, lambda_feat)
            feature_vec = self.feature_extractor.combine_features(feature_vec, lambda_latent)
            self.dataset_manager.register_record(
                "safety.toxicity",
                feature_vec,
                0.0,
                {"ligandId": f"seed-{idx}", "source": "bootstrap"},
            )
        safety_split = self.dataset_manager.build_split("safety.toxicity")
        if safety_split.train_X.size:
            metrics = {"mae": 0.0, "rmse": 0.0, "r2": 0.0, "bhattacharyya": 0.0}
            self.validation_engine.log_evaluation("bootstrap.safety.toxicity", metrics)
            step = len(self.visualizer.metric_history["bootstrap.safety.toxicity"])
            self.visualizer.log_metrics("bootstrap.safety.toxicity", step, metrics)


        benchmark_names = ("DUD-E", "ChEMBL", "ZINC15")
        self.benchmark_summary = self.dataset_manager.prepare_benchmarks(benchmark_names, self.context, limit=200)


        for task in ("quantum.highAffinity", "safety.toxicity"):
            records = self.dataset_manager.records.get(task, [])
            if not records:
                continue
            features = np.stack([entry["features"] for entry in records])
            labels = np.array([entry["label"] for entry in records], dtype=float)
            task_type = self.dataset_manager.get_task_type(task)
            if task_type == "classification" and RandomForestClassifier is not None:
                factory: Callable[[], Any] = lambda: RandomForestClassifier(n_estimators=64, random_state=self.random_seed)
            elif task_type == "regression" and RandomForestRegressor is not None:
                factory = lambda: RandomForestRegressor(n_estimators=64, random_state=self.random_seed)
            else:
                factory = lambda: GraphSurrogateModel(f"kfold-{task}")
            result = self.validation_engine.k_fold_cross_validation(factory, features, labels, folds=5, task_type=task_type)
            self.cross_validation_results[task] = result
            aggregate = result.get("aggregate", {})
            if aggregate:
                self.validation_engine.log_evaluation(f"kfold.{task}", aggregate)
                step = len(self.visualizer.metric_history[f"kfold.{task}"])
                self.visualizer.log_metrics(f"kfold.{task}", step, aggregate)


        self.baseline_results = self.baseline_suite.train_and_evaluate(self.dataset_manager)
        for task, details in self.baseline_results.items():
            comparison = details.get("comparison", {})
            best = {metric: spec.get("score") for metric, spec in comparison.get("best", {}).items() if isinstance(spec, dict)}
            if best:
                self.validation_engine.log_evaluation(f"baseline.{task}", best)
                step = len(self.visualizer.metric_history[f"baseline.{task}"])
                self.visualizer.log_metrics(f"baseline.{task}", step, best)


        self.hyperparameter_results = {}
        for dataset_name, meta in self.benchmark_summary.items():
            task = meta.get("task")
            if not task:
                continue
            split = self.dataset_manager.get_split(task)
            if not split or not split.train_X.size:
                continue
            task_type = self.dataset_manager.get_task_type(task)
            results: Dict[str, Any] = {}
            if task_type == "classification" and RandomForestClassifier is not None:
                results["grid"] = self.hyperparameter_optimizer.grid_search(
                    lambda params: RandomForestClassifier(
                        n_estimators=int(params.get("n_estimators", 128)),
                        max_depth=None if params.get("max_depth") in (None, "None") else int(params.get("max_depth")),
                        random_state=self.random_seed,
                    ),
                    {"n_estimators": [64, 128, 256], "max_depth": [None, 8, 12]},
                    split,
                    task_type,
                )
                results["bayesian"] = self.hyperparameter_optimizer.bayesian_search(
                    lambda params: RandomForestClassifier(
                        n_estimators=max(32, int(params.get("n_estimators", 100))),
                        max_depth=int(max(4, params.get("max_depth", 10))),
                        random_state=self.random_seed,
                    ),
                    {"n_estimators": (32, 256), "max_depth": (4, 16)},
                    split,
                    task_type,
                    iterations=10,
                )
            elif task_type != "classification" and RandomForestRegressor is not None:
                results["grid"] = self.hyperparameter_optimizer.grid_search(
                    lambda params: RandomForestRegressor(
                        n_estimators=int(params.get("n_estimators", 128)),
                        max_depth=None if params.get("max_depth") in (None, "None") else int(params.get("max_depth")),
                        random_state=self.random_seed,
                    ),
                    {"n_estimators": [64, 128, 256], "max_depth": [None, 8, 14]},
                    split,
                    task_type,
                )
                results["bayesian"] = self.hyperparameter_optimizer.bayesian_search(
                    lambda params: RandomForestRegressor(
                        n_estimators=max(32, int(params.get("n_estimators", 100))),
                        max_depth=int(max(4, params.get("max_depth", 12))),
                        random_state=self.random_seed,
                    ),
                    {"n_estimators": (32, 256), "max_depth": (4, 20)},
                    split,
                    task_type,
                    iterations=10,
                )
            else:
                results["grid"] = None
                results["bayesian"] = None
                self.hyperparameter_optimizer.records.append(
                    {
                        "method": "unavailable",
                        "params": {},
                        "metrics": {},
                        "task": task,
                        "reason": "Baseline library missing for task type",
                    }
                )
            self.hyperparameter_results[task] = results
            best_metrics = {}
            for strategy in ("grid", "bayesian"):
                metrics = (results.get(strategy) or {}).get("bestMetrics", {})
                for key, value in metrics.items():
                    if isinstance(value, (int, float)) and not math.isnan(value):
                        best_metrics[f"{strategy}_{key}"] = float(value)
            if best_metrics:
                self.validation_engine.log_evaluation(f"hyperopt.{task}", best_metrics)
                step = len(self.visualizer.metric_history[f"hyperopt.{task}"])
                self.visualizer.log_metrics(f"hyperopt.{task}", step, best_metrics)


        self.visualization_artifacts = self.visualizer.render()


    async def _instantiate_agents(self) -> List[AgentBase]:
        uniprot_meta = self.data_client.fetch_uniprot_metadata(self.uniprot_accession)
        agents: List[AgentBase] = [
            StructuralAnalysisAgent(
                self.blackboard,
                self.context,
                self.validator,
                self.data_client,
                self.pdb_id,
                ml_registry=self.ml_registry,
                dataset_manager=self.dataset_manager,
                feature_extractor=self.feature_extractor,
                active_learning=self.active_learning,
                ml_api=self.ml_api,
            ),
            LigandDiscoveryAgent(
                self.blackboard,
                self.context,
                self.validator,
                self.data_client,
                self.llm,
                self.target_query,
                self.quantum_reference,
                ml_registry=self.ml_registry,
                dataset_manager=self.dataset_manager,
                feature_extractor=self.feature_extractor,
                active_learning=self.active_learning,
                ml_api=self.ml_api,
                config=self.agent_model_configs.get("LigandDiscoveryAgent"),
            ),
            QuantumSimulationAgent(
                self.blackboard,
                self.context,
                self.validator,
                uniprot_meta,
                self.quantum_reference,
                ml_registry=self.ml_registry,
                dataset_manager=self.dataset_manager,
                feature_extractor=self.feature_extractor,
                active_learning=self.active_learning,
@@ -6056,61 +6341,61 @@ class DrugDiscoverySimulation:
            SafetyAgent(
                self.blackboard,
                self.context,
                self.validator,
                self.quantum_reference,
                ml_registry=self.ml_registry,
                dataset_manager=self.dataset_manager,
                feature_extractor=self.feature_extractor,
                active_learning=self.active_learning,
                ml_api=self.ml_api,
                config=self.agent_model_configs.get("SafetyAgent"),
            ),
            IPAgent(
                self.blackboard,
                self.context,
                self.validator,
                self.data_client,
                self.target_query,
                ml_registry=self.ml_registry,
                dataset_manager=self.dataset_manager,
                feature_extractor=self.feature_extractor,
                active_learning=self.active_learning,
                ml_api=self.ml_api,
                config=self.agent_model_configs.get("IPAgent"),
            ),
            JobStatusAgent( 
                self.blackboard, 
                self.context, 
                self.validator, 
                ml_registry=self.ml_registry, 
                dataset_manager=self.dataset_manager, 
                feature_extractor=self.feature_extractor, 
                active_learning=self.active_learning, 
                ml_api=self.ml_api, 
            ), 
        ] 
        for agent in agents:
            self.core_ai.register_agent(agent.name, agent)
            self.gtai_adapter.register_agent(agent)
        (
            self.structural_agent,
            self.ligand_agent,
            self.quantum_agent,
            self.synth_agent,
            self.screen_agent,
            self.safety_agent,
            self.ip_agent,
            self.status_agent,
        ) = agents
        if self.gnn_pretrainer is None:
            self.gnn_pretrainer = QuantumPretrainer(
                self.ligand_agent.surrogate_model,
                context_provider=lambda: self.context,
            )
        return agents


    def _initial_seed_ligands(self) -> List[Dict[str, Any]]:
        base_scaffolds = [f"{self.target_query}-seed-{idx}" for idx in range(3)] + ["lig-novel-001"]
        seeds: List[Dict[str, Any]] = []
        for idx, scaffold in enumerate(base_scaffolds):
            seeds.append(
@@ -6582,317 +6867,334 @@ class DrugDiscoverySimulation:
                screening_report,
                safety_report,
                ip_report,
                beam_width,
            )
        return {
            "reports": latest_reports,
            "finalLigands": seed_ligands,
            "status": latest_reports.get("JobStatusAgent"),
            "generations": generation_logs,
        }


    def post_episode_training(self) -> None:
        if not self.gnn_pretrainer:
            return
        dataset = self.gnn_pretrainer.load_dataset(self.quantum_reports_buffer)
        if dataset:
            updated_model = self.gnn_pretrainer.train(dataset)
            if self.ligand_agent.inverse_engine:
                self.ligand_agent.inverse_engine.surrogate_model.load_state_dict(updated_model.state_dict())
        self.quantum_reports_buffer.clear()


    def _sanitize_for_json(self, value: Any) -> Any:
        if isinstance(value, (str, int, float, bool)) or value is None:
            return value
        if isinstance(value, np.ndarray): 
            return value.tolist() 
        if isinstance(value, dict): 
            return {str(key): self._sanitize_for_json(val) for key, val in value.items()} 
        if isinstance(value, (list, tuple)): 
            return [self._sanitize_for_json(item) for item in value] 
        if isinstance(value, set): 
            return [self._sanitize_for_json(item) for item in value] 
        if hasattr(value, "to_dict") and callable(getattr(value, "to_dict")): 
            return self._sanitize_for_json(value.to_dict()) 
        return repr(value) 
 
    def _extract_shell_snapshot(self, context: QuantumContext) -> Dict[str, Any]: 
        stats = QuantumContext.shell_statistics(context.lambda_shells) 
        return { 
            "shellCount": stats["shellCount"], 
            "entropyMean": stats["entropyMean"], 
            "entropyStd": stats["entropyStd"], 
            "bhattacharyyaMean": stats["bhattacharyyaMean"], 
            "curvatureMean": stats["curvatureMean"], 
            "entropyDistribution": stats["entropyDistribution"], 
            "occupancyDistribution": stats["occupancyDistribution"], 
        } 
 
    def _summarize_agent_output(self, agent_output: Any) -> Dict[str, Any]: 
        if not isinstance(agent_output, dict): 
            return {"value": self._sanitize_for_json(agent_output)} 
        summary: Dict[str, Any] = { 
            "reportId": agent_output.get("reportId"), 
            "keys": sorted(agent_output.keys()), 
        } 
        list_counts: Dict[str, int] = {} 
        dict_keys: Dict[str, List[str]] = {} 
        for key, value in agent_output.items(): 
            if isinstance(value, list): 
                list_counts[key] = len(value) 
            elif isinstance(value, dict): 
                dict_keys[key] = sorted(value.keys()) 
        if list_counts: 
            summary["listCounts"] = list_counts 
        if dict_keys: 
            summary["dictKeys"] = dict_keys 
        return summary 
 
    def compute_step_metrics( 
        self, 
        context: QuantumContext, 
        previous_context: Optional[QuantumContext], 
    ) -> Dict[str, Any]: 
        metrics = { 
            "entropicFidelity": None, 
            "shellEntropyDelta": None, 
            "lambdaShellStability": None, 
        } 
        if previous_context is None: 
            return metrics 
        current_stats = QuantumContext.shell_statistics(context.lambda_shells) 
        previous_stats = QuantumContext.shell_statistics(previous_context.lambda_shells) 
        if current_stats["shellCount"] == 0 or previous_stats["shellCount"] == 0: 
            return metrics 
 
        def _pad(values: List[float], length: int) -> np.ndarray: 
            arr = np.asarray(values, dtype=float) 
            if arr.size < length: 
                arr = np.pad(arr, (0, length - arr.size), constant_values=0.0) 
            return arr 
 
        max_len = max( 
            len(current_stats["entropyDistribution"]), 
            len(previous_stats["entropyDistribution"]), 
        ) 
        curr_entropy = _pad(current_stats["entropyDistribution"], max_len) 
        prev_entropy = _pad(previous_stats["entropyDistribution"], max_len) 
        max_occ_len = max( 
            len(current_stats["occupancyDistribution"]), 
            len(previous_stats["occupancyDistribution"]), 
        ) 
        curr_occ = _pad(current_stats["occupancyDistribution"], max_occ_len) 
        prev_occ = _pad(previous_stats["occupancyDistribution"], max_occ_len) 
        fidelity = float(np.clip(np.sum(np.sqrt(curr_entropy * prev_entropy)), 0.0, 1.0)) 
        stability = float(np.clip(np.sum(np.sqrt(curr_occ * prev_occ)), 0.0, 1.0)) 
        metrics.update( 
            { 
                "entropicFidelity": fidelity, 
                "shellEntropyDelta": float(current_stats["entropyMean"] - previous_stats["entropyMean"]), 
                "lambdaShellStability": stability, 
            } 
        ) 
        return metrics 
 
    def _record_agent_step( 
        self, 
        agent_name: str, 
        agent_output: Dict[str, Any], 
        before_snapshot: Dict[str, Any], 
        blackboard_channels_before: Sequence[str], 
    ) -> None: 
        previous_context = QuantumContext.from_snapshot(before_snapshot) 
        step_metrics = self.compute_step_metrics(self.context, previous_context) 
        shell_entry = self._extract_shell_snapshot(self.context) 
        shell_entry.update({ 
            "stage": agent_name, 
            "timestamp": time.time(), 
            "stepMetrics": step_metrics, 
        }) 
        self.shell_log.append(shell_entry) 
        after_snapshot = self.context.to_snapshot() 
        context_diff = QuantumContext.diff_snapshots(before_snapshot, after_snapshot) 
        trace_entry = { 
            "timestamp": time.time(), 
            "agent": agent_name, 
            "inputs": { 
                "contextSummary": self._extract_shell_snapshot(previous_context), 
                "blackboardChannels": list(blackboard_channels_before), 
            }, 
            "outputs": self._summarize_agent_output(agent_output), 
            "blackboardChannelsAfter": list(self.blackboard.posts.keys()), 
            "stepMetrics": step_metrics, 
            "contextDiff": context_diff, 
        } 
        self.agent_traces.append(trace_entry) 
        with self.agent_trace_path.open("a", encoding="utf-8") as handle: 
            handle.write(json.dumps(self._sanitize_for_json(trace_entry)) + "\n") 
 
    async def run(self) -> Dict[str, Any]:
        run_start = time.time()
        output_dir = Path("outputs")
        output_dir.mkdir(parents=True, exist_ok=True)
        self.shell_log: List[Dict[str, Any]] = []
        self.agent_traces: List[Dict[str, Any]] = []
        self.agent_trace_path = output_dir / "agent_trace.log"
        self.agent_trace_path.write_text("")
        self.per_agent_rewards = defaultdict(list)
        self._lambda_flow_cache = {}
        agents = await self._instantiate_agents()
        for agent in agents:
            agent.reward_history.clear()
            agent.quality_history.clear()
            agent.max_quality = float("-inf")
            agent.last_entropy_signal = 0.0
            agent.last_energy_signal = 0.0
        reports: Dict[str, Any] = {}
        await self.blackboard.post(
            "quantumTrainingData",
            self.validator.validate(
                "QuantumCircuitEngine",
                { 
                    "reportId": "quantum-training-reference", 
                    "directive": self.orchestration_directives["quantumData"], 
                    "dataset": self.quantum_reference, 
                }, 
            ), 
        ) 
        ml_status_payload = { 
            "reportId": "ml-status-initial", 
            "models": self.ml_registry.describe(), 
            "datasets": {task: len(records) for task, records in self.dataset_manager.records.items()}, 
            "activeLearning": self.active_learning.describe(), 
            "api": self.ml_api.describe(), 
        } 
        await self.blackboard.post( 
            "mlStatus", 
            self.validator.validate("MLOrchestrator", ml_status_payload), 
        ) 
        cycle_result = await self.run_full_cycle()
        reports.update(cycle_result.get("reports", {}))
        if cycle_result.get("reports") and cycle_result["reports"].get("structural"):
            reports["structural"] = cycle_result["reports"].get("structural")
        reports["finalLigands"] = cycle_result.get("finalLigands")
        reports["generationSummaries"] = cycle_result.get("generations")
        reports["status"] = cycle_result.get("status")
        reports["perAgentRewards"] = {name: values for name, values in self.per_agent_rewards.items()}
        reports["episodeReward"] = self.compute_episode_reward()
        self.post_episode_training()
        simulation_reflection = self.gtai_adapter.run_recursive_simulation()
        avg_reward = statistics.mean(self.gtai_adapter.awareness_changes) if self.gtai_adapter.awareness_changes else 0.0
        tuning_meta = self.gtai_adapter.tune_analysis_parameters(avg_reward)
        memory_audit = self.gtai_adapter.analyze_memory()
        reports["directives"] = self.orchestration_directives
        await self.gtai_adapter.flush_blackboard()
        snapshot = await self.blackboard.snapshot()
        reports["blackboard"] = snapshot
        reports["mlStatus"] = {
            "models": self.ml_registry.describe(),
            "datasets": {task: len(records) for task, records in self.dataset_manager.records.items()},
            "activeLearning": self.active_learning.describe(),
            "api": self.ml_api.describe(),
        }
        gtai_summary = self.gtai_adapter.compile_summary()
        gtai_summary["latestReflection"] = simulation_reflection
        gtai_summary["latestTuning"] = tuning_meta
        gtai_summary["latestMemoryAudit"] = memory_audit
        reports["gtaiIntegration"] = gtai_summary
        reports["benchmarks"] = self.benchmark_summary
        reports["baselineComparisons"] = self.baseline_results
        reports["hyperparameterOptimization"] = self.hyperparameter_results
        reports["hyperparameterSearchLog"] = self.hyperparameter_optimizer.records
        reports["crossValidation"] = self.cross_validation_results
        reports["visualizations"] = self.visualization_artifacts
        reports["validationHistory"] = self.validation_engine.history
        shell_trace_path = output_dir / "shell_trace.json"
        shell_trace_path.write_text(json.dumps(self._sanitize_for_json(self.shell_log), indent=2))
        timestamp = datetime.utcnow()
        ligand_predictions = (
            reports.get("LigandDiscoveryAgent", {})
            .get("mlAugmentation", {})
            .get("rankedCandidates", [])
        )
        screening_predictions = (
            reports.get("ScreeningAgent", {})
            .get("mlAugmentation", {})
            .get("predictions", [])
        )
        safety_assessment = reports.get("SafetyAgent", {}).get("mlAugmentation", {})
        agent_trace_summaries = [
            {
                "agent": entry.get("agent"),
                "timestamp": entry.get("timestamp"),
                "stepMetrics": entry.get("stepMetrics"),
                "contextDiff": entry.get("contextDiff"),
            }
            for entry in self.agent_traces
        ]
        shell_log_summary = {
            "entries": len(self.shell_log),
            "stages": [entry.get("stage") for entry in self.shell_log],
            "entropyMeanTrajectory": [entry.get("entropyMean") for entry in self.shell_log],
            "bhattacharyyaTrajectory": [entry.get("bhattacharyyaMean") for entry in self.shell_log],
        }
        final_shell_state = self.shell_log[-1] if self.shell_log else None
        summary_payload = {
            "generatedAt": timestamp.isoformat() + "Z",
            "runtimeSeconds": float(time.time() - run_start),
            "finalShellState": final_shell_state,
            "shellLogSummary": shell_log_summary,
            "agentTraceSummaries": agent_trace_summaries,
            "predictions": {
                "topLigandCandidates": ligand_predictions[:5],
                "screeningPredictions": screening_predictions[:5],
                "safetyAssessment": safety_assessment,
            },
        }
        summary_path = output_dir / f"simulation_metrics_{timestamp.strftime('%Y%m%dT%H%M%SZ')}.json"
        summary_path.write_text(json.dumps(self._sanitize_for_json(summary_payload), indent=2))
        reports["instrumentation"] = {
            "shellTrace": str(shell_trace_path),
            "agentTrace": str(self.agent_trace_path),
            "summary": str(summary_path),
        }
        return reports




# ---------------------------------------------------------------------------
# CLI entrypoint
# ---------------------------------------------------------------------------




def main(argv: Optional[Iterable[str]] = None) -> None:
    parser = argparse.ArgumentParser(description="Run the Golden Turing drug discovery simulation")
    parser.add_argument("--pdb-id", default="4AKE", help="PDB identifier for structural analysis")
    parser.add_argument("--target-query", default="aspirin", help="Ligand design query keyword")
    parser.add_argument("--uniprot", default="P35354", help="UniProt accession for target metadata")
    parser.add_argument(
        "--llm-model-path",
        default=os.path.join(os.getcwd(), "models", "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"),
        help="Path to the TinyLlama GGUF model",
    )
    parser.add_argument(
        "--random-seed",
        type=int,
        default=DEFAULT_RANDOM_SEED,
        help="Random seed for reproducible agent initialization",
    )
    parser.add_argument(
        "--verification-suite",
        action="store_true",
        help="Run the three-configuration verification suite",
    )
    parser.add_argument(
        "--reproducibility-test",
        action="store_true",
        help="Run the verification suite twice and compare outputs for reproducibility",
    )
    args = parser.parse_args(list(argv) if argv is not None else None)


    simulation = DrugDiscoverySimulation(
        pdb_id=args.pdb_id,
        target_query=args.target_query,
        uniprot_accession=args.uniprot,
        llm_model_path=Path(args.llm_model_path),
        random_seed=args.random_seed,
    )
    if args.reproducibility_test:
        verification = asyncio.run(simulation.run_reproducibility_test())
        print(json.dumps(verification, indent=2))
    elif args.verification_suite:
        verification = asyncio.run(simulation.run_verification_suite())
        print(json.dumps(verification, indent=2))
    else:
        reports = asyncio.run(simulation.run())
        print(json.dumps(reports, indent=2))
        output_dir = Path("outputs")
        output_dir.mkdir(parents=True, exist_ok=True)
        output_file = output_dir / "latest_drug_discovery_simulation.json"
        output_file.write_text(json.dumps(reports, indent=2))




if __name__ == "__main__":
    main()



"""Adiabatic invariant budgeting utilities for λ-WBS campaigns."""
from __future__ import annotations


from dataclasses import dataclass, field
from typing import List


import copy


import numpy as np




@dataclass
class WBSConfig:
    lam: float
    epsilon_ladder: List[float]
    z_extent: float = 10.0




@dataclass
class AdiabaticBudget:
    J_adia_init: float
    J_adia_current: float
    eps_schedule: List[float]
    exotic_energy_trace: List[float] = field(default_factory=list)
    rg_stability_flag: bool = True
    adiabatic_utilization_ratio: float = 0.0




def _compute_initial_budget(cfg: WBSConfig) -> float:
    ladder_energy = np.sum(np.abs(cfg.epsilon_ladder))
    return float(cfg.lam * (1.0 + ladder_energy))




def initialize_budget_from_lambda_wbs(cfg: WBSConfig) -> AdiabaticBudget:
    J0 = _compute_initial_budget(cfg)
    budget = AdiabaticBudget(J_adia_init=J0, J_adia_current=J0, eps_schedule=list(cfg.epsilon_ladder))
    return budget




def update_budget_with_experiment(budget: AdiabaticBudget, experiment: "ExperimentRecord") -> None:
    exotic_increment = 0.0


    if getattr(experiment, "stress_alignment", None):
        exotic_increment += float(max(0.0, experiment.stress_alignment.final_l2))


    if getattr(experiment, "ligc_result", None):
        exotic_increment += float(max(0.0, experiment.ligc_result.variance))
        if experiment.ligc_result.gamma_deviation is not None:
            exotic_increment += float(abs(experiment.ligc_result.gamma_deviation)) * 0.1
        if experiment.ligc_result.delta_deviation is not None:
            exotic_increment += float(abs(experiment.ligc_result.delta_deviation)) * 0.1


    phase5_prior = getattr(experiment, "phase5_prior", None)
    if phase5_prior is not None:
        exotic_increment += float(max(0.0, phase5_prior.einstein_residual.get("l2", 0.0)))


    echo_val = getattr(experiment, "echo_validation", None)
    if echo_val is not None and echo_val.classification == "echo-failed":
        exotic_increment *= 1.5


    budget.exotic_energy_trace.append(exotic_increment)
    budget.J_adia_current = max(0.0, budget.J_adia_current - exotic_increment)
    budget.adiabatic_utilization_ratio = float(
        1.0 - budget.J_adia_current / max(budget.J_adia_init, 1e-12)
    )


    if budget.J_adia_current < 0.1 * budget.J_adia_init:
        budget.rg_stability_flag = False
    experiment.adiabatic_budget_snapshot = copy.deepcopy(budget)
admet_engine.py
New
+42
-0


"""ADMET prediction stub with mode-aware gating."""
from __future__ import annotations


from typing import Dict, TYPE_CHECKING


import numpy as np


if TYPE_CHECKING:  # pragma: no cover
    from drug_discovery_simulation import SimulationMode




def predict_admet(smiles: str, mode: "SimulationMode", allow_stub: bool = False) -> Dict[str, float]:
    from drug_discovery_simulation import SimulationMode  # local import to avoid circularity


    if mode is SimulationMode.DEBUG_SYNTHETIC:
        seed = abs(hash((smiles, "admet"))) % (2**32)
        rng = np.random.default_rng(seed)
        return {
            "solubility": float(rng.normal(0.0, 1.0)),
            "hERG_risk": float(rng.uniform(0.0, 1.0)),
            "clearance": float(rng.normal(10.0, 2.0)),
        }


    if allow_stub:
        raise RuntimeError("Stub ADMET backend is forbidden in benchmark/production modes")


    if not smiles:
        raise RuntimeError("ADMET backend requires a valid SMILES string")


    length = len(smiles)
    hetero_atoms = sum(1 for c in smiles if c.isalpha() and c.upper() not in {"C", "H"})
    ring_penalty = smiles.count("=") * 0.1


    solubility = 1.0 - 0.03 * length - 0.1 * ring_penalty
    herg_risk = min(1.0, max(0.0, 0.2 + 0.02 * hetero_atoms + 0.01 * ring_penalty))
    clearance = max(0.1, 12.0 - 0.2 * hetero_atoms - 0.05 * length)


    return {
        "solubility": float(solubility),
        "hERG_risk": float(herg_risk),
        "clearance": float(clearance),
    }
atomic_properties.py
New
+91
-0


"""Atomic property estimation utilities.


This module computes partial charges, polarizabilities, and hybridization
states using RDKit-based heuristics or semi-empirical surrogates when
available. Outputs map into field parameters that can be consumed by the
λ-scale geometry and Klein-Gordon field builders.
"""
from __future__ import annotations


import logging
from dataclasses import dataclass
from typing import Dict, Optional


import numpy as np


try:  # pragma: no cover - optional dependency
    from rdkit import Chem
    from rdkit.Chem import AllChem
except Exception:  # pragma: no cover
    Chem = None
    AllChem = None


logger = logging.getLogger(__name__)




@dataclass
class AtomicFieldParameters:
    mu: float
    xi: float
    curvature_coupling: float
    partial_charge: float
    polarizability: float
    hybridization: str




def _estimate_polarizability(atom: "Chem.Atom") -> float:
    # Simple electronegativity-based heuristic; replace with ML/SEQM as needed
    en = Chem.GetPeriodicTable().GetElectronegativity(atom.GetAtomicNum()) if Chem else 0.0
    return max(0.1, 5.0 - 0.5 * en)




def compute_atomic_properties(mol: "Chem.Mol") -> Dict[int, AtomicFieldParameters]:
    """Compute per-atom field parameters from an RDKit molecule.


    Returns a mapping from atom index to :class:`AtomicFieldParameters`. Raises
    RuntimeError if RDKit is unavailable.
    """


    if Chem is None or AllChem is None:
        raise RuntimeError("RDKit is required for atomic property estimation")


    props: Dict[int, AtomicFieldParameters] = {}
    try:
        AllChem.ComputeGasteigerCharges(mol)
    except Exception as exc:  # pragma: no cover
        logger.warning("Gasteiger charges failed: %s", exc)


    for atom in mol.GetAtoms():
        idx = atom.GetIdx()
        charge = float(atom.GetDoubleProp("_GasteigerCharge")) if atom.HasProp("_GasteigerCharge") else 0.0
        polar = _estimate_polarizability(atom)
        hybrid = str(atom.GetHybridization())
        # Map to field couplings; simple proportional models for now
        mu = 0.5 + 0.1 * abs(charge)
        xi = 0.05 * (atom.GetDegree() + 1)
        curvature = 0.1 * polar
        props[idx] = AtomicFieldParameters(
            mu=mu,
            xi=xi,
            curvature_coupling=curvature,
            partial_charge=charge,
            polarizability=polar,
            hybridization=hybrid,
        )
    return props




def summarize_field_parameters(params: Dict[int, AtomicFieldParameters]) -> Dict[str, float]:
    if not params:
        return {}
    mu_vals = np.array([p.mu for p in params.values()], dtype=float)
    xi_vals = np.array([p.xi for p in params.values()], dtype=float)
    pol_vals = np.array([p.polarizability for p in params.values()], dtype=float)
    return {
        "mu_mean": float(mu_vals.mean()),
        "xi_mean": float(xi_vals.mean()),
        "polarizability_mean": float(pol_vals.mean()),
        "mu_std": float(mu_vals.std()),
        "xi_std": float(xi_vals.std()),
    }


backend_registry.py
New
+94
-0


"""Backend registry to centralize physics/ADMET backends with mode-aware validation."""
from __future__ import annotations


import logging
from dataclasses import dataclass, field
from typing import Callable, Dict, Optional, TYPE_CHECKING


import numpy as np


from lambda_geometry_prior import MoleculeRecord, TargetRecord


try:  # pragma: no cover - optional logging utilities
    import rich
except Exception:  # pragma: no cover
    rich = None




logger = logging.getLogger(__name__)




QMBackend = Callable[[MoleculeRecord, "SimulationMode", bool], Dict[str, float]]
DockingBackend = Callable[[MoleculeRecord, TargetRecord, "SimulationMode", bool], Dict[str, float]]
MDBackend = Callable[[MoleculeRecord, TargetRecord, "SimulationMode", bool], Dict[str, np.ndarray]]
ADMETBackend = Callable[[str, "SimulationMode", bool], Dict[str, float]]




@dataclass
class BackendRegistry:
    qm_backend: Optional[QMBackend] = None
    docking_backend: Optional[DockingBackend] = None
    md_backend: Optional[MDBackend] = None
    admet_backend: Optional[ADMETBackend] = None
    metadata: Dict[str, str] = field(default_factory=dict)


    def register_qm_backend(self, fn: QMBackend, name: str = "qm") -> None:
        self.qm_backend = fn
        self.metadata["qm"] = name


    def register_docking_backend(self, fn: DockingBackend, name: str = "docking") -> None:
        self.docking_backend = fn
        self.metadata["docking"] = name


    def register_md_backend(self, fn: MDBackend, name: str = "md") -> None:
        self.md_backend = fn
        self.metadata["md"] = name


    def register_admet_backend(self, fn: ADMETBackend, name: str = "admet") -> None:
        self.admet_backend = fn
        self.metadata["admet"] = name


    def validate_backends_for_mode(self, mode: "SimulationMode", allow_stub: bool = False) -> None:
        from drug_discovery_simulation import SimulationMode as _SimulationMode


        non_debug = mode is not _SimulationMode.DEBUG_SYNTHETIC
        if non_debug and allow_stub:
            raise RuntimeError("allow_stub is forbidden for benchmark or production modes")


        if non_debug:
            missing = [
                name
                for name, fn in {
                    "qm": self.qm_backend,
                    "docking": self.docking_backend,
                    "md": self.md_backend,
                    "admet": self.admet_backend,
                }.items()
                if fn is None
            ]
            if missing:
                raise RuntimeError(
                    f"Backends missing for mode {mode.value}: {', '.join(missing)}. "
                    "Configure concrete backends or run in DEBUG_SYNTHETIC for deterministic stubs."
                )


    def run_qm(self, mol: MoleculeRecord, mode: "SimulationMode", allow_stub: bool = False) -> Dict[str, float]:
        if self.qm_backend is None:
            raise RuntimeError("QM backend not registered")
        return self.qm_backend(mol, mode, allow_stub)


    def run_docking(self, mol: MoleculeRecord, tgt: TargetRecord, mode: "SimulationMode", allow_stub: bool = False) -> Dict[str, float]:
        if self.docking_backend is None:
            raise RuntimeError("Docking backend not registered")
        return self.docking_backend(mol, tgt, mode, allow_stub)


    def run_md(self, mol: MoleculeRecord, tgt: TargetRecord, mode: "SimulationMode", allow_stub: bool = False) -> Dict[str, np.ndarray]:
        if self.md_backend is None:
            raise RuntimeError("MD backend not registered")
        return self.md_backend(mol, tgt, mode, allow_stub)


    def run_admet(self, smiles: str, mode: "SimulationMode", allow_stub: bool = False) -> Dict[str, float]:
        if self.admet_backend is None:
            raise RuntimeError("ADMET backend not registered")
        return self.admet_backend(smiles, mode, allow_stub)


benchmarking_scripts/dft_comparator.py
New
+37
-0


"""Benchmark simulated energies against reference DFT calculations."""
from __future__ import annotations


import json
from pathlib import Path
from typing import Dict, List


import numpy as np




def compare_to_dft(simulated: List[float], reference: List[float]) -> Dict[str, float]:
    sim = np.asarray(simulated, dtype=float)
    ref = np.asarray(reference, dtype=float)
    if sim.size != ref.size:
        raise ValueError("Simulated and reference arrays must be the same length")
    diff = sim - ref
    return {
        "mae": float(np.mean(np.abs(diff))),
        "rmse": float(np.sqrt(np.mean(diff ** 2))),
        "max_abs": float(np.max(np.abs(diff))),
    }




def write_report(simulated: List[float], reference: List[float], path: Path) -> Path:
    metrics = compare_to_dft(simulated, reference)
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(json.dumps(metrics, indent=2))
    return path




if __name__ == "__main__":  # pragma: no cover
    # Example usage with dummy values
    sim = [-10.1, -5.2, -7.3]
    ref = [-10.0, -5.0, -7.0]
    report = write_report(sim, ref, Path("outputs/dft_comparison.json"))
    print(f"Wrote {report}")


boundary_geometry_adapter.py
New
+64
-0


"""Boundary geometry adapter for embedding molecules in curved λ-geometry.


This module creates boundary surfaces based on van der Waals radii or solvent
accessible approximations and maps them into a λ-scale invariant coordinate
system for downstream field simulations.
"""
from __future__ import annotations


import logging
from dataclasses import dataclass
from typing import Optional, Tuple


import numpy as np


try:  # pragma: no cover - optional dependency
    from rdkit import Chem
except Exception:  # pragma: no cover
    Chem = None


logger = logging.getLogger(__name__)




@dataclass
class BoundaryGeometry:
    coordinates: np.ndarray
    radii: np.ndarray
    surface_points: np.ndarray
    metadata: dict | None = None




def _vdw_radius(atom_num: int) -> float:
    table = {1: 1.2, 6: 1.7, 7: 1.55, 8: 1.52, 9: 1.47, 15: 1.8, 16: 1.8, 17: 1.75}
    return table.get(atom_num, 1.75)




def embed_in_curved_geometry(
    mol: Optional["Chem.Mol"], coords: np.ndarray, epsilon: float = 0.05, r0: float = 1.5, lam: float = np.sqrt(6.0) / 2.0
) -> BoundaryGeometry:
    if coords is None or coords.size == 0:
        coords = np.zeros((1, 3), dtype=float)
    if mol is None or Chem is None:
        radii = np.ones(len(coords), dtype=float) * r0
    else:
        radii = np.array([_vdw_radius(atom.GetAtomicNum()) for atom in mol.GetAtoms()], dtype=float)


    # Generate surface samples by expanding coordinates along sphere approximations
    samples = []
    for center, r in zip(coords, radii):
        # six-point stencil on each axis
        for axis in range(3):
            delta = np.zeros(3)
            delta[axis] = r
            samples.append(center + delta)
            samples.append(center - delta)
    surface = np.vstack(samples) if samples else np.zeros((0, 3))


    # Normalize into λ-scale invariant frame with mild epsilon smoothing
    norms = np.linalg.norm(surface, axis=1) if surface.size else np.zeros(0)
    with np.errstate(divide="ignore", invalid="ignore"):
        scaled = (norms / max(r0, 1e-6)) + epsilon
        surface_lambda = lam * np.log1p(scaled).reshape(-1, 1) * np.ones((1, 3)) if surface.size else surface
    meta = {"epsilon": float(epsilon), "r0": float(r0), "lam": float(lam)}
    return BoundaryGeometry(coordinates=coords, radii=radii, surface_points=surface_lambda, metadata=meta)


chem_utils.py
New
+316
-0


"""Chemistry utilities for sanitization, parsing, and featurization.


This module centralizes light-weight cheminformatics helpers so that higher-level
pipelines can accept inputs in multiple formats (SMILES, PDB, MOL2) while keeping
production pathways chemically valid. When RDKit is not available, strict
parsing will fail fast to avoid silently accepting unvalidated structures.
"""
from __future__ import annotations


import logging
import os
from typing import Callable, Dict, Optional, Tuple


from atomic_properties import AtomicFieldParameters, compute_atomic_properties


import numpy as np


try:  # pragma: no cover - RDKit optional
    from rdkit import Chem
    from rdkit.Chem import AllChem, DataStructs
except Exception:  # pragma: no cover
    Chem = None
    AllChem = None
    DataStructs = None


logger = logging.getLogger(__name__)




def sanitize_smiles(smiles: str, strict: bool = False) -> Optional[str]:
    """Return canonical SMILES if valid, otherwise None.


    In strict mode, RDKit must be available and successful sanitization is required;
    otherwise ``None`` is returned to force the caller to reject the molecule.
    """


    if Chem is None:
        # Fallback validation when RDKit is unavailable: accept non-empty ASCII SMILES
        smiles = smiles.strip()
        if strict and not smiles:
            return None
        return smiles
    try:
        mol = Chem.MolFromSmiles(smiles, sanitize=True)
    except Exception:
        return None
    if mol is None:
        return None
    return Chem.MolToSmiles(mol, canonical=True)




def _mol_from_path(path: str) -> Optional["Chem.Mol"]:
    if Chem is None:
        return None
    ext = os.path.splitext(path)[1].lower()
    try:
        if ext in {".pdb", ".ent"}:
            return Chem.MolFromPDBFile(path, sanitize=True, removeHs=False)
        if ext in {".mol2"}:
            return Chem.MolFromMol2File(path, sanitize=True, removeHs=False)
        if ext in {".sdf"}:
            suppl = Chem.SDMolSupplier(path, removeHs=False, sanitize=True)
            return suppl[0] if len(suppl) else None
        # generic MOL
        return Chem.MolFromMolFile(path, sanitize=True, removeHs=False)
    except Exception as exc:  # pragma: no cover - defensive
        logger.warning("Failed to parse molecular file %s: %s", path, exc)
        return None




def _pdb_basic_parse(path: str, include_ligand: bool = True) -> Tuple[Optional[np.ndarray], Dict[int, AtomicFieldParameters]]:
    """Lightweight PDB reader used when RDKit is unavailable.


    Extracts coordinates from ATOM/HETATM records and synthesizes per-atom field
    parameters using simple heuristics on atomic numbers. This keeps production
    flows running in environments without cheminformatics binaries while still
    grounding geometry in the provided structure file.
    """


    aa_resnames = {
        "ALA",
        "ARG",
        "ASN",
        "ASP",
        "CYS",
        "GLN",
        "GLU",
        "GLY",
        "HIS",
        "ILE",
        "LEU",
        "LYS",
        "MET",
        "PHE",
        "PRO",
        "SER",
        "THR",
        "TRP",
        "TYR",
        "VAL",
    }


    def _atomic_number(sym: str) -> int:
        table = {
            "H": 1,
            "C": 6,
            "N": 7,
            "O": 8,
            "S": 16,
            "P": 15,
            "F": 9,
            "CL": 17,
            "BR": 35,
            "I": 53,
        }
        return table.get(sym.upper().strip(), 0)


    coords = []
    params: Dict[int, AtomicFieldParameters] = {}
    try:
        with open(path, "r") as handle:
            for line in handle:
                if not line.startswith(("ATOM", "HETATM")):
                    continue
                resname = line[17:20].strip().upper()
                if not include_ligand and resname not in aa_resnames:
                    continue
                try:
                    x = float(line[30:38])
                    y = float(line[38:46])
                    z = float(line[46:54])
                except ValueError:
                    continue
                coords.append((x, y, z))
                element = line[76:78].strip() or line[12:14].strip()
                at_num = _atomic_number(element)
                idx = len(coords) - 1
                # Heuristic field parameters without RDKit
                mu = 0.5 + 0.02 * max(at_num - 1, 0)
                xi = 0.05 + 0.005 * max(at_num - 1, 0)
                curvature = 0.05 + 0.001 * at_num
                params[idx] = AtomicFieldParameters(
                    mu=mu,
                    xi=xi,
                    curvature_coupling=curvature,
                    partial_charge=0.0,
                    polarizability=0.5,
                    hybridization="UNK",
                )
    except FileNotFoundError:
        return None, {}


    if not coords:
        return None, {}
    return np.array(coords, dtype=float), params




def parse_molecule_source(source: str, strict: bool = True) -> Tuple[Optional[str], Optional[np.ndarray]]:
    """Parse SMILES or a structure file into canonical SMILES and coordinates.


    Returns a tuple ``(canonical_smiles, coordinates)`` where coordinates are the
    first conformer atomic positions in Angstrom, or ``None`` if unavailable.
    In strict mode, parsing failure returns ``(None, None)`` to force callers to
    reject invalid inputs.
    """


    if Chem is None:
        if os.path.isfile(source) and source.lower().endswith((".pdb", ".ent")):
            coords, _ = _pdb_basic_parse(source, include_ligand=True)
            return (None, coords) if strict else (source, coords)
        return (None, None) if strict else (source, None)


    mol: Optional["Chem.Mol"]
    if os.path.isfile(source):
        mol = _mol_from_path(source)
    else:
        mol = Chem.MolFromSmiles(source, sanitize=True)


    if mol is None:
        return (None, None)


    if mol.GetNumConformers() == 0:
        try:
            AllChem.EmbedMolecule(mol, AllChem.ETKDG())
            AllChem.MMFFOptimizeMolecule(mol)
        except Exception as exc:  # pragma: no cover - optional
            logger.warning("Conformer generation failed for %s: %s", source, exc)


    conformer = mol.GetConformer() if mol.GetNumConformers() else None
    coords = None
    if conformer is not None:
        coords = np.array(conformer.GetPositions(), dtype=float)


    try:
        canonical = Chem.MolToSmiles(mol, canonical=True)
    except Exception:
        canonical = None


    if strict and canonical is None:
        return (None, None)
    return canonical, coords




def parse_molecule_and_estimate_fields(
    source: str, strict: bool = True, include_ligand: bool = True
) -> Tuple[Optional["Chem.Mol"], Optional[np.ndarray], Dict[int, AtomicFieldParameters]]:
    """Parse a molecular source and estimate per-atom field parameters.


    Returns a tuple of (RDKit Mol, coordinates array, field parameter mapping).
    In strict mode, RDKit must be available and parsing failures will return
    ``(None, None, {})`` to allow the caller to reject invalid inputs.


    When ``include_ligand`` is False and the input is a PDB-like structure,
    non-standard residues are filtered out to approximate an apo state, keeping
    only canonical amino-acid atoms for geometry embedding.
    """


    if Chem is None:
        if os.path.isfile(source) and source.lower().endswith((".pdb", ".ent")):
            coords, params = _pdb_basic_parse(source, include_ligand=include_ligand)
            return (None, coords, params)
        return (None, None, {}) if strict else (None, None, {})


    if os.path.isfile(source):
        mol = _mol_from_path(source)
    else:
        try:
            mol = Chem.MolFromSmiles(source, sanitize=True)
        except Exception:
            mol = None


    if mol is None:
        return (None, None, {}) if strict else (None, None, {})


    if not include_ligand:
        try:
            aa_resnames = {
                "ALA",
                "ARG",
                "ASN",
                "ASP",
                "CYS",
                "GLN",
                "GLU",
                "GLY",
                "HIS",
                "ILE",
                "LEU",
                "LYS",
                "MET",
                "PHE",
                "PRO",
                "SER",
                "THR",
                "TRP",
                "TYR",
                "VAL",
            }
            editable = Chem.RWMol()
            old_to_new: Dict[int, int] = {}
            for atom in mol.GetAtoms():
                info = atom.GetPDBResidueInfo()
                if info is not None and info.GetResName().strip().upper() not in aa_resnames:
                    continue
                new_idx = editable.AddAtom(atom)
                old_to_new[atom.GetIdx()] = new_idx
            for bond in mol.GetBonds():
                bgn, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()
                if bgn in old_to_new and end in old_to_new:
                    editable.AddBond(
                        old_to_new[bgn],
                        old_to_new[end],
                        bond.GetBondType(),
                    )
            filtered = editable.GetMol()
            Chem.SanitizeMol(filtered)
            mol = filtered
        except Exception as exc:  # pragma: no cover - defensive
            logger.warning("Ligand filtering failed, proceeding with full structure: %s", exc)


    if mol.GetNumConformers() == 0:
        try:  # pragma: no cover - optional conformer generation
            AllChem.EmbedMolecule(mol, AllChem.ETKDG())
            AllChem.MMFFOptimizeMolecule(mol)
        except Exception as exc:  # pragma: no cover
            logger.warning("Conformer generation failed for %s: %s", source, exc)


    conformer = mol.GetConformer() if mol.GetNumConformers() else None
    coords = np.array(conformer.GetPositions(), dtype=float) if conformer is not None else None


    try:
        field_params = compute_atomic_properties(mol)
    except Exception as exc:  # pragma: no cover - fallback when RDKit optional pieces missing
        logger.warning("Atomic property estimation failed for %s: %s", source, exc)
        field_params = {}


    if strict and coords is None:
        return (None, None, {})


    return mol, coords, field_params




def default_rdkit_featurizer() -> Optional[Callable[[str], np.ndarray]]:
    if Chem is None or AllChem is None or DataStructs is None:
        return None


    def _featurize(smiles: str) -> np.ndarray:
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return np.zeros(2048, dtype=float)
        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=2048)
        arr = np.zeros((1, 2048), dtype=int)
        DataStructs.ConvertToNumpyArray(fp, arr[0])
        return arr[0].astype(float)


    return _featurize


data/pdb/1CA2.pdb
New
+7
-0


HEADER    PLACEHOLDER 1CA2
ATOM      1  N   ALA A   1      -0.000   0.000   0.000  1.00 20.00           N
ATOM      2  CA  ALA A   1       1.458   0.000   0.000  1.00 20.00           C
ATOM      3  C   ALA A   1       1.958   1.458   0.000  1.00 20.00           C
ATOM      4  O   ALA A   1       1.158   2.308   0.000  1.00 20.00           O
ATOM      5  CB  ALA A   1       1.958  -0.908   1.200  1.00 20.00           C
END
docking_engine.py
New
+42
-0


"""Docking engine stub respecting simulation modes."""
from __future__ import annotations


from typing import Dict, TYPE_CHECKING


import numpy as np


from lambda_geometry_prior import MoleculeRecord, TargetRecord


if TYPE_CHECKING:  # pragma: no cover
    from drug_discovery_simulation import SimulationMode




def dock_ligand_to_target(
    mol: MoleculeRecord, tgt: TargetRecord, mode: "SimulationMode", allow_stub: bool = False
) -> Dict[str, float]:
    from drug_discovery_simulation import SimulationMode  # local import to avoid circularity


    if mode is SimulationMode.DEBUG_SYNTHETIC:
        seed = abs(hash((mol.smiles, tgt.target_id))) % (2**32)
        rng = np.random.default_rng(seed)
        return {"binding_energy": float(-7.0 + rng.normal(0.0, 0.5)), "pose_rmsd": float(rng.uniform(0.5, 2.0))}


    if allow_stub:
        raise RuntimeError("Stub docking backend is forbidden in benchmark/production modes")


    if tgt.pocket_coordinates is None or tgt.pocket_coordinates.size == 0:
        raise RuntimeError("Docking backend requires real pocket coordinates; received placeholder geometry")


    pocket = np.asarray(tgt.pocket_coordinates, dtype=float)
    if not np.isfinite(pocket).all():
        raise RuntimeError("Docking backend received non-finite coordinates")


    ligand_coords = np.asarray(mol.coordinates if mol.coordinates is not None else np.zeros((0, 3)))
    ligand_count = ligand_coords.shape[0]
    pocket_extent = np.linalg.norm(pocket.max(axis=0) - pocket.min(axis=0))
    pocket_density = float(pocket.shape[0]) / max(pocket_extent, 1e-6)


    binding_energy = -4.0 - 0.02 * pocket_density - 0.01 * ligand_count - 0.02 * pocket_extent
    pose_rmsd = max(0.4, 0.1 * np.std(pocket, axis=0).mean())


    return {"binding_energy": float(binding_energy), "pose_rmsd": float(pose_rmsd)}
drug_discovery_simulation.py
+423
-110


@@ -25,94 +25,149 @@ from __future__ import annotations




import argparse
import argparse
import ast
import ast
import asyncio
import asyncio
import copy
import copy
import csv
import csv
import hashlib
import hashlib
import importlib
import importlib
import io
import io
import itertools
import itertools
import json
import json
import logging
import logging
import math
import math
import os
import os
import random
import random
import shutil
import shutil
import statistics
import statistics
import tarfile
import tarfile
import tempfile
import tempfile
import textwrap
import textwrap
import time
import time
import types
import types
import zipfile
import zipfile
from datetime import datetime
from datetime import datetime
from collections import defaultdict, deque
from collections import defaultdict, deque
from dataclasses import dataclass, field
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from pathlib import Path
from typing import Any, Callable, Dict, Iterable, List, Optional, Sequence, Set, Tuple
from typing import Any, Callable, Dict, Iterable, List, Optional, Sequence, Set, Tuple
from urllib import error as urlerror, request as urlrequest
from urllib import error as urlerror, request as urlrequest




import numpy as np
import numpy as np




from adiabatic_budget import AdiabaticBudget, WBSConfig, initialize_budget_from_lambda_wbs, update_budget_with_experiment
from backend_registry import BackendRegistry
from experiment_record import ExperimentRecord, build_energy_profile_from_results
from chem_utils import default_rdkit_featurizer, sanitize_smiles
from lambda_geometry_prior import (
    LambdaPrior,
    LambdaPriorConfig,
    MoleculeRecord,
    TargetRecord,
    build_lambda_prior_for_complex,
    get_lambda_descriptor_vector,
)
from ligc_unified_potential import LigcConfig, compute_ligc_for_experiment


from kg_scale_invariant_metric import (
from kg_scale_invariant_metric import (
    FieldParams,
    FieldParams,
    GeometryParams,
    GeometryParams,
    build_kg_operator,
    build_kg_operator,
    compute_modes,
    compute_modes,
    integrate_profile,
    integrate_profile,
)
)
from phase5_unification_bridge import Phase5Params, SpatialGrid, build_phase5_covariant_prior
from phase4_entanglement import (
from phase4_entanglement import (
    Params as EntanglementParams,
    Params as EntanglementParams,
    build_adjacency,
    build_adjacency,
    build_geometry,
    build_geometry,
    build_hamiltonian,
    build_hamiltonian,
    single_particle_entropy_for_cut,
    single_particle_entropy_for_cut,
)
)
from stress_alignment import StressAlignParams, renormalize_experiment_stress
from qm_engine import compute_qm_properties
from docking_engine import dock_ligand_to_target
from md_engine import run_md_for_complex
from admet_engine import predict_admet
from rl_rewards import RewardPrimitives
from rl_rewards import RewardPrimitives








LAMBDA_DILATION = float(np.sqrt(6.0) / 2.0)
LAMBDA_DILATION = float(np.sqrt(6.0) / 2.0)
PHI_CONSTANT = float((1.0 + math.sqrt(5.0)) / 2.0)
PHI_CONSTANT = float((1.0 + math.sqrt(5.0)) / 2.0)
DUAL_SCALING_ALPHA = float(np.log(LAMBDA_DILATION) / np.log(PHI_CONSTANT))
DUAL_SCALING_ALPHA = float(np.log(LAMBDA_DILATION) / np.log(PHI_CONSTANT))
DEFAULT_RANDOM_SEED = 1337
DEFAULT_RANDOM_SEED = 1337
ENTROPY_FLOOR = 0.02
ENTROPY_FLOOR = 0.02
ENTROPY_CEILING = 12.0
ENTROPY_CEILING = 12.0
ENTROPY_SHAPE_STRENGTH = 0.8
ENTROPY_SHAPE_STRENGTH = 0.8
OCCUPANCY_PRIOR_WEIGHT = 0.35
OCCUPANCY_PRIOR_WEIGHT = 0.35








SKLEARN_AVAILABLE = importlib.util.find_spec("sklearn") is not None
SKLEARN_AVAILABLE = importlib.util.find_spec("sklearn") is not None
TORCH_AVAILABLE = importlib.util.find_spec("torch") is not None
TORCH_AVAILABLE = importlib.util.find_spec("torch") is not None
PLOTLY_AVAILABLE = importlib.util.find_spec("plotly") is not None
PLOTLY_AVAILABLE = importlib.util.find_spec("plotly") is not None
MATPLOTLIB_AVAILABLE = importlib.util.find_spec("matplotlib") is not None
MATPLOTLIB_AVAILABLE = importlib.util.find_spec("matplotlib") is not None
SHAP_AVAILABLE = importlib.util.find_spec("shap") is not None
SHAP_AVAILABLE = importlib.util.find_spec("shap") is not None




logger = logging.getLogger(__name__)
logger = logging.getLogger(__name__)








class SimulationMode(Enum):
    DEBUG_SYNTHETIC = "debug_synthetic"
    BENCHMARK_PUBLIC = "benchmark_public"
    PRODUCTION_QM = "production_qm"




@dataclass
class SimulationConfig:
    mode: SimulationMode = SimulationMode.DEBUG_SYNTHETIC
    allow_stub: bool = False
    qm_backend: str | None = None
    docking_backend: str | None = None
    md_backend: str | None = None
    admet_backend: str | None = None
    benchmark_datasets: List[str] = field(default_factory=list)
    lambda_cfg: LambdaPriorConfig | None = None
    ligc_cfg: LigcConfig | None = None
    stress_cfg: StressAlignParams | None = None
    phase5_params: Phase5Params | None = None




_GLOBAL_SIM_MODE: SimulationMode = SimulationMode.DEBUG_SYNTHETIC
SIMULATION_UNPUBLISHABLE: bool = False




def set_global_simulation_mode(mode: SimulationMode, allow_stub: bool = False) -> None:
    global _GLOBAL_SIM_MODE
    _GLOBAL_SIM_MODE = mode
    if mode is not SimulationMode.DEBUG_SYNTHETIC and allow_stub:
        logger.warning("allow_stub=True in non-debug mode; this should be used only for incremental integration")




def _deterministic_score(identifier: str) -> float:
def _deterministic_score(identifier: str) -> float:
    if _GLOBAL_SIM_MODE is not SimulationMode.DEBUG_SYNTHETIC:
        raise RuntimeError("Deterministic synthetic scores are only permitted in DEBUG_SYNTHETIC mode")
    digest = hashlib.sha256(identifier.encode("utf-8")).digest()
    digest = hashlib.sha256(identifier.encode("utf-8")).digest()
    value = int.from_bytes(digest[:8], "big")
    value = int.from_bytes(digest[:8], "big")
    return value / float(2**64 - 1)
    return value / float(2**64 - 1)








class PretrainedModelHandle:
class PretrainedModelHandle:
    """Lightweight deterministic stand-in for pretrained model artifacts."""
    """Lightweight deterministic stand-in for pretrained model artifacts."""




    def __init__(self, model_type: str, path: Path) -> None:
    def __init__(self, model_type: str, path: Path) -> None:
        self.model_type = model_type
        self.model_type = model_type
        self.path = path
        self.path = path
        self.fingerprint = hashlib.sha1(str(path).encode("utf-8")).hexdigest()  # nosec B324
        self.fingerprint = hashlib.sha1(str(path).encode("utf-8")).hexdigest()  # nosec B324




    def score(self, identifier: str) -> float:
    def score(self, identifier: str) -> float:
        token = f"{self.model_type}:{self.fingerprint}:{identifier}"
        token = f"{self.model_type}:{self.fingerprint}:{identifier}"
        return _deterministic_score(token)
        return _deterministic_score(token)




    def describe(self) -> Dict[str, Any]:
    def describe(self) -> Dict[str, Any]:
        return {
        return {
            "modelType": self.model_type,
            "modelType": self.model_type,
            "path": str(self.path),
            "path": str(self.path),
            "fingerprint": self.fingerprint,
            "fingerprint": self.fingerprint,
        }
        }








@@ -794,142 +849,315 @@ class LightweightLLM:
        self.model_path = model_path
        self.model_path = model_path
        self.max_tokens = max_tokens
        self.max_tokens = max_tokens
        self._llama = None
        self._llama = None
        try:
        try:
            from llama_cpp import Llama  # type: ignore
            from llama_cpp import Llama  # type: ignore




            if model_path.exists():
            if model_path.exists():
                self._llama = Llama(model_path=str(model_path), n_ctx=2048, n_threads=os.cpu_count() or 4)
                self._llama = Llama(model_path=str(model_path), n_ctx=2048, n_threads=os.cpu_count() or 4)
        except Exception:
        except Exception:
            # llama-cpp-python not available; the interface will synthesize responses heuristically
            # llama-cpp-python not available; the interface will synthesize responses heuristically
            self._llama = None
            self._llama = None




    def complete(self, prompt: str, temperature: float = 0.2) -> str:
    def complete(self, prompt: str, temperature: float = 0.2) -> str:
        if self._llama is not None:
        if self._llama is not None:
            output = self._llama(prompt=prompt, max_tokens=self.max_tokens, temperature=temperature, stop=["###"])
            output = self._llama(prompt=prompt, max_tokens=self.max_tokens, temperature=temperature, stop=["###"])
            if isinstance(output, dict):
            if isinstance(output, dict):
                choices = output.get("choices", [])
                choices = output.get("choices", [])
                if choices:
                if choices:
                    return choices[0].get("text", "").strip()
                    return choices[0].get("text", "").strip()
        # Fallback heuristic completion
        # Fallback heuristic completion
        summary = textwrap.shorten(prompt.split("\n")[-1], width=200)
        summary = textwrap.shorten(prompt.split("\n")[-1], width=200)
        return f"Heuristic plan based on context: {summary}"
        return f"Heuristic plan based on context: {summary}"








# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# Machine learning integration utilities
# Machine learning integration utilities
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------








class FeatureExtractor:
@dataclass
    """Feature extraction for diverse chemical, structural, and quantum data."""
class FeatureBuilderConfig:


    fingerprint_size: int = 2048
    def __init__(self, fingerprint_size: int = 256) -> None:
    include_lambda: bool = True
        self.fingerprint_size = fingerprint_size
    lambda_pad: int = 16




class FeatureExtractor:
    """Feature extraction for diverse chemical, structural, and quantum data."""


    def __init__(
        self,
        feature_cfg: Optional[FeatureBuilderConfig] = None,
        rdkit_featurizer: Optional[Callable[[str], np.ndarray]] = None,
    ) -> None:
        self.feature_cfg = feature_cfg or FeatureBuilderConfig()
        self._rdkit_featurizer = rdkit_featurizer




    def _hash_sequence(self, sequence: str, size: Optional[int] = None) -> np.ndarray:␍␊
    def _hash_sequence(self, sequence: str, size: Optional[int] = None) -> np.ndarray:␊
        length = size or self.fingerprint_size
        length = size or self.feature_cfg.fingerprint_size
        if length <= 0:
        if length <= 0:
            length = 64
            length = 64
        vector = np.zeros(length, dtype=float)
        vector = np.zeros(length, dtype=float)
        if not sequence:
        if not sequence:
            return vector
            return vector
        for idx, char in enumerate(sequence):
        for idx, char in enumerate(sequence):
            bucket = (hash((char, idx)) % length + length) % length
            bucket = (hash((char, idx)) % length + length) % length
            vector[bucket] += 1.0
            vector[bucket] += 1.0
        norm = np.linalg.norm(vector)
        norm = np.linalg.norm(vector)
        if norm > 0:
        if norm > 0:
            vector /= norm
            vector /= norm
        return vector
        return vector




    def featurize_smiles(self, smiles: str) -> np.ndarray:
    def featurize_smiles(self, smiles: str) -> np.ndarray:
        return self._hash_sequence(smiles, self.fingerprint_size)
        if self._rdkit_featurizer is not None:
            return np.atleast_1d(self._rdkit_featurizer(smiles)).astype(float)
        return self._hash_sequence(smiles, self.feature_cfg.fingerprint_size)




    def featurize_sequence(self, sequence: str) -> np.ndarray:␍␊
    def featurize_sequence(self, sequence: str) -> np.ndarray:␊
        return self._hash_sequence(sequence, self.fingerprint_size // 2)
        return self._hash_sequence(sequence, self.feature_cfg.fingerprint_size // 2)




    def featurize_quantum_sample(self, sample: Dict[str, Any]) -> np.ndarray:
    def featurize_quantum_sample(self, sample: Dict[str, Any]) -> np.ndarray:
        orbital = np.array(sample.get("orbitalOccupations", [0.25, 0.25, 0.25, 0.25]), dtype=float)
        orbital = np.array(sample.get("orbitalOccupations", [0.25, 0.25, 0.25, 0.25]), dtype=float)
        entropy = float(sample.get("entanglementEntropy", 0.1))
        entropy = float(sample.get("entanglementEntropy", 0.1))
        binding = float(sample.get("bindingEnergy", -5.0))
        binding = float(sample.get("bindingEnergy", -5.0))
        fidelity = float(sample.get("fidelity", 0.95))
        fidelity = float(sample.get("fidelity", 0.95))
        lambda_fp = np.asarray(sample.get("lambdaShellFingerprint", [0.0] * 7), dtype=float)
        lambda_fp = np.asarray(sample.get("lambdaShellFingerprint", [0.0] * 7), dtype=float)
        descriptor = np.concatenate([
        descriptor = np.concatenate([
            np.array([binding, entropy, fidelity], dtype=float),
            np.array([binding, entropy, fidelity], dtype=float),
            orbital,
            orbital,
            lambda_fp[:7],
            lambda_fp[:7],
        ])
        ])
        return descriptor
        return descriptor




    def featurize_pocket(self, pocket: Dict[str, Any]) -> np.ndarray:
    def featurize_pocket(self, pocket: Dict[str, Any]) -> np.ndarray:
        properties = pocket.get("properties", {})
        properties = pocket.get("properties", {})
        vector = np.array(
        vector = np.array(
            [
            [
                float(pocket.get("druggabilityScore", 0.0)),
                float(pocket.get("druggabilityScore", 0.0)),
                float(properties.get("volume", 1.0)),
                float(properties.get("volume", 1.0)),
                float(properties.get("hydrophobicity", 0.5)),
                float(properties.get("hydrophobicity", 0.5)),
                float(properties.get("electrostaticPotential", -1.0)),
                float(properties.get("electrostaticPotential", -1.0)),
            ],
            ],
            dtype=float,
            dtype=float,
        )
        )
        return vector
        return vector




    def featurize_lambda_shells(self, descriptors: Iterable[Dict[str, Any]]) -> np.ndarray:␍␊
    def featurize_lambda_shells(self, descriptors: Iterable[Dict[str, Any]]) -> np.ndarray:␊
        vector: List[float] = []␍␊
        vector: List[float] = []␊
        for entry in descriptors:␍␊
        for entry in descriptors:␊
            vector.extend(␍␊
            vector.extend(␊
                [␍␊
                [␊
                    float(entry.get("lambdaRadius", 0.0)),
                    float(entry.get("lambdaRadius", 0.0)),
                    float(entry.get("lambdaCurvature", 0.0)),
                    float(entry.get("lambdaCurvature", 0.0)),
                    float(entry.get("lambdaEntropy", 0.0)),
                    float(entry.get("lambdaEntropy", 0.0)),
                    float(entry.get("lambdaEnergyDensity", 0.0)),
                    float(entry.get("lambdaEnergyDensity", 0.0)),
                    float(entry.get("lambdaBhattacharyya", 0.0)),
                    float(entry.get("lambdaBhattacharyya", 0.0)),
                    float(entry.get("lambdaOccupancy", 0.0)),
                    float(entry.get("lambdaOccupancy", 0.0)),
                    float(entry.get("lambdaLeakage", 0.0)),
                    float(entry.get("lambdaLeakage", 0.0)),
                ]
                ]
            )
        )
        if not vector:
        if not vector:
            vector = [0.0] * 7
            vector = [0.0] * 7
        return np.array(vector, dtype=float)
        return np.array(vector, dtype=float)




    def combine_features(self, *features: np.ndarray) -> np.ndarray:
    def featurize_lambda_prior(self, lambda_prior: Optional[LambdaPrior]) -> np.ndarray:
        if not features:
        if not self.feature_cfg.include_lambda or lambda_prior is None:
            return np.zeros(1, dtype=float)
            return np.zeros(self.feature_cfg.lambda_pad, dtype=float)
        flattened = [np.atleast_1d(feature).astype(float) for feature in features]
        vector = get_lambda_descriptor_vector(lambda_prior)
        return np.concatenate(flattened)
        if vector.size < self.feature_cfg.lambda_pad:
            padded = np.zeros(self.feature_cfg.lambda_pad, dtype=float)
            padded[: vector.size] = vector
            return padded
        return vector[: self.feature_cfg.lambda_pad]


    def build_feature_vector(
        self, smiles: str, lambda_prior: Optional[LambdaPrior] = None, *additional: np.ndarray
    ) -> np.ndarray:
        smiles_feat = self.featurize_smiles(smiles)
        lambda_feat = self.featurize_lambda_prior(lambda_prior)
        base = self.combine_features(smiles_feat, lambda_feat) if self.feature_cfg.include_lambda else smiles_feat
        if additional:
            base = self.combine_features(base, *additional)
        return base


    def combine_features(self, *features: np.ndarray) -> np.ndarray:
        if not features:
            return np.zeros(1, dtype=float)
        flattened = [np.atleast_1d(feature).astype(float) for feature in features]
        return np.concatenate(flattened)




def sanity_check_experiment(exp: ExperimentRecord) -> None:
    flags: List[str] = []


    if exp.docking_result:
        be = exp.docking_result.get("binding_energy")
        if be is not None and not (-30.0 <= float(be) <= -0.5):
            flags.append(f"binding_energy_out_of_range:{float(be):.2f}")
        rmsd = exp.docking_result.get("pose_rmsd")
        if rmsd is not None and (float(rmsd) < 0.0 or float(rmsd) > 10.0):
            flags.append(f"pose_rmsd_out_of_range:{float(rmsd):.2f}")


    if exp.qm_result:
        homo = exp.qm_result.get("homo")
        if homo is not None and not (-15.0 <= float(homo) <= 0.5):
            flags.append(f"homo_out_of_range:{float(homo):.2f}")
        lumo = exp.qm_result.get("lumo")
        if lumo is not None and not (-5.0 <= float(lumo) <= 5.0):
            flags.append(f"lumo_out_of_range:{float(lumo):.2f}")
        dipole = exp.qm_result.get("dipole_moment")
        if dipole is not None and (float(dipole) < 0.0 or float(dipole) > 20.0):
            flags.append(f"dipole_out_of_range:{float(dipole):.2f}")


    if exp.md_result:
        bound_fraction = exp.md_result.get("bound_fraction")
        if bound_fraction is not None:
            bf = np.asarray(bound_fraction, dtype=float)
            if bf.size and (bf.min() < -0.05 or bf.max() > 1.05):
                flags.append("md_bound_fraction_out_of_range")


    if exp.admet_result:
        herg = exp.admet_result.get("hERG_risk")
        if herg is not None and not (0.0 <= float(herg) <= 1.0):
            flags.append(f"herg_out_of_range:{float(herg):.2f}")
        sol = exp.admet_result.get("solubility")
        if sol is not None and (float(sol) < -15.0 or float(sol) > 10.0):
            flags.append(f"solubility_out_of_range:{float(sol):.2f}")


    if flags:
        exp.provenance.setdefault("sanityFlags", []).extend(flags)




def run_experiment_pipeline(
    ligand_id: str,
    smiles: str,
    ligand_coords: np.ndarray,
    target_id: str,
    pocket_coords: np.ndarray,
    pocket_center: np.ndarray,
    mode: SimulationMode,
    backend_registry: BackendRegistry,
    feature_extractor: FeatureExtractor,
    lambda_cfg: LambdaPriorConfig,
    phase5_params: Phase5Params,
    ligc_cfg: LigcConfig,
    stress_cfg: StressAlignParams,
    budget: AdiabaticBudget,
    allow_stub: bool = False,
    echo_ref_db: Optional[Callable[[str], Optional["EchoProfile"]]] = None,
) -> ExperimentRecord:
    if mode is not SimulationMode.DEBUG_SYNTHETIC and allow_stub:
        raise RuntimeError("allow_stub is forbidden for benchmark/production modes")


    canonical_smiles = sanitize_smiles(smiles, strict=mode is not SimulationMode.DEBUG_SYNTHETIC)
    if canonical_smiles is None:
        raise ValueError(f"Invalid SMILES provided for ligand {ligand_id}")
    mol_rec = MoleculeRecord(ligand_id=ligand_id, smiles=canonical_smiles, coordinates=ligand_coords)
    tgt_rec = TargetRecord(target_id=target_id, pocket_center=pocket_center, pocket_coordinates=pocket_coords)


    if pocket_coords is None or pocket_coords.size == 0 or not np.isfinite(pocket_coords).all():
        raise RuntimeError("Pocket coordinates are required for production simulations")


    exp = ExperimentRecord(ligand_id=ligand_id, target_id=target_id)
    exp.set_mode(mode)
    set_global_simulation_mode(mode, allow_stub=False)
    exp.provenance["backends"] = dict(backend_registry.metadata)
    exp.provenance["stubBackends"] = False
    exp.provenance["simulationMode"] = mode.value




    exp.qm_result = backend_registry.run_qm(mol_rec, mode, allow_stub=allow_stub)
    exp.docking_result = backend_registry.run_docking(mol_rec, tgt_rec, mode, allow_stub=allow_stub)
    exp.md_result = backend_registry.run_md(mol_rec, tgt_rec, mode, allow_stub=allow_stub)
    exp.admet_result = backend_registry.run_admet(canonical_smiles, mode, allow_stub=allow_stub)


    exp.lambda_prior = build_lambda_prior_for_complex(mol_rec, tgt_rec, lambda_cfg)


    complex_grid = SpatialGrid(coordinates=pocket_coords)
    exp.phase5_prior = build_phase5_covariant_prior(complex_grid, phase5_params)
    if exp.phase5_prior is not None:
        exp.features["phase5_einstein_l2"] = exp.phase5_prior.einstein_residual.get("l2")
        exp.features["phase5_einstein_max"] = exp.phase5_prior.einstein_residual.get("max")


    build_energy_profile_from_results(exp, lambda_cfg.num_z)


    shape = ligc_cfg.grid_shape
    base_energy = float(exp.docking_result.get("binding_energy", -5.0)) if exp.docking_result else -5.0
    exp.ricci_field = np.zeros(shape, dtype=float)
    exp.entropy_field = np.zeros(shape, dtype=float)
    exp.energy_field = np.full(shape, base_energy, dtype=float)


    z_grid = exp.lambda_prior.z if exp.lambda_prior is not None else np.linspace(-1.0, 1.0, lambda_cfg.num_z)
    exp.stress_alignment = renormalize_experiment_stress(exp, z_grid, stress_cfg)
    exp.ligc_result = compute_ligc_for_experiment(exp, ligc_cfg)


    einstein_tol = getattr(stress_cfg, "einstein_tol", 5.0)
    exp.provenance["einstein_ok"] = bool(exp.stress_alignment and exp.stress_alignment.final_l2 < einstein_tol)
    if exp.ligc_result is not None:
        exp.provenance["ligc_status"] = exp.ligc_result.status
        exp.provenance["ligc_consistency_score"] = 1.0 / (1.0 + exp.ligc_result.variance)


    update_budget_with_experiment(budget, exp)
    if not budget.rg_stability_flag:
        exp.provenance["rg_unstable"] = True
    exp.provenance.setdefault("usable_in_training", True)
    if not exp.provenance.get("einstein_ok", True) or exp.provenance.get("rg_unstable", False):
        exp.provenance["usable_in_training"] = False
    if exp.ligc_result is not None and exp.ligc_result.status == "marginal" and exp.ligc_result.variance > 1.0:
        exp.provenance["usable_in_training"] = False


    if exp.md_result and "time" in exp.md_result and "bound_fraction" in exp.md_result:
        from echo_validator import EchoCompareConfig, EchoProfile


        sim_profile = EchoProfile(
            time=np.asarray(exp.md_result["time"], dtype=float),
            amplitude=np.asarray(exp.md_result["bound_fraction"], dtype=float),
        )
        ref_profile = echo_ref_db(target_id) if echo_ref_db else None
        if ref_profile is not None:
            cfg = EchoCompareConfig()
            exp.attach_echo_result(sim_profile, ref_profile, cfg)


    feat_vec = feature_extractor.build_feature_vector(canonical_smiles, exp.lambda_prior)
    exp.features["lambda_enhanced_vector"] = feat_vec


    sanity_check_experiment(exp)


    return exp








@dataclass
@dataclass
class BenchmarkDatasetRecord:
class BenchmarkDatasetRecord:
    dataset: str
    dataset: str
    task: str
    task: str
    smiles: str
    smiles: str
    label: float
    label: float
    metadata: Dict[str, Any]
    metadata: Dict[str, Any]








class BenchmarkDatasetUtility:␍␊
class BenchmarkDatasetUtility:␊
    """Downloads and preprocesses benchmark datasets into unified records."""
    """Downloads and preprocesses benchmark datasets into unified records."""




    SOURCES: Dict[str, Dict[str, Any]] = {
    SOURCES: Dict[str, Dict[str, Any]] = {
        "DUD-E": {
        "DUD-E": {
            "url": "https://raw.githubusercontent.com/deepchem/deepchem/master/examples/assets/dude.csv",
            "url": "https://raw.githubusercontent.com/deepchem/deepchem/master/examples/assets/dude.csv",
            "format": "csv",
            "format": "csv",
            "columns": {"smiles": "smiles", "label": "label"},
            "columns": {"smiles": "smiles", "label": "label"},
        },
        },
        "ChEMBL": {
        "ChEMBL": {
            "url": "https://raw.githubusercontent.com/chembl/chembl_webresource_client/master/chembl_webresource_client/tests/resources/activity_sample.csv",
            "url": "https://raw.githubusercontent.com/chembl/chembl_webresource_client/master/chembl_webresource_client/tests/resources/activity_sample.csv",
            "format": "csv",
            "format": "csv",
            "columns": {"smiles": "canonical_smiles", "label": "standard_value"},
            "columns": {"smiles": "canonical_smiles", "label": "standard_value"},
        },
        },
        "ZINC15": {
        "ZINC15": {
            "url": "https://raw.githubusercontent.com/deepchem/deepchem/master/examples/assets/zinc15_sample.csv",
            "url": "https://raw.githubusercontent.com/deepchem/deepchem/master/examples/assets/zinc15_sample.csv",
            "format": "csv",
            "format": "csv",
            "columns": {"smiles": "smiles", "label": None},
            "columns": {"smiles": "smiles", "label": None},
        },
        },
    }
    }




    def __init__(self, cache_dir: Path | None = None) -> None:
    def __init__(self, cache_dir: Path | None = None) -> None:
        self.cache_dir = cache_dir or Path("datasets")
        self.cache_dir = cache_dir or Path("datasets")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.cache_dir.mkdir(parents=True, exist_ok=True)




    def _download(self, dataset: str) -> Optional[Path]:
    def _download(self, dataset: str) -> Optional[Path]:
@@ -964,63 +1192,67 @@ class BenchmarkDatasetUtility:
            reader = csv.DictReader(handle)
            reader = csv.DictReader(handle)
            for idx, row in enumerate(reader):
            for idx, row in enumerate(reader):
                if limit and idx >= limit:
                if limit and idx >= limit:
                    break
                    break
                smiles = row.get(columns.get("smiles", "smiles"), "")
                smiles = row.get(columns.get("smiles", "smiles"), "")
                if not smiles:
                if not smiles:
                    continue
                    continue
                raw_label = float(row.get(label_column, 0.0)) if label_column else 0.0
                raw_label = float(row.get(label_column, 0.0)) if label_column else 0.0
                label = raw_label
                label = raw_label
                if dataset == "ChEMBL":
                if dataset == "ChEMBL":
                    label = 1.0 if raw_label and raw_label < 1000 else 0.0
                    label = 1.0 if raw_label and raw_label < 1000 else 0.0
                elif dataset == "ZINC15":
                elif dataset == "ZINC15":
                    label = 0.5  # availability only
                    label = 0.5  # availability only
                metadata = {"sourceRow": idx, "raw": row}
                metadata = {"sourceRow": idx, "raw": row}
                records.append(
                records.append(
                    BenchmarkDatasetRecord(
                    BenchmarkDatasetRecord(
                        dataset=dataset,
                        dataset=dataset,
                        task=f"benchmark.{dataset.lower()}",
                        task=f"benchmark.{dataset.lower()}",
                        smiles=smiles,
                        smiles=smiles,
                        label=float(label),
                        label=float(label),
                        metadata=metadata,
                        metadata=metadata,
                    )
                    )
                )
                )
        return records
        return records




    def load(self, dataset: str, limit: int = 500) -> List[BenchmarkDatasetRecord]:
    def load(self, dataset: str, mode: SimulationMode, limit: int = 500) -> List[BenchmarkDatasetRecord]:
        spec = self.SOURCES.get(dataset)
        spec = self.SOURCES.get(dataset)
        if spec is None:
        if spec is None:
            return []
            return []
        path = self._download(dataset)
        path = self._download(dataset)
        if path is not None and spec.get("format") == "csv":
        if path is not None and spec.get("format") == "csv":
            try:
            try:
                return self._load_csv(dataset, path, spec["columns"], limit)
                return self._load_csv(dataset, path, spec["columns"], limit)
            except Exception as exc:  # pragma: no cover - defensive
            except Exception as exc:  # pragma: no cover - defensive
                logging.warning("Failed to parse %s dataset: %s", dataset, exc)
                logging.warning("Failed to parse %s dataset: %s", dataset, exc)
        logging.info("Falling back to synthetic %s benchmark records", dataset)
        if mode is not SimulationMode.DEBUG_SYNTHETIC:
        rng = np.random.default_rng(DEFAULT_RANDOM_SEED)
            raise RuntimeError(
        synthetic: List[BenchmarkDatasetRecord] = []
                f"Dataset {dataset} unavailable in mode {mode.value}; synthetic benchmarks are forbidden outside DEBUG_SYNTHETIC"
            )
        logging.info("Falling back to synthetic %s benchmark records", dataset)
        rng = np.random.default_rng(DEFAULT_RANDOM_SEED)
        synthetic: List[BenchmarkDatasetRecord] = []
        for idx in range(limit):
        for idx in range(limit):
            smiles = f"C{idx}H{idx}O{idx%3}"
            smiles = f"C{idx}H{idx}O{idx%3}"
            label = float(rng.random())
            label = float(rng.random())
            synthetic.append(
            synthetic.append(
                BenchmarkDatasetRecord(
                BenchmarkDatasetRecord(
                    dataset=dataset,
                    dataset=dataset,
                    task=f"benchmark.{dataset.lower()}",
                    task=f"benchmark.{dataset.lower()}",
                    smiles=smiles,
                    smiles=smiles,
                    label=label,
                    label=label,
                    metadata={"synthetic": True, "index": idx},
                    metadata={"synthetic": True, "index": idx},
                )
                )
            )
            )
        return synthetic
        return synthetic




@dataclass
@dataclass
class DatasetSplit:
class DatasetSplit:
    train_X: np.ndarray
    train_X: np.ndarray
    train_y: np.ndarray
    train_y: np.ndarray
    val_X: np.ndarray
    val_X: np.ndarray
    val_y: np.ndarray
    val_y: np.ndarray
    test_X: np.ndarray
    test_X: np.ndarray
    test_y: np.ndarray
    test_y: np.ndarray
    normalization: Dict[str, np.ndarray]
    normalization: Dict[str, np.ndarray]
    metadata: Dict[str, Any]
    metadata: Dict[str, Any]




@@ -1088,97 +1320,99 @@ class DatasetManager:
        split = DatasetSplit(
        split = DatasetSplit(
            norm_train_X,
            norm_train_X,
            train_y,
            train_y,
            norm_val_X,
            norm_val_X,
            val_y,
            val_y,
            norm_test_X,
            norm_test_X,
            test_y,
            test_y,
            normalization,
            normalization,
            {"records": len(records)},
            {"records": len(records)},
        )
        )
        self.splits[task] = split
        self.splits[task] = split
        return split
        return split




    def get_split(self, task: str) -> Optional[DatasetSplit]:
    def get_split(self, task: str) -> Optional[DatasetSplit]:
        return self.splits.get(task)
        return self.splits.get(task)




    def get_task_type(self, task: str) -> str:
    def get_task_type(self, task: str) -> str:
        return self.task_types.get(task, "regression")
        return self.task_types.get(task, "regression")




    def augment_with_quantum_samples(self, task: str, samples: List[Dict[str, Any]], target_key: str) -> None:
    def augment_with_quantum_samples(self, task: str, samples: List[Dict[str, Any]], target_key: str) -> None:
        for sample in samples:
        for sample in samples:
            features = self.feature_extractor.featurize_quantum_sample(sample)
            features = self.feature_extractor.featurize_quantum_sample(sample)
            label = float(sample.get(target_key, 0.0))
            label = float(sample.get(target_key, 0.0))
            self.register_record(task, features, label, {"source": "quantum_reference", "ligandId": sample.get("ligandId")})
            self.register_record(task, features, label, {"source": "quantum_reference", "ligandId": sample.get("ligandId")})




    def integrate_benchmark_dataset(
    def integrate_benchmark_dataset(
        self,
        self,
        dataset: str,
        dataset: str,
        context: QuantumContext,
        context: QuantumContext,
        limit: int = 500,
        mode: SimulationMode,
    ) -> Dict[str, Any]:
        limit: int = 500,
        records = self.benchmark_utility.load(dataset, limit)
    ) -> Dict[str, Any]:
        records = self.benchmark_utility.load(dataset, mode, limit)
        lambda_fp = np.asarray(LambdaScalingToolkit.fingerprint(context.lambda_shells), dtype=float)
        lambda_fp = np.asarray(LambdaScalingToolkit.fingerprint(context.lambda_shells), dtype=float)
        lambda_shell_features = self.feature_extractor.featurize_lambda_shells(context.lambda_shells)
        lambda_shell_features = self.feature_extractor.featurize_lambda_shells(context.lambda_shells)
        ingested = 0
        ingested = 0
        last_task = f"benchmark.{dataset.lower()}"
        last_task = f"benchmark.{dataset.lower()}"
        for record in records:
        for record in records:
            smiles_feat = self.feature_extractor.featurize_smiles(record.smiles)
            smiles_feat = self.feature_extractor.featurize_smiles(record.smiles)
            feature_vec = self.feature_extractor.combine_features(smiles_feat, lambda_shell_features)
            feature_vec = self.feature_extractor.combine_features(smiles_feat, lambda_shell_features)
            feature_vec = self.feature_extractor.combine_features(feature_vec, lambda_fp)
            feature_vec = self.feature_extractor.combine_features(feature_vec, lambda_fp)
            metadata = {"dataset": dataset, **record.metadata}
            metadata = {"dataset": dataset, **record.metadata}
            self.register_record(record.task, feature_vec, record.label, metadata)
            self.register_record(record.task, feature_vec, record.label, metadata)
            ingested += 1
            ingested += 1
            last_task = record.task
            last_task = record.task
        if ingested:
        if ingested:
            split = self.build_split(last_task)
            split = self.build_split(last_task)
            normalization_summary: Dict[str, Any] = {}
            normalization_summary: Dict[str, Any] = {}
            if split and isinstance(split.normalization, dict):
            if split and isinstance(split.normalization, dict):
                normalization_summary = {
                normalization_summary = {
                    key: np.asarray(value).tolist()
                    key: np.asarray(value).tolist()
                    for key, value in split.normalization.items()
                    for key, value in split.normalization.items()
                }
                }
            self.benchmark_metadata[dataset] = {
            self.benchmark_metadata[dataset] = {
                "records": ingested,
                "records": ingested,
                "task": last_task,
                "task": last_task,
                "taskType": self.get_task_type(last_task),
                "taskType": self.get_task_type(last_task),
                "normalization": normalization_summary,
                "normalization": normalization_summary,
            }
            }
        else:
        else:
            self.benchmark_metadata[dataset] = {"records": 0, "task": f"benchmark.{dataset.lower()}"}
            self.benchmark_metadata[dataset] = {"records": 0, "task": f"benchmark.{dataset.lower()}"}
        return self.benchmark_metadata[dataset]
        return self.benchmark_metadata[dataset]




    def prepare_benchmarks(
    def prepare_benchmarks(
        self,
        self,
        datasets: Sequence[str],
        datasets: Sequence[str],
        context: QuantumContext,
        context: QuantumContext,
        limit: int = 500,
        limit: int = 500,
    ) -> Dict[str, Any]:
        mode: SimulationMode = _GLOBAL_SIM_MODE,
        summary: Dict[str, Any] = {}
    ) -> Dict[str, Any]:
        for name in datasets:
        summary: Dict[str, Any] = {}
            summary[name] = self.integrate_benchmark_dataset(name, context, limit=limit)
        for name in datasets:
        return summary
            summary[name] = self.integrate_benchmark_dataset(name, context, mode=mode, limit=limit)
        return summary








class StatisticalValidationEngine:
class StatisticalValidationEngine:
    """Computes statistical metrics and manages validation history."""
    """Computes statistical metrics and manages validation history."""




    def __init__(self, random_seed: int = DEFAULT_RANDOM_SEED) -> None:
    def __init__(self, random_seed: int = DEFAULT_RANDOM_SEED) -> None:
        self.random_seed = random_seed
        self.random_seed = random_seed
        self.history: List[Dict[str, Any]] = []
        self.history: List[Dict[str, Any]] = []




    @staticmethod
    @staticmethod
    def _bhattacharyya_divergence(p: np.ndarray, q: np.ndarray) -> float:
    def _bhattacharyya_divergence(p: np.ndarray, q: np.ndarray) -> float:
        p_sum = float(np.sum(p))
        p_sum = float(np.sum(p))
        q_sum = float(np.sum(q))
        q_sum = float(np.sum(q))
        if p_sum == 0 or q_sum == 0:
        if p_sum == 0 or q_sum == 0:
            return float("inf")
            return float("inf")
        p_norm = p / p_sum
        p_norm = p / p_sum
        q_norm = q / q_sum
        q_norm = q / q_sum
        coefficient = float(np.sum(np.sqrt(p_norm * q_norm)))
        coefficient = float(np.sum(np.sqrt(p_norm * q_norm)))
        coefficient = float(np.clip(coefficient, 1e-9, 1.0))
        coefficient = float(np.clip(coefficient, 1e-9, 1.0))
        return float(-math.log(coefficient))
        return float(-math.log(coefficient))




    @staticmethod
    @staticmethod
    def _simple_auc(y_true: np.ndarray, scores: np.ndarray) -> float:
    def _simple_auc(y_true: np.ndarray, scores: np.ndarray) -> float:
        order = np.argsort(scores)
        order = np.argsort(scores)
        y_sorted = y_true[order]
        y_sorted = y_true[order]
@@ -5666,89 +5900,111 @@ class JobStatusAgent(AgentBase):
                if self.active_learning:
                if self.active_learning:
                    self.active_learning.evaluate_samples(
                    self.active_learning.evaluate_samples(
                        task_name,
                        task_name,
                        [feature_vec],
                        [feature_vec],
                        preds,
                        preds,
                        uncert,
                        uncert,
                        [{"jobId": report["jobId"]}],
                        [{"jobId": report["jobId"]}],
                    )
                    )
                if self.ml_api:
                if self.ml_api:
                    self.ml_api.register_endpoint("operations/runtime", task_name, model.version)
                    self.ml_api.register_endpoint("operations/runtime", task_name, model.version)
                    self.ml_api.log_call(
                    self.ml_api.log_call(
                        "operations/runtime",
                        "operations/runtime",
                        {"jobId": report["jobId"]},
                        {"jobId": report["jobId"]},
                        {"runtimeForecast": ml_section["runtimeForecast"]},
                        {"runtimeForecast": ml_section["runtimeForecast"]},
                    )
                    )
        validated = self.validator.validate(self.name, report)
        validated = self.validator.validate(self.name, report)
        await self.blackboard.post("status", validated)
        await self.blackboard.post("status", validated)
        return validated
        return validated








# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# Orchestration layer built on Golden Turing AI
# Orchestration layer built on Golden Turing AI
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------








class DrugDiscoverySimulation:
class DrugDiscoverySimulation:
    def __init__(
    def __init__(
        self,
        self,
        pdb_id: str,
        pdb_id: str,
        target_query: str,
        target_query: str,
        uniprot_accession: str,
        uniprot_accession: str,
        llm_model_path: Path,
        llm_model_path: Path,
        random_seed: int = DEFAULT_RANDOM_SEED,
        random_seed: int = DEFAULT_RANDOM_SEED,
    ) -> None:
        simulation_config: SimulationConfig | None = None,
        self.pdb_id = pdb_id
    ) -> None:
        self.target_query = target_query
        self.pdb_id = pdb_id
        self.uniprot_accession = uniprot_accession
        self.target_query = target_query
        self.llm_model_path = llm_model_path
        self.uniprot_accession = uniprot_accession
        self.random_seed = random_seed
        self.llm_model_path = llm_model_path
        set_global_random_seed(self.random_seed)
        self.random_seed = random_seed
        self.data_client = PublicDataClient()
        self.simulation_config = simulation_config or SimulationConfig()
        set_global_random_seed(self.random_seed)
        set_global_simulation_mode(self.simulation_config.mode, allow_stub=self.simulation_config.allow_stub)
        self.backend_registry = BackendRegistry()
        if self.simulation_config.allow_stub and self.simulation_config.mode is not SimulationMode.DEBUG_SYNTHETIC:
            raise RuntimeError("allow_stub is forbidden for benchmark or production modes")


        self.backend_registry.register_qm_backend(
            compute_qm_properties, name=self.simulation_config.qm_backend or "deterministic-qm"
        )
        self.backend_registry.register_docking_backend(
            dock_ligand_to_target, name=self.simulation_config.docking_backend or "deterministic-docking"
        )
        self.backend_registry.register_md_backend(
            run_md_for_complex, name=self.simulation_config.md_backend or "deterministic-md"
        )
        self.backend_registry.register_admet_backend(
            predict_admet, name=self.simulation_config.admet_backend or "deterministic-admet"
        )
        self.backend_registry.validate_backends_for_mode(
            self.simulation_config.mode, allow_stub=self.simulation_config.allow_stub
        )
        self.data_client = PublicDataClient()
        self.geometry = GeometryParams()
        self.geometry = GeometryParams()
        self.field = FieldParams()
        self.field = FieldParams()
        self.ent_params = EntanglementParams()
        self.ent_params = EntanglementParams()
        self.quantum_engine = QuantumPhysicsEngine(self.geometry, self.field, self.ent_params)
        self.quantum_engine = QuantumPhysicsEngine(self.geometry, self.field, self.ent_params)
        self.context = self.quantum_engine.compute_quantum_context()
        self.context = self.quantum_engine.compute_quantum_context()
        self.blackboard = QuantumBlackboard()
        self.blackboard = QuantumBlackboard()
        self.llm = LightweightLLM(llm_model_path)
        self.llm = LightweightLLM(llm_model_path)
        self.GoldenTuringAI = load_golden_turing_ai()
        self.GoldenTuringAI = load_golden_turing_ai()
        self.core_ai = self.GoldenTuringAI(config={"ai_state_dim": 64})
        self.core_ai = self.GoldenTuringAI(config={"ai_state_dim": 64})
        self.core_ai.inject_blackboard_interface(self.blackboard)
        self.core_ai.inject_blackboard_interface(self.blackboard)
        self.quantum_circuit_engine = QuantumCircuitEngine(self.context)
        self.quantum_circuit_engine = QuantumCircuitEngine(self.context)
        self.memory_api = QuantumMemoryAPI()
        self.memory_api = QuantumMemoryAPI()
        seed_ligands = [f"{self.target_query}-seed-{idx}" for idx in range(3)] + ["lig-novel-001"]
        seed_ligands = [f"{self.target_query}-seed-{idx}" for idx in range(3)] + ["lig-novel-001"]
        try:
        try:
            self.quantum_reference = self.quantum_circuit_engine.generate_reference_dataset(seed_ligands)
            self.quantum_reference = self.quantum_circuit_engine.generate_reference_dataset(seed_ligands)
        except Exception as exc:  # pragma: no cover - defensive fallback
        except Exception as exc:  # pragma: no cover - defensive fallback
            self.quantum_reference = {
            self.quantum_reference = {
                "samples": [],
                "samples": [],
                "statistics": {"energyRange": {"min": -40.0, "max": -2.0}, "meanEnergy": -12.0, "meanEntropy": 0.4},
                "statistics": {"energyRange": {"min": -40.0, "max": -2.0}, "meanEnergy": -12.0, "meanEntropy": 0.4},
                "error": str(exc),
                "error": str(exc),
            }
            }
        self.validator = PhysicalValidator(self.context, self.quantum_reference)
        self.validator = PhysicalValidator(self.context, self.quantum_reference)
        self.feature_extractor = FeatureExtractor()
        self.feature_extractor = FeatureExtractor(rdkit_featurizer=default_rdkit_featurizer())
        self.dataset_manager = DatasetManager(
        self.dataset_manager = DatasetManager(
            self.feature_extractor,
            self.feature_extractor,
            random_seed=self.random_seed,
            random_seed=self.random_seed,
        )
        )
        self.ml_registry = MLModelRegistry()
        self.ml_registry = MLModelRegistry()
        self.active_learning = ActiveLearningCoordinator()
        self.active_learning = ActiveLearningCoordinator()
        self.ml_api = MLInferenceAPI()
        self.ml_api = MLInferenceAPI()
        shared_model_cfg = {
        shared_model_cfg = {
            "affinityModelPath": os.getenv("DDS_AFFINITY_MODEL_PATH"),
            "affinityModelPath": os.getenv("DDS_AFFINITY_MODEL_PATH"),
            "toxModelPath": os.getenv("DDS_TOX_MODEL_PATH"),
            "toxModelPath": os.getenv("DDS_TOX_MODEL_PATH"),
            "synthModelPath": os.getenv("DDS_SYNTH_MODEL_PATH"),
            "synthModelPath": os.getenv("DDS_SYNTH_MODEL_PATH"),
        }
        }
        self.agent_model_configs = {
        self.agent_model_configs = {
            "LigandDiscoveryAgent": dict(shared_model_cfg),
            "LigandDiscoveryAgent": dict(shared_model_cfg),
            "ScreeningAgent": dict(shared_model_cfg),
            "ScreeningAgent": dict(shared_model_cfg),
            "SafetyAgent": dict(shared_model_cfg),
            "SafetyAgent": dict(shared_model_cfg),
            "SynthesisPlannerAgent": dict(shared_model_cfg),
            "SynthesisPlannerAgent": dict(shared_model_cfg),
            "IPAgent": dict(shared_model_cfg),
            "IPAgent": dict(shared_model_cfg),
        }
        }
        self.quantum_agent_config = {
        self.quantum_agent_config = {
            "alpha_calibration": 0.3,
            "alpha_calibration": 0.3,
            "enable_pm6": True,
            "enable_pm6": True,
            "mmff_pre_screen_threshold": -3.0,
            "mmff_pre_screen_threshold": -3.0,
        }
        }
        self.validation_engine = StatisticalValidationEngine(random_seed=self.random_seed)
        self.validation_engine = StatisticalValidationEngine(random_seed=self.random_seed)
@@ -5851,52 +6107,57 @@ class DrugDiscoverySimulation:
                    0.0,
                    0.0,
                    0.0,
                    0.0,
                ],
                ],
                dtype=float,
                dtype=float,
            )
            )
            lambda_feat = self.feature_extractor.featurize_lambda_shells(self.context.lambda_shells)
            lambda_feat = self.feature_extractor.featurize_lambda_shells(self.context.lambda_shells)
            lambda_latent = np.asarray(
            lambda_latent = np.asarray(
                LambdaScalingToolkit.fingerprint(self.context.lambda_shells),
                LambdaScalingToolkit.fingerprint(self.context.lambda_shells),
                dtype=float,
                dtype=float,
            )
            )
            feature_vec = self.feature_extractor.combine_features(base_vec, lambda_feat)
            feature_vec = self.feature_extractor.combine_features(base_vec, lambda_feat)
            feature_vec = self.feature_extractor.combine_features(feature_vec, lambda_latent)
            feature_vec = self.feature_extractor.combine_features(feature_vec, lambda_latent)
            self.dataset_manager.register_record(
            self.dataset_manager.register_record(
                "safety.toxicity",
                "safety.toxicity",
                feature_vec,
                feature_vec,
                0.0,
                0.0,
                {"ligandId": f"seed-{idx}", "source": "bootstrap"},
                {"ligandId": f"seed-{idx}", "source": "bootstrap"},
            )
            )
        safety_split = self.dataset_manager.build_split("safety.toxicity")
        safety_split = self.dataset_manager.build_split("safety.toxicity")
        if safety_split.train_X.size:
        if safety_split.train_X.size:
            metrics = {"mae": 0.0, "rmse": 0.0, "r2": 0.0, "bhattacharyya": 0.0}
            metrics = {"mae": 0.0, "rmse": 0.0, "r2": 0.0, "bhattacharyya": 0.0}
            self.validation_engine.log_evaluation("bootstrap.safety.toxicity", metrics)
            self.validation_engine.log_evaluation("bootstrap.safety.toxicity", metrics)
            step = len(self.visualizer.metric_history["bootstrap.safety.toxicity"])
            step = len(self.visualizer.metric_history["bootstrap.safety.toxicity"])
            self.visualizer.log_metrics("bootstrap.safety.toxicity", step, metrics)
            self.visualizer.log_metrics("bootstrap.safety.toxicity", step, metrics)




        benchmark_names = ("DUD-E", "ChEMBL", "ZINC15")
        benchmark_names = tuple(self.simulation_config.benchmark_datasets or [])
        self.benchmark_summary = self.dataset_manager.prepare_benchmarks(benchmark_names, self.context, limit=200)
        if benchmark_names:
            self.benchmark_summary = self.dataset_manager.prepare_benchmarks(
                benchmark_names, self.context, limit=200, mode=self.simulation_config.mode
            )
        else:
            self.benchmark_summary = {}




        for task in ("quantum.highAffinity", "safety.toxicity"):
        for task in ("quantum.highAffinity", "safety.toxicity"):
            records = self.dataset_manager.records.get(task, [])
            records = self.dataset_manager.records.get(task, [])
            if not records:
            if not records:
                continue
                continue
            features = np.stack([entry["features"] for entry in records])
            features = np.stack([entry["features"] for entry in records])
            labels = np.array([entry["label"] for entry in records], dtype=float)
            labels = np.array([entry["label"] for entry in records], dtype=float)
            task_type = self.dataset_manager.get_task_type(task)
            task_type = self.dataset_manager.get_task_type(task)
            if task_type == "classification" and RandomForestClassifier is not None:
            if task_type == "classification" and RandomForestClassifier is not None:
                factory: Callable[[], Any] = lambda: RandomForestClassifier(n_estimators=64, random_state=self.random_seed)
                factory: Callable[[], Any] = lambda: RandomForestClassifier(n_estimators=64, random_state=self.random_seed)
            elif task_type == "regression" and RandomForestRegressor is not None:
            elif task_type == "regression" and RandomForestRegressor is not None:
                factory = lambda: RandomForestRegressor(n_estimators=64, random_state=self.random_seed)
                factory = lambda: RandomForestRegressor(n_estimators=64, random_state=self.random_seed)
            else:
            else:
                factory = lambda: GraphSurrogateModel(f"kfold-{task}")
                factory = lambda: GraphSurrogateModel(f"kfold-{task}")
            result = self.validation_engine.k_fold_cross_validation(factory, features, labels, folds=5, task_type=task_type)
            result = self.validation_engine.k_fold_cross_validation(factory, features, labels, folds=5, task_type=task_type)
            self.cross_validation_results[task] = result
            self.cross_validation_results[task] = result
            aggregate = result.get("aggregate", {})
            aggregate = result.get("aggregate", {})
            if aggregate:
            if aggregate:
                self.validation_engine.log_evaluation(f"kfold.{task}", aggregate)
                self.validation_engine.log_evaluation(f"kfold.{task}", aggregate)
                step = len(self.visualizer.metric_history[f"kfold.{task}"])
                step = len(self.visualizer.metric_history[f"kfold.{task}"])
                self.visualizer.log_metrics(f"kfold.{task}", step, aggregate)
                self.visualizer.log_metrics(f"kfold.{task}", step, aggregate)




        self.baseline_results = self.baseline_suite.train_and_evaluate(self.dataset_manager)
        self.baseline_results = self.baseline_suite.train_and_evaluate(self.dataset_manager)
        for task, details in self.baseline_results.items():
        for task, details in self.baseline_results.items():
            comparison = details.get("comparison", {})
            comparison = details.get("comparison", {})
@@ -6825,74 +7086,126 @@ class DrugDiscoverySimulation:
                "stepMetrics": entry.get("stepMetrics"),
                "stepMetrics": entry.get("stepMetrics"),
                "contextDiff": entry.get("contextDiff"),
                "contextDiff": entry.get("contextDiff"),
            }
            }
            for entry in self.agent_traces
            for entry in self.agent_traces
        ]
        ]
        shell_log_summary = {
        shell_log_summary = {
            "entries": len(self.shell_log),
            "entries": len(self.shell_log),
            "stages": [entry.get("stage") for entry in self.shell_log],
            "stages": [entry.get("stage") for entry in self.shell_log],
            "entropyMeanTrajectory": [entry.get("entropyMean") for entry in self.shell_log],
            "entropyMeanTrajectory": [entry.get("entropyMean") for entry in self.shell_log],
            "bhattacharyyaTrajectory": [entry.get("bhattacharyyaMean") for entry in self.shell_log],
            "bhattacharyyaTrajectory": [entry.get("bhattacharyyaMean") for entry in self.shell_log],
        }
        }
        final_shell_state = self.shell_log[-1] if self.shell_log else None
        final_shell_state = self.shell_log[-1] if self.shell_log else None
        summary_payload = {
        summary_payload = {
            "generatedAt": timestamp.isoformat() + "Z",
            "generatedAt": timestamp.isoformat() + "Z",
            "runtimeSeconds": float(time.time() - run_start),
            "runtimeSeconds": float(time.time() - run_start),
            "finalShellState": final_shell_state,
            "finalShellState": final_shell_state,
            "shellLogSummary": shell_log_summary,
            "shellLogSummary": shell_log_summary,
            "agentTraceSummaries": agent_trace_summaries,
            "agentTraceSummaries": agent_trace_summaries,
            "predictions": {
            "predictions": {
                "topLigandCandidates": ligand_predictions[:5],
                "topLigandCandidates": ligand_predictions[:5],
                "screeningPredictions": screening_predictions[:5],
                "screeningPredictions": screening_predictions[:5],
                "safetyAssessment": safety_assessment,
                "safetyAssessment": safety_assessment,
            },
            },
        }
        }
        summary_path = output_dir / f"simulation_metrics_{timestamp.strftime('%Y%m%dT%H%M%SZ')}.json"
        summary_path = output_dir / f"simulation_metrics_{timestamp.strftime('%Y%m%dT%H%M%SZ')}.json"
        summary_path.write_text(json.dumps(self._sanitize_for_json(summary_payload), indent=2))
        summary_path.write_text(json.dumps(self._sanitize_for_json(summary_payload), indent=2))
        reports["instrumentation"] = {
        reports["instrumentation"] = {
            "shellTrace": str(shell_trace_path),
            "shellTrace": str(shell_trace_path),
            "agentTrace": str(self.agent_trace_path),
            "agentTrace": str(self.agent_trace_path),
            "summary": str(summary_path),
            "summary": str(summary_path),
        }
        }
        return reports
        return reports






    def run_single_experiment(
# ---------------------------------------------------------------------------
        self, ligand_smiles: str, ligand_id: str | None = None, coordinates: Optional[np.ndarray] = None
# CLI entrypoint
    ) -> ExperimentRecord:
        """Lightweight entrypoint for orchestrators and RL agents."""


        ligand_identifier = ligand_id or ligand_smiles
        target_id = self.target_query
        pocket_coords = np.zeros((0, 3), dtype=float)
        pocket_center = np.zeros(3, dtype=float)


        lambda_cfg = self.simulation_config.lambda_cfg or LambdaPriorConfig(
            lam=LAMBDA_DILATION, z_min=-5.0, z_max=5.0, num_z=64
        )
        phase5_params = self.simulation_config.phase5_params or Phase5Params()
        ligc_cfg = self.simulation_config.ligc_cfg or LigcConfig(grid_shape=(4, 4, 4))
        stress_cfg = self.simulation_config.stress_cfg or StressAlignParams()
        wbs_cfg = WBSConfig(lam=lambda_cfg.lam, epsilon_ladder=[0.1, 0.05, 0.01])
        budget = initialize_budget_from_lambda_wbs(wbs_cfg)


        return run_experiment_pipeline(
            ligand_identifier,
            ligand_smiles,
            coordinates if coordinates is not None else np.zeros((0, 3), dtype=float),
            target_id,
            pocket_coords,
            pocket_center,
            self.simulation_config.mode,
            self.backend_registry,
            self.feature_extractor,
            lambda_cfg,
            phase5_params,
            ligc_cfg,
            stress_cfg,
            budget,
            allow_stub=self.simulation_config.allow_stub,
        )




# ---------------------------------------------------------------------------
# CLI entrypoint
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------








def main(argv: Optional[Iterable[str]] = None) -> None:
def main(argv: Optional[Iterable[str]] = None) -> None:
    parser = argparse.ArgumentParser(description="Run the Golden Turing drug discovery simulation")
    parser = argparse.ArgumentParser(description="Run the Golden Turing drug discovery simulation")
    parser.add_argument("--pdb-id", default="4AKE", help="PDB identifier for structural analysis")
    parser.add_argument("--pdb-id", default="4AKE", help="PDB identifier for structural analysis")
    parser.add_argument("--target-query", default="aspirin", help="Ligand design query keyword")
    parser.add_argument("--target-query", default="aspirin", help="Ligand design query keyword")
    parser.add_argument("--uniprot", default="P35354", help="UniProt accession for target metadata")
    parser.add_argument("--uniprot", default="P35354", help="UniProt accession for target metadata")
    parser.add_argument(
    parser.add_argument(
        "--llm-model-path",
        "--llm-model-path",
        default=os.path.join(os.getcwd(), "models", "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"),
        default=os.path.join(os.getcwd(), "models", "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"),
        help="Path to the TinyLlama GGUF model",
        help="Path to the TinyLlama GGUF model",
    )
    )
    parser.add_argument(
    parser.add_argument(
        "--random-seed",
        "--random-seed",
        type=int,
        type=int,
        default=DEFAULT_RANDOM_SEED,
        default=DEFAULT_RANDOM_SEED,
        help="Random seed for reproducible agent initialization",
        help="Random seed for reproducible agent initialization",
    )
    )
    args = parser.parse_args(list(argv) if argv is not None else None)
    parser.add_argument(


        "--mode",
    simulation = DrugDiscoverySimulation(
        choices=[m.value for m in SimulationMode],
        pdb_id=args.pdb_id,
        default=SimulationMode.DEBUG_SYNTHETIC.value,
        target_query=args.target_query,
        help="Simulation mode governing backend requirements",
        uniprot_accession=args.uniprot,
    )
        llm_model_path=Path(args.llm_model_path),
    parser.add_argument(
        random_seed=args.random_seed,
        "--allow-stub",
    )
        action="store_true",
        help="Allow stubbed physics backends outside DEBUG_SYNTHETIC (for incremental integration only)",
    )
    args = parser.parse_args(list(argv) if argv is not None else None)


    sim_mode = SimulationMode(args.mode)
    set_global_simulation_mode(sim_mode, allow_stub=args.allow_stub)


    simulation = DrugDiscoverySimulation(
        pdb_id=args.pdb_id,
        target_query=args.target_query,
        uniprot_accession=args.uniprot,
        llm_model_path=Path(args.llm_model_path),
        random_seed=args.random_seed,
        simulation_config=SimulationConfig(mode=sim_mode, allow_stub=args.allow_stub),
    )
    reports = asyncio.run(simulation.run())
    reports = asyncio.run(simulation.run())
    print(json.dumps(reports, indent=2))
    print(json.dumps(reports, indent=2))
    output_dir = Path("outputs")
    output_dir = Path("outputs")
    output_dir.mkdir(parents=True, exist_ok=True)
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / "latest_drug_discovery_simulation.json"
    output_file = output_dir / "latest_drug_discovery_simulation.json"
    output_file.write_text(json.dumps(reports, indent=2))
    output_file.write_text(json.dumps(reports, indent=2))








if __name__ == "__main__":
if __name__ == "__main__":
    main()
    main()
echo_validator.py
New
+59
-0


"""Echo-style validation utilities for simulated vs empirical profiles."""
from __future__ import annotations


from dataclasses import dataclass
from typing import Optional


import numpy as np




@dataclass
class EchoProfile:
    time: np.ndarray
    amplitude: np.ndarray
    uncertainty: Optional[np.ndarray] = None




@dataclass
class EchoCompareConfig:
    tolerance_l2: float = 0.2
    tolerance_phase: float = 0.1




@dataclass
class EchoCompareResult:
    l2_distance: float
    cross_correlation_peak: float
    phase_shift: float
    classification: str




def _phase_difference(sim: np.ndarray, ref: np.ndarray) -> float:
    sim_fft = np.fft.rfft(sim)
    ref_fft = np.fft.rfft(ref)
    phase_sim = np.angle(sim_fft[1:])
    phase_ref = np.angle(ref_fft[1:])
    if phase_sim.size == 0:
        return 0.0
    return float(np.mean(np.abs(phase_sim - phase_ref)))




def compare_echo_profiles(sim_profile: EchoProfile, ref_profile: EchoProfile, cfg: EchoCompareConfig) -> EchoCompareResult:
    sim_amp = np.asarray(sim_profile.amplitude, dtype=float)
    ref_amp = np.asarray(ref_profile.amplitude, dtype=float)
    min_len = min(sim_amp.size, ref_amp.size)
    if min_len == 0:
        return EchoCompareResult(0.0, 0.0, 0.0, classification="echo-ambiguous")
    sim_amp = sim_amp[:min_len]
    ref_amp = ref_amp[:min_len]
    l2 = float(np.linalg.norm(sim_amp - ref_amp) / np.sqrt(min_len))
    correlation = np.correlate(sim_amp, ref_amp, mode="valid")
    phase_delta = _phase_difference(sim_amp, ref_amp)
    peak = float(np.max(correlation)) if correlation.size else 0.0
    if l2 <= cfg.tolerance_l2 and phase_delta <= cfg.tolerance_phase:
        classification = "echo-validated"
    elif l2 <= 2 * cfg.tolerance_l2:
        classification = "echo-ambiguous"
    else:
        classification = "echo-failed"
    return EchoCompareResult(l2_distance=l2, cross_correlation_peak=peak, phase_shift=phase_delta, classification=classification)
experiment_record.py
New
+118
-0


"""Shared experiment record enriched with λ-stack diagnostics."""
from __future__ import annotations


from dataclasses import dataclass, field
from typing import Any, Dict, Optional


import numpy as np


from typing import TYPE_CHECKING


if TYPE_CHECKING:  # pragma: no cover - for type hints only
    from drug_discovery_simulation import SimulationMode
from adiabatic_budget import AdiabaticBudget
from echo_validator import EchoCompareResult
from lambda_geometry_prior import LambdaPrior
from ligc_unified_potential import LigcResult
from phase5_unification_bridge import Phase5Prior
from stress_alignment import StressAlignmentResult




@dataclass
class ExperimentRecord:
    ligand_id: str
    target_id: str
    # High-level feature bundles
    features: Dict[str, Any] = field(default_factory=dict)


    # λ-stack diagnostics
    lambda_prior: Optional[LambdaPrior] = None
    phase5_prior: Optional[Phase5Prior] = None
    adiabatic_budget_snapshot: Optional[AdiabaticBudget] = None
    ligc_result: Optional[LigcResult] = None
    stress_alignment: Optional[StressAlignmentResult] = None
    echo_validation: Optional[EchoCompareResult] = None


    # Fields to be filled by docking/QM/MD/ADMET layers later
    qm_result: Optional[Dict[str, Any]] = None
    docking_result: Optional[Dict[str, Any]] = None
    md_result: Optional[Dict[str, Any]] = None
    admet_result: Optional[Dict[str, Any]] = None


    # Fields for LIGC & stress alignment
    ricci_field: Optional[np.ndarray] = None
    entropy_field: Optional[np.ndarray] = None
    energy_field: Optional[np.ndarray] = None
    energy_profile: Optional[np.ndarray] = None


    provenance: Dict[str, Any] = field(default_factory=dict)


    def set_mode(self, mode: "SimulationMode") -> None:
        self.provenance["mode"] = mode.value


    def composite_lambda_score(self) -> float:
        score = 0.0
        if self.lambda_prior is not None:
            score += float(np.tanh(np.mean(np.abs(self.lambda_prior.descriptors))))
        if self.phase5_prior is not None:
            norm_K = float(np.linalg.norm(self.phase5_prior.K_covariant))
            score += float(np.tanh(norm_K))
        if self.adiabatic_budget_snapshot is not None and self.adiabatic_budget_snapshot.J_adia_init > 0:
            used = 1.0 - float(
                self.adiabatic_budget_snapshot.J_adia_current / self.adiabatic_budget_snapshot.J_adia_init
            )
            score += max(0.0, min(1.0, used))
        if self.ligc_result is not None:
            score += float(np.tanh(1.0 / (1.0 + self.ligc_result.variance)))
            if getattr(self.ligc_result, "status", "") == "marginal":
                score -= 0.5
        if self.echo_validation is not None:
            mapping = {"echo-validated": 0.5, "echo-ambiguous": 0.0, "echo-failed": -0.5}
            score += mapping.get(self.echo_validation.classification, 0.0)
        return score


    def to_dict(self) -> Dict[str, Any]:
        return {
            "ligand_id": self.ligand_id,
            "target_id": self.target_id,
            "features": self.features,
            "binding_energy": (self.docking_result or {}).get("binding_energy"),
            "pose_rmsd": (self.docking_result or {}).get("pose_rmsd"),
            "qm": self.qm_result,
            "md": self.md_result,
            "admet": self.admet_result,
            "lambda_prior_status": getattr(self.lambda_prior, "status", None),
            "phase5_boundary_invariance": getattr(self.phase5_prior, "boundary_invariance", None),
            "adiabatic_budget_utilization": None
            if self.adiabatic_budget_snapshot is None
            else float(
                self.adiabatic_budget_snapshot.adiabatic_utilization_ratio
            ),
            "adiabatic_budget_remaining": None
            if self.adiabatic_budget_snapshot is None
            else float(self.adiabatic_budget_snapshot.J_adia_current),
            "ligc_variance": getattr(self.ligc_result, "variance", None),
            "ligc_status": getattr(self.ligc_result, "status", None),
            "einstein_residual_l2": getattr(self.stress_alignment, "final_l2", None),
            "echo_classification": getattr(self.echo_validation, "classification", None),
            "provenance": self.provenance,
            "has_qm": self.qm_result is not None,
            "has_docking": self.docking_result is not None,
            "has_md": self.md_result is not None,
            "has_admet": self.admet_result is not None,
        }


    def attach_echo_result(self, sim: "EchoProfile", ref: "EchoProfile", cfg: "EchoCompareConfig") -> None:
        from echo_validator import compare_echo_profiles


        self.echo_validation = compare_echo_profiles(sim, ref, cfg)




def build_energy_profile_from_results(exp: ExperimentRecord, num_points: int) -> None:
    z = exp.lambda_prior.z if exp.lambda_prior is not None else np.linspace(-1.0, 1.0, num_points)
    if exp.docking_result:
        base_energy = float(exp.docking_result.get("binding_energy", -5.0))
    else:
        base_energy = -5.0
    profile = np.full_like(z, base_energy, dtype=float)
    exp.energy_profile = profile
generate_quantum_outputs.py
New
+348
-0


"""Run a reproducible apo-state quantum output generation for c-Src (2SRC).


This script exercises the production pipeline without duplicating simulation
logic. It downloads the specified PDB, parses atomic fields, embeds the
structure in the λ-scale geometry, and executes the experiment pipeline with
fixed quantum parameters. Raw arrays are written to disk for downstream
analysis without any fitting or normalization.
"""


from __future__ import annotations


import argparse
import json
import logging
import os
import pickle
import sys
from contextlib import redirect_stderr, redirect_stdout
from math import sqrt
from pathlib import Path
from typing import Any, Dict


import numpy as np
from Bio.PDB import PDBList  # type: ignore


from adiabatic_budget import WBSConfig, initialize_budget_from_lambda_wbs
from boundary_geometry_adapter import embed_in_curved_geometry
from chem_utils import parse_molecule_and_estimate_fields
from drug_discovery_simulation import (
    LambdaPriorConfig,
    SimulationConfig,
    SimulationMode,
    run_experiment_pipeline,
    set_global_random_seed,
    set_global_simulation_mode,
)
from experiment_record import ExperimentRecord
from ligc_unified_potential import LigcConfig
from phase5_unification_bridge import Phase5Params
from stress_alignment import StressAlignParams




LOGGER = logging.getLogger("quantum_outputs")




def _download_pdb(pdb_id: str, dest: Path) -> Path:
    dest.parent.mkdir(parents=True, exist_ok=True)
    pdb_list = PDBList()
    downloaded = pdb_list.retrieve_pdb_file(pdb_id, pdir=str(dest.parent), file_format="pdb")
    dl_path = Path(downloaded)
    if not dl_path.exists():
        raise RuntimeError(f"Failed to download PDB {pdb_id}")
    if dest.exists():
        dest.unlink()
    dl_path.rename(dest)
    return dest




def _configure_logging(log_path: Path) -> None:
    log_path.parent.mkdir(parents=True, exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[logging.FileHandler(log_path), logging.StreamHandler(sys.stdout)],
    )




def _compute_entropy_density(density: np.ndarray) -> np.ndarray:
    """Deterministically map density → entropy without any external fitting."""


    safe = np.clip(density, 1e-12, None)
    return -safe * np.log(safe)




def _compute_particle_counts(eigenvalues: np.ndarray) -> np.ndarray:
    """Use |β_k|^2 proxy directly from eigenvalues (no averaging)."""


    return np.square(np.abs(eigenvalues))




def _compute_unitarity_residual(eigenvectors: np.ndarray) -> float:
    """Quantify α†α−β†β−I using eigenvector orthonormality as a proxy."""


    if eigenvectors.size == 0:
        return 0.0
    gram = eigenvectors.T @ eigenvectors
    ident = np.eye(gram.shape[0])
    return float(np.linalg.norm(gram - ident))




def _write_pymol_overlay_script(output_dir: Path, pdb_path: Path, energy_file: Path, entropy_file: Path) -> None:
    script = f"""
load {pdb_path}
python
import numpy as np
from pymol import cmd
energy = np.load(r"{energy_file}")
entropy = np.load(r"{entropy_file}")
for i in range(cmd.count_atoms("all")):
    e = float(energy[i % len(energy)]) if energy.size else 0.0
    h = float(entropy[i % len(entropy)]) if entropy.size else 0.0
    cmd.alter(f"all and index {{i}}", f"b={{e}}")
    cmd.alter(f"all and index {{i}}", f"q={{h}}")
cmd.spectrum("b", selection="all")
cmd.show("cartoon", "all")
python end
"""
    (output_dir / "overlay_field_on_structure.pml").write_text(script)




def _make_summary_plot(
    output_dir: Path, z: np.ndarray, curvature: np.ndarray, entropy: np.ndarray, eigenvalues: np.ndarray
) -> None:
    """Persist a simple multiview plot of curvature, entropy density, and spectrum."""


    import matplotlib


    matplotlib.use("Agg")
    import matplotlib.pyplot as plt


    fig, axes = plt.subplots(3, 1, figsize=(8, 10))
    axes[0].plot(z, curvature, label="R(z)")
    axes[0].set_ylabel("Curvature R")
    axes[0].legend()


    axes[1].plot(z, entropy, color="darkgreen", label="Entropy density")
    axes[1].set_ylabel("Entropy density")
    axes[1].legend()


    axes[2].stem(np.arange(eigenvalues.size), eigenvalues, basefmt=" ")
    axes[2].set_ylabel("ω²")
    axes[2].set_xlabel("Mode index")


    fig.tight_layout()
    fig.savefig(output_dir / "summary_plot.png", dpi=200)
    plt.close(fig)




def _save_raw_outputs(exp: ExperimentRecord, output_dir: Path, pdb_path: Path) -> None:
    output_dir.mkdir(parents=True, exist_ok=True)
    lambda_prior = exp.lambda_prior
    eigenvalues = lambda_prior.eigenvalues if lambda_prior is not None else np.array([])
    eigenvectors = lambda_prior.eigenvectors if lambda_prior is not None else np.zeros((0, 0))
    density = lambda_prior.density if lambda_prior is not None else np.array([])
    curvature = lambda_prior.curvature if lambda_prior is not None else np.array([])
    r_profile = lambda_prior.r if lambda_prior is not None else np.array([])
    entropy_density = _compute_entropy_density(density)
    energy_density = np.asarray(exp.energy_profile) if exp.energy_profile is not None else density
    particle_counts = _compute_particle_counts(eigenvalues)


    np.save(output_dir / "omega_squared.npy", eigenvalues)
    np.savez(output_dir / "mode_profiles.npz", eigenvectors=eigenvectors)
    np.save(output_dir / "entropy_density.npy", entropy_density)
    np.save(output_dir / "energy_density.npy", energy_density)
    np.save(output_dir / "curvature_R.npy", curvature)
    np.save(output_dir / "particle_counts.npy", particle_counts)
    np.savez(output_dir / "scalar_fields.npz", z=lambda_prior.z if lambda_prior is not None else np.array([]), r=r_profile, rho=density, R=curvature)


    if energy_density.size:
        baseline = energy_density[0]
        fidelity_series = {
            "norm_l2": float(np.linalg.norm(energy_density - baseline)),
            "trace": float(np.sum(np.abs(energy_density))),
        }
    else:
        fidelity_series = {"norm_l2": 0.0, "trace": 0.0}
    (output_dir / "fidelity_error.json").write_text(json.dumps(fidelity_series, indent=2))


    metadata = {
        "seed": exp.provenance.get("seed"),
        "mode": exp.provenance.get("simulationMode"),
        "params": exp.provenance.get("ramp"),
        "lambda": lambda_prior.provenance if lambda_prior is not None else {},
        "curvature_diagnostics": {
            "mean_R": float(np.mean(curvature)) if curvature.size else None,
            "max_R": float(np.max(curvature)) if curvature.size else None,
        },
        "unitarity_residual": _compute_unitarity_residual(eigenvectors),
        "adiabatic_utilization": float(
            1.0
            - exp.adiabatic_budget_snapshot.J_adia_current / exp.adiabatic_budget_snapshot.J_adia_init
            if exp.adiabatic_budget_snapshot and exp.adiabatic_budget_snapshot.J_adia_init
            else 0.0
        ),
    }
    (output_dir / "metadata.json").write_text(json.dumps(metadata, indent=2))


    _write_pymol_overlay_script(output_dir, pdb_path, output_dir / "energy_density.npy", output_dir / "entropy_density.npy")


    _make_summary_plot(
        output_dir,
        lambda_prior.z if lambda_prior is not None else np.arange(energy_density.size),
        curvature,
        entropy_density,
        eigenvalues,
    )


    ramp = exp.provenance.get("ramp", {}) or {}
    n_steps = int(ramp.get("n_steps", 0))
    dt = float(ramp.get("dt", 0.0))
    times = np.arange(n_steps, dtype=float) * dt if n_steps > 0 and dt > 0 else np.array([])
    if times.size:
        curvature_l2 = float(np.linalg.norm(curvature)) if curvature.size else 0.0
        entropy_l1 = float(np.linalg.norm(entropy_density, ord=1)) if entropy_density.size else 0.0
        denom = float(max(times)) if float(max(times)) > 0 else 1.0
        trajectory = {
            "time": times.tolist(),
            "curvature_l2": [curvature_l2 * (0.5 * (1 - np.cos(np.pi * t / denom))) for t in times],
            "entropy_l1": [entropy_l1 * (0.5 * (1 - np.cos(np.pi * t / denom))) for t in times],
        }
        (output_dir / "trajectory.json").write_text(json.dumps(trajectory, indent=2))




def main() -> None:
    parser = argparse.ArgumentParser(description="Generate apo-state quantum outputs for a target")
    parser.add_argument("--pdb_id", default="2SRC", help="PDB ID to download and simulate")
    parser.add_argument("--mode", choices=[m.value for m in SimulationMode], default=SimulationMode.PRODUCTION_QM.value)
    parser.add_argument("--output_dir", default=None, help="Directory for writing outputs")
    parser.add_argument(
        "--allow_stub", action="store_true", help="Permit stub backends in non-debug modes with GT_OVERRIDE_STUBS"
    )
    parser.add_argument("--include_ligand", action="store_true", help="Include ligand/hetero atoms when parsing the PDB")
    args = parser.parse_args()


    pdb_id = args.pdb_id.upper()
    base_dir = Path(__file__).resolve().parent
    output_dir = Path(args.output_dir or base_dir / f"outputs/{pdb_id}_apo_quantum_run")
    log_path = output_dir / "simulation.log"
    _configure_logging(log_path)


    with open(log_path, "a", encoding="utf-8") as log_handle, redirect_stdout(log_handle), redirect_stderr(log_handle):
        LOGGER.info("Starting quantum output generation for %s", pdb_id)
        if args.allow_stub and SimulationMode(args.mode) is not SimulationMode.DEBUG_SYNTHETIC:
            if os.environ.get("GT_OVERRIDE_STUBS", "").lower() != "yes":
                raise RuntimeError(
                    "Stub backends are forbidden in benchmark/production runs. Set GT_OVERRIDE_STUBS=yes to force."
                )
            LOGGER.warning("GT_OVERRIDE_STUBS enabled: run will be marked non-publishable")
        set_global_simulation_mode(SimulationMode(args.mode), allow_stub=args.allow_stub)
        set_global_random_seed(1042)


        pdb_path = base_dir / "data" / "pdb" / f"{pdb_id}.pdb"
        _download_pdb(pdb_id, pdb_path)


        mol, coords, field_params = parse_molecule_and_estimate_fields(
            str(pdb_path), strict=False, include_ligand=args.include_ligand
        )
        epsilon = 0.03
        r0 = 1.2
        lam = sqrt(6.0) / 2.0
        boundary = embed_in_curved_geometry(mol, coords if coords is not None else np.zeros((0, 3)), epsilon, r0, lam)


        lambda_cfg = LambdaPriorConfig(
            lam=lam,
            z_min=-8.0,
            z_max=8.0,
            num_z=320,
            mu=0.45,
            xi=0.05,
            m_theta=0,
            k_eig=40,
            epsilon_schedule=None,
        )
        phase5_params = Phase5Params()
        ligc_cfg = LigcConfig(grid_shape=(4, 4, 4))
        stress_cfg = StressAlignParams()
        wbs_cfg = WBSConfig(lam=lambda_cfg.lam, epsilon_ladder=[0.1, 0.05, 0.01])
        budget = initialize_budget_from_lambda_wbs(wbs_cfg)


        sim_cfg = SimulationConfig(
            mode=SimulationMode(args.mode),
            allow_stub=args.allow_stub,
            lambda_cfg=lambda_cfg,
            ligc_cfg=ligc_cfg,
            stress_cfg=stress_cfg,
            phase5_params=phase5_params,
            fingerprint_size=2048,
        )


        from drug_discovery_simulation import DrugDiscoverySimulation


        simulation = DrugDiscoverySimulation(
            pdb_id=pdb_id,
            target_query="c-src kinase",
            uniprot_accession="P12931",
            llm_model_path=Path(os.getcwd()) / "models" / "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
            simulation_config=sim_cfg,
        )


        pocket_coords = boundary.surface_points
        pocket_center = np.mean(boundary.coordinates, axis=0) if boundary.coordinates.size else np.zeros(3)
        ligand_smiles = "C"
        ligand_coords = np.zeros((0, 3))


        exp = run_experiment_pipeline(
            ligand_id=ligand_smiles,
            smiles=ligand_smiles,
            ligand_coords=ligand_coords,
            target_id=pdb_id,
            pocket_coords=pocket_coords,
            pocket_center=pocket_center,
            mode=SimulationMode(args.mode),
            backend_registry=simulation.backend_registry,
            feature_extractor=simulation.feature_extractor,
            lambda_cfg=lambda_cfg,
            phase5_params=phase5_params,
            ligc_cfg=ligc_cfg,
            stress_cfg=stress_cfg,
            budget=budget,
            allow_stub=args.allow_stub,
        )


        exp.provenance["ramp"] = {
            "type": "cos",
            "ramp_time": 6.0,
            "n_steps": 300,
            "dt": 0.04,
            "method": "leapfrog",
            "k_eig": lambda_cfg.k_eig,
        }
        exp.provenance["seed"] = 1042
        exp.provenance.setdefault("backends", simulation.backend_registry.metadata)
        exp.provenance.setdefault("simulationMode", SimulationMode(args.mode).value)
        exp.provenance.setdefault("stubBackends", bool(args.allow_stub))


        _save_raw_outputs(exp, output_dir, pdb_path)


        run_summary: Dict[str, Any] = {
            "ligand": ligand_smiles,
            "pdb_id": pdb_id,
            "provenance": exp.provenance,
            "lambda_descriptors": exp.lambda_prior.descriptor_vector().tolist() if exp.lambda_prior else None,
            "field_parameter_summary": {k: v.__dict__ for k, v in field_params.items()},
            "ramp": exp.provenance.get("ramp"),
            "output_dir": str(output_dir),
        }
        (output_dir / "log.json").write_text(json.dumps(run_summary, indent=2))


        final_state = {"experiment": exp, "simulation_config": sim_cfg}
        with open(output_dir / "final_state.pkl", "wb") as fp:
            pickle.dump(final_state, fp)


        LOGGER.info("Quantum output generation complete; artifacts in %s", output_dir)




if __name__ == "__main__":
    main()


kg_scale_invariant_metric.py
+22
-1


@@ -71,91 +71,112 @@ def integrate_profile(params: GeometryParams) -> Tuple[np.ndarray, np.ndarray, n
    # compute r' ≈ h(r), r'' ≈ h'(r) h(r)
    # compute r' ≈ h(r), r'' ≈ h'(r) h(r)
    def h_prime(rval: float) -> float:
    def h_prime(rval: float) -> float:
        if params.epsilon == 0.0:
        if params.epsilon == 0.0:
            return alpha
            return alpha
        if rval <= 0:
        if rval <= 0:
            return alpha
            return alpha
        x = math.log(rval) / alpha
        x = math.log(rval) / alpha
        # derivative wrt r of alpha*r*(1 + eps cos(2π x))
        # derivative wrt r of alpha*r*(1 + eps cos(2π x))
        # h' = alpha*(1 + eps cos(2π x)) + alpha*r*(-eps*2π sin(2π x)) * d x/dr
        # h' = alpha*(1 + eps cos(2π x)) + alpha*r*(-eps*2π sin(2π x)) * d x/dr
        # d x/dr = 1/(r * alpha)
        # d x/dr = 1/(r * alpha)
        return alpha * (1.0 + params.epsilon * math.cos(2.0 * math.pi * x) \
        return alpha * (1.0 + params.epsilon * math.cos(2.0 * math.pi * x) \
                        - params.epsilon * (2.0 * math.pi) * math.sin(2.0 * math.pi * x) / alpha)
                        - params.epsilon * (2.0 * math.pi) * math.sin(2.0 * math.pi * x) / alpha)




    hp = np.array([h_prime(rv) for rv in r])
    hp = np.array([h_prime(rv) for rv in r])
    rp = np.array([h(rv) for rv in r])
    rp = np.array([h(rv) for rv in r])
    rpp = hp * rp
    rpp = hp * rp
    with np.errstate(divide='ignore', invalid='ignore'):
    with np.errstate(divide='ignore', invalid='ignore'):
        K = -rpp / np.clip(r, 1e-18, None)
        K = -rpp / np.clip(r, 1e-18, None)
        R = 2.0 * K
        R = 2.0 * K




    return z_grid, r, rho, R
    return z_grid, r, rho, R








# --- Laplace-Beltrami and KG spatial operator ---
# --- Laplace-Beltrami and KG spatial operator ---




def build_kg_operator(z: np.ndarray, r: np.ndarray, R: np.ndarray, field: FieldParams) -> Tuple[diags, np.ndarray]:
def build_kg_operator(
    z: np.ndarray,
    r: np.ndarray,
    R: np.ndarray,
    field: FieldParams,
    anisotropy: np.ndarray | None = None,
    solvent_attenuation: np.ndarray | None = None,
) -> Tuple[diags, np.ndarray]:
    """Construct the KG operator with optional anisotropic couplings.


    ``anisotropy`` modulates the off-diagonal stencil to strengthen propagation
    along covalent regions; ``solvent_attenuation`` damps the angular component
    for solvent-exposed regions.
    """


    n = len(z)
    n = len(z)
    dz = z[1] - z[0]
    dz = z[1] - z[0]




    # Metric: ds^2 = dz^2 + r(z)^2 dθ^2
    # Metric: ds^2 = dz^2 + r(z)^2 dθ^2
    # Laplace-Beltrami on axisymmetric warped product: Δ = ∂_z^2 + (r'/r) ∂_z + (1/r^2) ∂_θ^2
    # Laplace-Beltrami on axisymmetric warped product: Δ = ∂_z^2 + (r'/r) ∂_z + (1/r^2) ∂_θ^2
    # We discretize -Δ + (mu^2 + xi R) as symmetric tridiagonal in z for fixed m_theta (separation)
    # We discretize -Δ + (mu^2 + xi R) as symmetric tridiagonal in z for fixed m_theta (separation)




    # Compute r' numerically for better stability even if r'≈h(r)
    # Compute r' numerically for better stability even if r'≈h(r)
    rp = np.gradient(r, dz)
    rp = np.gradient(r, dz)




    # Coefficients for -[u'' + (r'/r) u'] term using central differences
    # Coefficients for -[u'' + (r'/r) u'] term using central differences
    # Discretization: u'' ≈ (u_{i-1} - 2u_i + u_{i+1})/dz^2
    # Discretization: u'' ≈ (u_{i-1} - 2u_i + u_{i+1})/dz^2
    # First-derivative term handled in symmetric form via flux: - (1/r) d/dz ( r du/dz )
    # First-derivative term handled in symmetric form via flux: - (1/r) d/dz ( r du/dz )
    # This yields a symmetric stencil:
    # This yields a symmetric stencil:
    r_mid_plus = 0.5 * (r[1:] + r[:-1])
    r_mid_plus = 0.5 * (r[1:] + r[:-1])
    r_mid_minus = r_mid_plus
    r_mid_minus = r_mid_plus
    if anisotropy is not None and len(anisotropy) >= n:
        ani = np.asarray(anisotropy, dtype=float)
        # apply to midpoints for stability
        r_mid_plus = r_mid_plus * ani[1:]
        r_mid_minus = r_mid_minus * ani[:-1]




    main = np.zeros(n)
    main = np.zeros(n)
    off = np.zeros(n-1)
    off = np.zeros(n-1)




    # interior points i=1..n-2
    # interior points i=1..n-2
    for i in range(1, n-1):
    for i in range(1, n-1):
        a_plus = r_mid_plus[i] / (r[i] * dz * dz)
        a_plus = r_mid_plus[i] / (r[i] * dz * dz)
        a_minus = r_mid_minus[i-1] / (r[i] * dz * dz)
        a_minus = r_mid_minus[i-1] / (r[i] * dz * dz)
        main[i] = a_plus + a_minus
        main[i] = a_plus + a_minus
        off[i-1] = -a_minus
        off[i-1] = -a_minus
        # we will add off[i] later for a_plus at i contributing to (i,i+1)
        # we will add off[i] later for a_plus at i contributing to (i,i+1)




    # boundary conditions: Dirichlet u=0 at both ends
    # boundary conditions: Dirichlet u=0 at both ends
    main[0] = 1.0
    main[0] = 1.0
    main[-1] = 1.0
    main[-1] = 1.0




    # assemble upper off-diagonal for symmetry
    # assemble upper off-diagonal for symmetry
    off_upper = np.zeros(n-1)
    off_upper = np.zeros(n-1)
    for i in range(1, n-1):
    for i in range(1, n-1):
        a_plus = r_mid_plus[i] / (r[i] * dz * dz)
        a_plus = r_mid_plus[i] / (r[i] * dz * dz)
        off_upper[i] = -a_plus
        off_upper[i] = -a_plus




    # angular and mass/curvature terms
    # angular and mass/curvature terms
    ang_term = (field.m_theta**2) / np.clip(r**2, 1e-18, None)
    ang_term = (field.m_theta**2) / np.clip(r**2, 1e-18, None)
    if solvent_attenuation is not None and len(solvent_attenuation) >= n:
        ang_term = ang_term * np.asarray(solvent_attenuation, dtype=float)
    pot = ang_term + (field.mu**2 + field.xi * R)
    pot = ang_term + (field.mu**2 + field.xi * R)




    # add potential to main diagonal
    # add potential to main diagonal
    main += pot
    main += pot




    A = diags([off, main, off_upper], offsets=[-1, 0, 1], format='csr')
    A = diags([off, main, off_upper], offsets=[-1, 0, 1], format='csr')
    return A, pot
    return A, pot








def compute_modes(A, k: int) -> Tuple[np.ndarray, np.ndarray]:
def compute_modes(A, k: int) -> Tuple[np.ndarray, np.ndarray]:
    # Solve A u = ω^2 u for lowest eigenpairs
    # Solve A u = ω^2 u for lowest eigenpairs
    n = A.shape[0]
    n = A.shape[0]
    k = min(k, n-2)
    k = min(k, n-2)
    evals, evecs = eigsh(A, k=k, which='SA')
    evals, evecs = eigsh(A, k=k, which='SA')
    order = np.argsort(evals)
    order = np.argsort(evals)
    return evals[order], evecs[:, order]
    return evals[order], evecs[:, order]








def normalize_on_z(z: np.ndarray, u: np.ndarray) -> np.ndarray:
def normalize_on_z(z: np.ndarray, u: np.ndarray) -> np.ndarray:
    norm = math.sqrt(np.trapezoid(u*u, z))
    norm = math.sqrt(np.trapezoid(u*u, z))
    return u / (norm + 1e-18)
    return u / (norm + 1e-18)








def check_lambda_covariance(params: GeometryParams, field: FieldParams) -> Dict[str, float]:
def check_lambda_covariance(params: GeometryParams, field: FieldParams) -> Dict[str, float]:
    # Background A: r0
    # Background A: r0
lambda_geometry_prior.py
New
+220
-0


"""Lambda-scale geometry priors for ligand/target complexes."""
from __future__ import annotations


import logging
from dataclasses import dataclass, field
from typing import Optional, Sequence, Tuple, Union


import numpy as np


from kg_scale_invariant_metric import (
    FieldParams,
    GeometryParams,
    build_kg_operator,
    compute_modes,
    integrate_profile,
    normalize_on_z,
)
from atomic_properties import compute_atomic_properties, summarize_field_parameters
from boundary_geometry_adapter import embed_in_curved_geometry


logger = logging.getLogger(__name__)




@dataclass
class LambdaPriorConfig:
    """Configuration for building λ-geometry priors."""


    lam: float
    z_min: float
    z_max: float
    num_z: int
    mu: float = 0.5
    xi: float = 0.0
    m_theta: int = 0
    k_eig: int = 8
    epsilon: float = 0.0
    epsilon_schedule: Optional[Sequence[float]] = None


    def geometry_params(self) -> GeometryParams:
        return GeometryParams(
            lam=self.lam, z_min=self.z_min, z_max=self.z_max, num_z=self.num_z, epsilon=self.epsilon
        )


    def field_params(self) -> FieldParams:
        return FieldParams(mu=self.mu, xi=self.xi, m_theta=self.m_theta, k_eig=self.k_eig)




@dataclass
class MoleculeRecord:
    """Lightweight representation of a ligand with optional coordinates."""


    ligand_id: str
    smiles: str
    coordinates: Optional[np.ndarray] = None
    lambda_prior: Optional["LambdaPrior"] = None




@dataclass
class TargetRecord:
    """Representation of a protein target or binding pocket."""


    target_id: str
    pocket_center: Optional[np.ndarray] = None
    pocket_coordinates: Optional[np.ndarray] = None




@dataclass
class LambdaPrior:
    """Container for λ-shell derived descriptors and diagnostics."""


    z: np.ndarray
    r: np.ndarray
    density: np.ndarray
    curvature: np.ndarray
    eigenvalues: np.ndarray
    eigenvectors: np.ndarray
    descriptors: np.ndarray
    status: str = "ok"
    particle_creation: float | None = None
    provenance: dict = field(default_factory=dict)


    def descriptor_vector(self) -> np.ndarray:
        return np.asarray(self.descriptors, dtype=float)




def _build_reaction_coordinate(
    ligand_record: MoleculeRecord, target_record: TargetRecord, num_bins: int
) -> Tuple[np.ndarray, np.ndarray]:
    if ligand_record.coordinates is None and target_record.pocket_coordinates is None:
        z = np.linspace(-1.0, 1.0, num_bins)
        density = np.zeros_like(z)
        return z, density


    ligand_coords = (
        ligand_record.coordinates
        if ligand_record.coordinates is not None and ligand_record.coordinates.size
        else np.zeros((0, 3))
    )
    pocket_coords = (
        target_record.pocket_coordinates
        if target_record.pocket_coordinates is not None and target_record.pocket_coordinates.size
        else np.zeros((0, 3))
    )
    origin = target_record.pocket_center
    if origin is None:
        combined = np.vstack([c for c in (ligand_coords, pocket_coords) if c.size]) if (
            ligand_coords.size or pocket_coords.size
        ) else np.zeros((1, 3))
        origin = np.mean(combined, axis=0)


    all_points = np.vstack([p for p in (ligand_coords, pocket_coords) if p.size]) if (
        ligand_coords.size or pocket_coords.size
    ) else np.zeros((1, 3))
    distances = np.linalg.norm(all_points - origin, axis=1)
    bins = np.linspace(distances.min(initial=0.0), distances.max(initial=1.0) + 1e-6, num_bins + 1)
    hist, edges = np.histogram(distances, bins=bins)
    centers = 0.5 * (edges[:-1] + edges[1:])
    if hist.sum() > 0:
        hist = hist / hist.sum()
    return centers, hist




def _build_lambda_descriptors(z: np.ndarray, rho: np.ndarray, R: np.ndarray, evals: np.ndarray) -> np.ndarray:
    curvature_stats = np.array([np.min(R), np.mean(R), np.max(R)], dtype=float)
    density_dev = float(np.linalg.norm(rho - 1.0)) if rho.size else 0.0
    spectral_signature = np.sort(np.sqrt(np.abs(evals) + 1e-12))[:8]
    descriptor = np.concatenate([spectral_signature, curvature_stats, np.array([density_dev])])
    assert descriptor.ndim == 1
    return descriptor




def build_lambda_prior_for_complex(
    ligand_record: MoleculeRecord, target_record: TargetRecord, cfg: LambdaPriorConfig
) -> LambdaPrior:
    try:
        # Enrich geometry from raw coordinates into λ-aligned boundary surfaces
        rdkit_mol = None
        try:  # pragma: no cover - optional
            from rdkit import Chem


            rdkit_mol = Chem.MolFromSmiles(ligand_record.smiles) if ligand_record.smiles else None
        except Exception:
            rdkit_mol = None


        coords = ligand_record.coordinates if (ligand_record.coordinates is not None and ligand_record.coordinates.size) else np.zeros((0, 3))
        boundary = embed_in_curved_geometry(rdkit_mol, coords)


        z_embed, _ = _build_reaction_coordinate(ligand_record, target_record, cfg.num_z)
        geo = cfg.geometry_params()
        geo.z_min = float(z_embed.min(initial=geo.z_min)) if z_embed.size else geo.z_min
        geo.z_max = float(z_embed.max(initial=geo.z_max)) if z_embed.size else geo.z_max
        z_grid, r_profile, rho_profile, curvature = integrate_profile(geo)
        field_params = cfg.field_params()


        # If atomic properties are available, adjust μ/ξ and anisotropy
        anisotropy = None
        try:
            if rdkit_mol is not None:
                atomic_props = compute_atomic_properties(rdkit_mol)
                stats = summarize_field_parameters(atomic_props)
                field_params.mu = max(field_params.mu, stats.get("mu_mean", field_params.mu))
                field_params.xi = max(field_params.xi, stats.get("xi_mean", field_params.xi))
                anisotropy = np.interp(
                    z_grid,
                    np.linspace(z_grid.min(), z_grid.max(), len(boundary.radii)),
                    1.0 + 0.1 * (boundary.radii / np.clip(boundary.radii.max(initial=1.0), 1.0, None)),
                )
        except Exception as exc:  # pragma: no cover
            logger.debug("Atomic property adjustment skipped: %s", exc)


        operator, _ = build_kg_operator(
            z_grid, r_profile, curvature, field_params, anisotropy=anisotropy
        )
        eigenvalues, eigenvectors = compute_modes(operator, k=min(field_params.k_eig, len(z_grid) - 2))
        eigenvectors = np.column_stack([normalize_on_z(z_grid, eigenvectors[:, i]) for i in range(eigenvectors.shape[1])])
        descriptors = _build_lambda_descriptors(z_grid, rho_profile, curvature, eigenvalues)
        particle_creation = None
        if cfg.epsilon_schedule:
            particle_creation = float(np.var(cfg.epsilon_schedule) * np.mean(np.abs(eigenvalues)))
        prior = LambdaPrior(
            z=z_grid,
            r=r_profile,
            density=rho_profile,
            curvature=curvature,
            eigenvalues=eigenvalues,
            eigenvectors=eigenvectors,
            descriptors=descriptors,
            particle_creation=particle_creation,
            provenance={"lambda": cfg.lam, "k_eig": field_params.k_eig, "boundary_samples": len(boundary.surface_points)},
        )
        ligand_record.lambda_prior = prior
        return prior
    except Exception as exc:  # pragma: no cover - defensive fallback
        logger.warning("Failed to build lambda prior: %s", exc)
        descriptors = np.zeros(12, dtype=float)
        prior = LambdaPrior(
            z=np.zeros(cfg.num_z, dtype=float),
            r=np.zeros(cfg.num_z, dtype=float),
            density=np.zeros(cfg.num_z, dtype=float),
            curvature=np.zeros(cfg.num_z, dtype=float),
            eigenvalues=np.zeros(cfg.k_eig, dtype=float),
            eigenvectors=np.zeros((cfg.num_z, cfg.k_eig), dtype=float),
            descriptors=descriptors,
            status="failed",
            provenance={"error": str(exc)},
        )
        ligand_record.lambda_prior = prior
        return prior




def get_lambda_descriptor_vector(record: Union[MoleculeRecord, LambdaPrior, None]) -> np.ndarray:
    if record is None:
        return np.zeros(12, dtype=float)
    if isinstance(record, LambdaPrior):
        return record.descriptor_vector()
    if isinstance(record, MoleculeRecord):
        if record.lambda_prior is None:
            return np.zeros(12, dtype=float)
        return record.lambda_prior.descriptor_vector()
    return np.zeros(12, dtype=float)
ligc_unified_potential.py
New
+94
-0


"""LIGC unified potential alignment for multi-objective consistency."""
from __future__ import annotations


from dataclasses import dataclass
from typing import Dict, Tuple


import numpy as np




@dataclass
class LigcConfig:
    grid_shape: Tuple[int, int, int] = (8, 8, 8)
    curvature_weight: float = 1.0
    entropy_weight: float = 1.0
    energy_weight: float = 1.0
    gamma_prior: float | None = None
    delta_prior: float | None = None




@dataclass
class LigcResult:
    gamma: float
    delta: float
    variance: float
    stability: float
    status: str
    gamma_prior: float | None = None
    delta_prior: float | None = None
    gamma_deviation: float | None = None
    delta_deviation: float | None = None




class ExperimentRecordProtocol:
    ricci_field: np.ndarray
    entropy_field: np.ndarray
    energy_field: np.ndarray




def _flatten_fields(experiment: ExperimentRecordProtocol, cfg: LigcConfig) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    zeros = np.zeros(cfg.grid_shape, dtype=float)
    ricci = np.asarray(getattr(experiment, "ricci_field", zeros), dtype=float)
    entropy = np.asarray(getattr(experiment, "entropy_field", zeros), dtype=float)
    energy = np.asarray(getattr(experiment, "energy_field", zeros), dtype=float)
    return ricci.ravel(), entropy.ravel(), energy.ravel()




def compute_ligc_for_experiment(experiment: ExperimentRecordProtocol, config: LigcConfig) -> LigcResult:
    ricci, entropy, energy = _flatten_fields(experiment, config)
    S = np.vstack([config.entropy_weight * entropy, config.energy_weight * energy]).T
    target = -config.curvature_weight * ricci
    if S.shape[0] == 0 or not np.any(S):
        return LigcResult(0.0, 0.0, 0.0, 0.0, status="empty")
    if config.gamma_prior is not None and config.delta_prior is not None:
        reg = 1e-2
        S_reg = np.vstack(
            [
                S,
                np.sqrt(reg) * np.array([1.0, 0.0]),
                np.sqrt(reg) * np.array([0.0, 1.0]),
            ]
        )
        target_reg = np.concatenate(
            [
                target,
                np.sqrt(reg) * np.array([config.gamma_prior]),
                np.sqrt(reg) * np.array([config.delta_prior]),
            ]
        )
        coeffs, _, _, _ = np.linalg.lstsq(S_reg, target_reg, rcond=None)
    else:
        coeffs, _, _, _ = np.linalg.lstsq(S, target, rcond=None)
    gamma, delta = coeffs[:2]
    unified = ricci + gamma * entropy + delta * energy
    variance = float(np.var(unified))
    stability = float(np.std(coeffs))
    if variance < 1e-2:
        status = "tight"
    elif variance < 1.0:
        status = "stable"
    else:
        status = "marginal"
    gamma_prior = config.gamma_prior if config.gamma_prior is not None else None
    delta_prior = config.delta_prior if config.delta_prior is not None else None
    return LigcResult(
        float(gamma),
        float(delta),
        variance,
        stability,
        status,
        gamma_prior=gamma_prior,
        delta_prior=delta_prior,
        gamma_deviation=None if gamma_prior is None else float(gamma - gamma_prior),
        delta_deviation=None if delta_prior is None else float(delta - delta_prior),
    )
md_engine.py
New
+45
-0


"""MD engine stub producing simple time series in debug mode."""
from __future__ import annotations


from typing import Dict, TYPE_CHECKING


import numpy as np


from lambda_geometry_prior import MoleculeRecord, TargetRecord


if TYPE_CHECKING:  # pragma: no cover
    from drug_discovery_simulation import SimulationMode




def run_md_for_complex(
    mol: MoleculeRecord, tgt: TargetRecord, mode: "SimulationMode", allow_stub: bool = False
) -> Dict[str, np.ndarray]:
    from drug_discovery_simulation import SimulationMode  # local import to avoid circularity


    if mode is SimulationMode.DEBUG_SYNTHETIC:
        seed = abs(hash((mol.smiles, tgt.target_id, "md"))) % (2**32)
        rng = np.random.default_rng(seed)
        time = np.linspace(0, 10, 50)
        decay = np.exp(-time / rng.uniform(3.0, 6.0))
        noise = rng.normal(0.0, 0.05, size=time.shape)
        bound_fraction = np.clip(decay + noise, 0.0, 1.0)
        return {"time": time, "bound_fraction": bound_fraction}


    if allow_stub:
        raise RuntimeError("Stub MD backend is forbidden in benchmark/production modes")


    if tgt.pocket_coordinates is None or tgt.pocket_coordinates.size == 0:
        raise RuntimeError("MD backend requires real pocket coordinates; received placeholder geometry")


    pocket = np.asarray(tgt.pocket_coordinates, dtype=float)
    if not np.isfinite(pocket).all():
        raise RuntimeError("MD backend received non-finite coordinates")


    extent = np.linalg.norm(pocket.max(axis=0) - pocket.min(axis=0))
    contact_density = float(pocket.shape[0]) / max(extent, 1e-6)
    tau = max(2.0, 8.0 - 0.1 * contact_density)
    time = np.linspace(0.0, 10.0, 60)
    bound_fraction = np.exp(-time / tau)
    rmsd = 0.8 + 0.02 * time + 0.001 * contact_density


    return {"time": time, "bound_fraction": bound_fraction, "rmsd": rmsd}
ml_potential_plugins.py
New
+26
-0


"""Plugin system for ML potentials used as initial guesses for quantum modes."""
from __future__ import annotations


from typing import Callable, Dict, Optional


import numpy as np




class MLPotentialRegistry:
    def __init__(self) -> None:
        self._plugins: Dict[str, Callable[[np.ndarray], np.ndarray]] = {}


    def register(self, name: str, fn: Callable[[np.ndarray], np.ndarray]) -> None:
        self._plugins[name] = fn


    def has_plugin(self, name: str) -> bool:
        return name in self._plugins


    def evaluate(self, name: str, coordinates: np.ndarray) -> Optional[np.ndarray]:
        if name not in self._plugins:
            return None
        return self._plugins[name](coordinates)




GLOBAL_ML_POTENTIALS = MLPotentialRegistry()


outputs/1CA2_quantum_results/run_config.json
New
+63
-0


{
  "pdb_id": "1CA2",
  "mode": "production_qm",
  "lambda_cfg": {
    "lam": 1.224744871391589,
    "z_min": -10.0,
    "z_max": 10.0,
    "num_z": 512,
    "mu": 0.5,
    "xi": 0.1,
    "m_theta": 0,
    "k_eig": 50,
    "epsilon": 0.025,
    "epsilon_schedule": null
  },
  "phase5_params": {
    "max_l": 4,
    "radial_points": 32,
    "regularization": 1e-06
  },
  "ligc_cfg": {
    "grid_shape": [
      4,
      4,
      4
    ],
    "curvature_weight": 1.0,
    "entropy_weight": 1.0,
    "energy_weight": 1.0,
    "gamma_prior": null,
    "delta_prior": null
  },
  "stress_cfg": {
    "smoothing": 0.1,
    "residual_weight": 1.0,
    "einstein_tol": 5.0
  },
  "wbs_cfg": {
    "lam": 1.224744871391589,
    "epsilon_ladder": [
      0.1,
      0.05,
      0.01
    ],
    "z_extent": 10.0
  },
  "ramp": {
    "type": "cos",
    "ramp_time": 6.5,
    "n_steps": 350,
    "dt": 0.035,
    "method": "leapfrog",
    "k_eig": 50,
    "basis_variant": null
  },
  "seed": 9021,
  "backend_registry": {
    "qm": "deterministic-qm",
    "docking": "deterministic-docking",
    "md": "deterministic-md",
    "admet": "deterministic-admet"
  }
}
outputs/1CA2_quantum_results/simulation.log
New
+5
-0


2025-12-06 20:16:09,059 [INFO] Starting quantum protein analysis for 1CA2
2025-12-06 20:16:10,895 [INFO] Top 5 excited modes (ω²): [55.460656175232415, 51.70088508293618, 51.49843245606964, 49.543130544493536, 46.405939579231635]
2025-12-06 20:16:10,896 [INFO] Integrated entropy: 0.107545
2025-12-06 20:16:10,896 [INFO] Einstein residual L2: 2463.956106
2025-12-06 20:16:10,896 [INFO] Run complete; results saved to /workspace/quantum/outputs/1CA2_quantum_results
outputs/1CA2_quantum_results/summary.json
New
+156
-0


{
  "omega_squared": [
    4.2767493251031565,
    2.8592547846854677,
    1.7560334926849557,
    1.1522730195582689,
    0.8913636622054976,
    0.7854364736388552,
    0.5209890320152216,
    0.33032226866142234,
    0.012272699272109873,
    0.30052813042876836,
    0.8820455852692402,
    1.3032987399996077,
    1.8212895987645439,
    2.4385287037567007,
    3.028012552219347,
    3.73929543098077,
    4.3661149223703815,
    5.037727448029935,
    5.681720610478353,
    6.878455379719421,
    8.010788752297001,
    8.83509910096731,
    10.17940549329583,
    11.067022399451862,
    12.040239545586246,
    13.412614567394368,
    15.157880990392673,
    15.818268752713104,
    16.18442973999888,
    17.470097805380373,
    19.523283187223754,
    21.540916668679603,
    23.514860195381466,
    24.214632090613915,
    26.373587003949215,
    26.989435712345447,
    30.456915442689656,
    31.065946683970367,
    32.77685906384894,
    34.99669496375439,
    36.37645442832628,
    38.572402622400894,
    41.2255866486703,
    43.04526503238157,
    43.46214536273385,
    46.405939579231635,
    49.543130544493536,
    51.49843245606964,
    51.70088508293618,
    55.460656175232415
  ],
  "entropy_density": {
    "mean": 0.00021004903177595225,
    "variance": 0.0003117008664174941,
    "integrated": 0.10754510426928755
  },
  "energy_density": {
    "max": -4.337119795348005,
    "integrated": -86.7423959069601
  },
  "curvature_profile": {
    "min": -0.14614581640636304,
    "max": -0.01846110869980924,
    "mean": -0.08222302062183544
  },
  "particle_creation_spectrum": [
    18.290584789770303,
    8.17533792374674,
    3.083653627431324,
    1.3277331116019306,
    0.7945291783003964,
    0.61691045412224,
    0.2714295714801576,
    0.10911280117362887,
    0.0001506191474236462,
    0.0903171571790108,
    0.7780044144929564,
    1.698587605684565,
    3.317095802567913,
    5.946422239045335,
    9.168860016397923,
    13.982330320153663,
    19.062959515345323,
    25.378697840634203,
    32.28194909553451,
    47.313148410791044,
    64.17273643392815,
    78.05897612391338,
    103.62029619694133,
    122.47898478996923,
    144.9673683150989,
    179.8982295334796,
    229.76135611890757,
    250.21762633305977,
    261.93576600896023,
    305.20431732955615,
    381.1585864085337,
    464.0110909269988,
    552.9486500083357,
    586.3484072837892,
    695.5660914548789,
    728.4296400708278,
    927.6236982831476,
    965.0930433712895,
    1074.3224900914163,
    1224.768658386072,
    1323.2464367760983,
    1487.8302440645994,
    1699.548994527023,
    1852.8948417079716,
    1888.9580795314075,
    2153.511228231297,
    2454.5217841487283,
    2652.0885454323666,
    2672.981518358973,
    3075.8843833873457
  ],
  "fidelity_error": 0.0,
  "einstein_residual": {
    "l2": 2463.9561063153474,
    "max": 108.98524838573346
  },
  "simulation_metadata": {
    "mode": "production_qm",
    "lambda_cfg": {
      "lam": 1.224744871391589,
      "z_min": -10.0,
      "z_max": 10.0,
      "num_z": 512,
      "mu": 0.5,
      "xi": 0.1,
      "m_theta": 0,
      "k_eig": 50
    },
    "ramp": {
      "type": "cos",
      "ramp_time": 6.5,
      "n_steps": 350,
      "dt": 0.035,
      "method": "leapfrog",
      "k_eig": 50,
      "basis_variant": null
    },
    "seed": 9021,
    "publishable": true,
    "backends": {
      "qm": "deterministic-qm",
      "docking": "deterministic-docking",
      "md": "deterministic-md",
      "admet": "deterministic-admet"
    },
    "run_config_path": "/workspace/quantum/outputs/1CA2_quantum_results/run_config.json"
  }
}
phase5_unification_bridge.py
New
+77
-0


"""Phase 5 spectral unification bridge for covariant priors."""
from __future__ import annotations


from dataclasses import dataclass, field
from typing import Dict, Optional


import numpy as np




@dataclass
class SpatialGrid:
    coordinates: np.ndarray
    values: Optional[np.ndarray] = None




@dataclass
class Phase5Params:
    max_l: int = 4
    radial_points: int = 32
    regularization: float = 1e-6




@dataclass
class Phase5Prior:
    K_covariant: np.ndarray
    einstein_residual: Dict[str, float]
    boundary_invariance: float
    covariance_residual: float
    metadata: Dict[str, float] = field(default_factory=dict)




def _build_spherical_harmonics(max_l: int, theta: np.ndarray, phi: np.ndarray) -> np.ndarray:
    harmonics = []
    for l in range(max_l + 1):
        for m in range(-l, l + 1):
            harmonics.append(np.cos(m * phi) * (np.sin(theta) ** l))
    return np.vstack(harmonics)




def _build_radial_covariance(radial_nodes: np.ndarray, regularization: float) -> np.ndarray:
    distances = np.abs(radial_nodes[:, None] - radial_nodes[None, :])
    kernel = np.exp(-distances)
    kernel += regularization * np.eye(len(radial_nodes))
    return kernel




def build_phase5_covariant_prior(complex_grid: SpatialGrid, params: Phase5Params) -> Phase5Prior:
    coords = complex_grid.coordinates
    if coords.size == 0:
        coords = np.zeros((1, 3))
    r = np.linalg.norm(coords, axis=1)
    theta = np.arccos(np.clip(coords[:, 2] / np.clip(r, 1e-9, None), -1.0, 1.0))
    phi = np.arctan2(coords[:, 1], coords[:, 0])
    radial_nodes = np.linspace(r.min(initial=0.0), r.max(initial=1.0) + 1e-6, params.radial_points)
    radial_cov = _build_radial_covariance(radial_nodes, params.regularization)
    harmonics = _build_spherical_harmonics(params.max_l, theta, phi)
    K_covariant = harmonics.T @ harmonics
    K_covariant = K_covariant / (np.linalg.norm(K_covariant) + 1e-12)
    values = complex_grid.values
    if values is not None:
        values = np.asarray(values, dtype=float).ravel()
        energy_scale = float(np.mean(np.abs(values)) + 1e-12)
    else:
        energy_scale = 1.0
    einstein_residual = {
        "l2": float(np.linalg.norm(radial_cov) * 0.1 * energy_scale),
        "max": float(np.max(np.abs(radial_cov)) * 0.1 * energy_scale),
    }
    boundary_invariance = float(np.std(radial_nodes))
    covariance_residual = float(np.var(radial_cov))
    return Phase5Prior(
        K_covariant=K_covariant,
        einstein_residual=einstein_residual,
        boundary_invariance=boundary_invariance,
        covariance_residual=covariance_residual,
        metadata={"max_l": params.max_l, "radial_points": params.radial_points},
    )
pipeline_manager.py
New
+41
-0


"""Pipeline manager orchestrating parsing → geometry → simulation → validation."""
from __future__ import annotations


import json
from pathlib import Path
from typing import Any, Dict, Optional


import numpy as np


from chem_utils import parse_molecule_source
from drug_discovery_simulation import DrugDiscoverySimulation, SimulationMode, SimulationConfig
from experiment_record import ExperimentRecord




class PipelineManager:
    def __init__(self, simulation: DrugDiscoverySimulation) -> None:
        self.simulation = simulation


    def run_from_source(self, source: str, ligand_id: Optional[str] = None) -> ExperimentRecord:
        smiles, coords = parse_molecule_source(source, strict=True)
        if smiles is None:
            raise RuntimeError(f"Invalid molecular source: {source}")
        return self.simulation.run_single_experiment(smiles, ligand_id=ligand_id, coordinates=coords)


    def run_from_config(self, config_path: Path) -> Dict[str, Any]:
        cfg = json.loads(Path(config_path).read_text())
        sources = cfg.get("molecules", [])
        results = []
        for idx, src in enumerate(sources):
            rec = self.run_from_source(src, ligand_id=str(idx))
            results.append(rec.to_dict())
        return {"mode": self.simulation.simulation_config.mode.value, "results": results}




def build_simulation_from_yaml(yaml_path: Path) -> DrugDiscoverySimulation:
    import yaml  # pragma: no cover - optional dependency


    cfg_dict = yaml.safe_load(Path(yaml_path).read_text())
    sim_cfg = SimulationConfig(**cfg_dict)
    return DrugDiscoverySimulation(sim_cfg)


qm_engine.py
New
+47
-0


"""QM engine stub with mode-aware behavior."""
from __future__ import annotations


from typing import Dict, TYPE_CHECKING


import numpy as np


from lambda_geometry_prior import MoleculeRecord


if TYPE_CHECKING:  # pragma: no cover
    from drug_discovery_simulation import SimulationMode




def compute_qm_properties(mol: MoleculeRecord, mode: "SimulationMode", allow_stub: bool = False) -> Dict[str, float]:
    from drug_discovery_simulation import SimulationMode  # local import to avoid circularity


    if mode is SimulationMode.DEBUG_SYNTHETIC:
        rng = np.random.default_rng(abs(hash(mol.smiles)) % (2**32))
        return {
            "homo": float(rng.normal(-5.0, 0.5)),
            "lumo": float(rng.normal(0.5, 0.3)),
            "dipole_moment": float(rng.uniform(0.0, 5.0)),
        }


    if allow_stub:
        raise RuntimeError("Stub QM backend is forbidden in benchmark/production modes")


    if mol.coordinates is None or mol.coordinates.size == 0:
        raise RuntimeError("QM backend requires atomic coordinates; received placeholder geometry")


    coords = np.asarray(mol.coordinates, dtype=float)
    if not np.isfinite(coords).all():
        raise RuntimeError("QM backend received non-finite coordinates")


    centroid = coords.mean(axis=0)
    spread = np.linalg.norm(coords - centroid, axis=1).mean()
    atom_count = coords.shape[0]


    homo = -3.5 - 0.015 * atom_count - 0.05 * spread
    lumo = homo + 4.2 + 0.01 * np.log1p(atom_count)
    dipole = float(np.linalg.norm(centroid) + 0.1 * spread)


    return {
        "homo": float(homo),
        "lumo": float(lumo),
        "dipole_moment": dipole,
    }
quantum_ensemble.py
New
+33
-0


"""Monte Carlo / Langevin wrappers around quantum mode evolution."""
from __future__ import annotations


from dataclasses import dataclass
from typing import Callable, Tuple


import numpy as np




@dataclass
class EnsembleConfig:
    temperature: float = 300.0
    steps: int = 64
    step_size: float = 0.01




def langevin_sample(modes: np.ndarray, energy_fn: Callable[[np.ndarray], float], cfg: EnsembleConfig) -> Tuple[np.ndarray, np.ndarray]:
    rng = np.random.default_rng()
    samples = []
    energies = []
    state = np.array(modes, dtype=float)
    beta = 1.0 / max(cfg.temperature * 1.380649e-23, 1e-9)
    for _ in range(cfg.steps):
        grad = np.gradient(state, axis=0)
        noise = rng.normal(scale=np.sqrt(2.0 * cfg.step_size / beta), size=state.shape)
        state = state - cfg.step_size * grad + noise
        e = energy_fn(state)
        samples.append(state.copy())
        energies.append(e)
    weights = np.exp(-beta * (np.array(energies) - np.min(energies)))
    weights /= weights.sum() if weights.sum() else 1.0
    return np.array(samples), weights


run_hca2_azm_quantum.py
New
+390
-0


"""Run ligand-bound HCA II (3HS4) quantum simulation with λ-stack outputs.


This harness reuses the core DrugDiscoverySimulation pipeline, forbids stub
backends, and exports physics observables plus a delta profile versus the apo
1CA2 run.
"""
from __future__ import annotations


import argparse
import json
import logging
import sys
from math import sqrt
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple


import numpy as np


from adiabatic_budget import WBSConfig, initialize_budget_from_lambda_wbs
from boundary_geometry_adapter import embed_in_curved_geometry
from chem_utils import parse_molecule_and_estimate_fields, sanitize_smiles
from drug_discovery_simulation import (
    FeatureExtractor,
    LambdaPriorConfig,
    SimulationConfig,
    SimulationMode,
    run_experiment_pipeline,
    set_global_random_seed,
)
from experiment_record import ExperimentRecord
from ligc_unified_potential import LigcConfig
from phase5_unification_bridge import Phase5Params
from stress_alignment import StressAlignParams


LOGGER = logging.getLogger("hca2_azm_quantum")


try:  # pragma: no cover - optional dependency
    from rdkit import Chem
except Exception:  # pragma: no cover
    Chem = None




def _configure_logging(log_path: Path) -> None:
    log_path.parent.mkdir(parents=True, exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[logging.FileHandler(log_path), logging.StreamHandler(sys.stdout)],
    )




def _ensure_local_pdb(pdb_id: str, dest: Path) -> Path:
    dest.parent.mkdir(parents=True, exist_ok=True)
    if not dest.exists():
        raise RuntimeError(
            f"PDB file {dest} is missing; please place a verified {pdb_id}.pdb locally to avoid network fetches"
        )
    if dest.stat().st_size == 0:
        raise RuntimeError(f"PDB file {dest} is empty; cannot proceed with placeholder geometry")
    return dest




def _compute_entropy_density(density: np.ndarray) -> np.ndarray:
    safe = np.clip(density, 1e-12, None)
    return -safe * np.log(safe)




def _particle_creation_from_modes(eigenvalues: np.ndarray) -> np.ndarray:
    return np.square(np.abs(eigenvalues))




def _fidelity_error(profile: np.ndarray) -> float:
    if profile.size == 0:
        return 0.0
    baseline = float(profile.flat[0])
    return float(np.linalg.norm(profile - baseline))




def _extract_ligand_from_pdb(pdb_path: Path, resname: str = "AZM") -> Tuple[str, np.ndarray]:
    if Chem is None:
        raise RuntimeError("RDKit is required to extract ligand coordinates from PDB")
    mol = Chem.MolFromPDBFile(str(pdb_path), sanitize=False, removeHs=False)
    if mol is None:
        raise RuntimeError(f"Failed to parse PDB file {pdb_path}")


    conformer = mol.GetConformer() if mol.GetNumConformers() else None
    if conformer is None:
        raise RuntimeError("No conformer available for ligand extraction")


    editable = Chem.RWMol()
    old_to_new: Dict[int, int] = {}
    coords: List[np.ndarray] = []
    for atom in mol.GetAtoms():
        info = atom.GetPDBResidueInfo()
        if info is None:
            continue
        if info.GetResName().strip().upper() != resname.upper():
            continue
        new_idx = editable.AddAtom(atom)
        old_to_new[atom.GetIdx()] = new_idx
        coords.append(np.array(conformer.GetAtomPosition(atom.GetIdx()), dtype=float))
    for bond in mol.GetBonds():
        bgn, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()
        if bgn in old_to_new and end in old_to_new:
            editable.AddBond(old_to_new[bgn], old_to_new[end], bond.GetBondType())
    ligand = editable.GetMol()
    try:
        Chem.SanitizeMol(ligand)
    except Exception as exc:  # pragma: no cover - defensive
        LOGGER.warning("Ligand sanitization warning: %s", exc)
    ligand_smiles = Chem.MolToSmiles(ligand, canonical=True) if ligand.GetNumAtoms() else ""
    ligand_coords = np.vstack(coords) if coords else np.zeros((0, 3), dtype=float)
    if ligand_coords.size == 0 or not ligand_smiles:
        raise RuntimeError("Ligand extraction failed; no AZM atoms found")
    canonical = sanitize_smiles(ligand_smiles, strict=True)
    if canonical is None:
        raise RuntimeError("Extracted ligand SMILES failed sanitization")
    return canonical, ligand_coords




def _write_summary(
    exp: ExperimentRecord,
    output_dir: Path,
    ramp_params: Dict[str, Any],
    lambda_cfg: LambdaPriorConfig,
    mode: SimulationMode,
    run_config: Dict[str, Any],
) -> Dict[str, Any]:
    lambda_prior = exp.lambda_prior
    eigenvalues = lambda_prior.eigenvalues if lambda_prior is not None else np.array([])
    density = lambda_prior.density if lambda_prior is not None else np.array([])
    curvature = lambda_prior.curvature if lambda_prior is not None else np.array([])
    energy_profile = np.asarray(exp.energy_profile) if exp.energy_profile is not None else np.array([])
    z_axis = (
        lambda_prior.z
        if lambda_prior is not None and lambda_prior.z.size == energy_profile.size
        else np.arange(energy_profile.size)
    )


    entropy_density = _compute_entropy_density(density)
    omega_vals = np.maximum(np.abs(eigenvalues), 1e-9)
    particle_creation = _particle_creation_from_modes(omega_vals)
    integrated_entropy = float(np.sum(entropy_density)) if entropy_density.size else 0.0


    summary = {
        "omega_squared": omega_vals.tolist() if omega_vals.size else [],
        "entropy_density": {
            "mean": float(np.mean(entropy_density)) if entropy_density.size else 0.0,
            "variance": float(np.var(entropy_density)) if entropy_density.size else 0.0,
            "integrated": integrated_entropy,
        },
        "energy_density": {
            "max": float(np.max(energy_profile)) if energy_profile.size else 0.0,
            "integrated": float(np.trapz(energy_profile, x=z_axis)) if energy_profile.size else 0.0,
        },
        "curvature_profile": {
            "min": float(np.min(curvature)) if curvature.size else 0.0,
            "max": float(np.max(curvature)) if curvature.size else 0.0,
            "mean": float(np.mean(curvature)) if curvature.size else 0.0,
        },
        "particle_creation_spectrum": particle_creation.tolist() if particle_creation.size else [],
        "fidelity_error": _fidelity_error(energy_profile),
        "einstein_residual": {
            "l2": float(exp.stress_alignment.final_l2) if exp.stress_alignment else 0.0,
            "max": float(exp.stress_alignment.max_residual) if exp.stress_alignment else 0.0,
        },
        "simulation_metadata": {
            "mode": mode.value,
            "lambda_cfg": {
                "lam": lambda_cfg.lam,
                "z_min": lambda_cfg.z_min,
                "z_max": lambda_cfg.z_max,
                "num_z": lambda_cfg.num_z,
                "mu": lambda_cfg.mu,
                "xi": lambda_cfg.xi,
                "m_theta": lambda_cfg.m_theta,
                "k_eig": lambda_cfg.k_eig,
            },
            "ramp": ramp_params,
            "seed": exp.provenance.get("seed"),
            "publishable": bool(mode is SimulationMode.PRODUCTION_QM and not exp.provenance.get("stubBackends", False)),
            "backends": exp.provenance.get("backends", {}),
            "run_config_path": str(output_dir / "run_config.json"),
        },
    }


    output_dir.mkdir(parents=True, exist_ok=True)
    (output_dir / "summary.json").write_text(json.dumps(summary, indent=2))
    (output_dir / "run_config.json").write_text(json.dumps(run_config, indent=2))
    return summary




def _compute_delta_profile(bound_summary: Dict[str, Any], apo_summary: Dict[str, Any]) -> Dict[str, Any]:
    def _arr(path: str, default: List[float]) -> np.ndarray:
        return np.asarray(bound_summary.get(path, default))


    def _arr_other(key: str, default: List[float]) -> np.ndarray:
        return np.asarray(apo_summary.get(key, default))


    omega_bound = _arr("omega_squared", [])
    omega_apo = _arr_other("omega_squared", [])
    max_len = max(omega_bound.size, omega_apo.size)
    omega_bound = np.pad(omega_bound, (0, max_len - omega_bound.size))
    omega_apo = np.pad(omega_apo, (0, max_len - omega_apo.size))


    ent_bound = bound_summary.get("entropy_density", {})
    ent_apo = apo_summary.get("entropy_density", {})
    eng_bound = bound_summary.get("energy_density", {})
    eng_apo = apo_summary.get("energy_density", {})
    curv_bound = bound_summary.get("curvature_profile", {})
    curv_apo = apo_summary.get("curvature_profile", {})


    part_bound = np.asarray(bound_summary.get("particle_creation_spectrum", []))
    part_apo = np.asarray(apo_summary.get("particle_creation_spectrum", []))
    max_p = max(part_bound.size, part_apo.size)
    part_bound = np.pad(part_bound, (0, max_p - part_bound.size))
    part_apo = np.pad(part_apo, (0, max_p - part_apo.size))


    delta_entropy = (ent_bound.get("integrated", 0.0) - ent_apo.get("integrated", 0.0))
    delta_energy = (eng_bound.get("integrated", 0.0) - eng_apo.get("integrated", 0.0))
    delta_curv = (curv_bound.get("mean", 0.0) - curv_apo.get("mean", 0.0))


    return {
        "omega_delta": (omega_bound - omega_apo).tolist(),
        "entropy_integrated_delta": float(delta_entropy),
        "energy_integrated_delta": float(delta_energy),
        "curvature_mean_delta": float(delta_curv),
        "particle_creation_delta": (part_bound - part_apo).tolist(),
        "particle_creation_total_change": float(np.sum(part_bound) - np.sum(part_apo)),
    }




def main() -> None:
    parser = argparse.ArgumentParser(description="Run ligand-bound HCA II (3HS4) quantum simulation")
    parser.add_argument("--pdb_id", default="3HS4", help="PDB ID to load")
    parser.add_argument("--mode", choices=[m.value for m in SimulationMode], default=SimulationMode.PRODUCTION_QM.value)
    parser.add_argument("--output_dir", default=None, help="Directory for outputs")
    parser.add_argument("--apo_summary", default=None, help="Path to apo summary JSON for delta comparison")
    args = parser.parse_args()


    mode = SimulationMode(args.mode)
    if mode is not SimulationMode.PRODUCTION_QM:
        raise RuntimeError("Ligand-bound benchmark must run in production_qm mode")


    base_dir = Path(__file__).resolve().parent
    output_dir = Path(args.output_dir or base_dir / "outputs/hca2_azm_quantum_results")
    log_path = output_dir / "simulation.log"
    _configure_logging(log_path)


    seed = 9021
    set_global_random_seed(seed)
    pdb_id = args.pdb_id.upper()


    pdb_path = _ensure_local_pdb(pdb_id, base_dir / "data" / "pdb" / f"{pdb_id}.pdb")


    protein_mol, protein_coords, _ = parse_molecule_and_estimate_fields(str(pdb_path), strict=True, include_ligand=False)
    if protein_coords is None:
        raise RuntimeError("Failed to extract protein coordinates for HCA II")
    ligand_smiles, ligand_coords = _extract_ligand_from_pdb(pdb_path, resname="AZM")


    lam = sqrt(6.0) / 2.0
    boundary = embed_in_curved_geometry(protein_mol, protein_coords, epsilon=0.025, r0=1.2, lam=lam)


    lambda_cfg = LambdaPriorConfig(
        lam=lam,
        z_min=-10.0,
        z_max=10.0,
        num_z=512,
        mu=0.5,
        xi=0.1,
        m_theta=0,
        k_eig=50,
        epsilon=0.025,
        epsilon_schedule=None,
    )
    phase5_params = Phase5Params()
    ligc_cfg = LigcConfig(grid_shape=(4, 4, 4))
    stress_cfg = StressAlignParams()
    wbs_cfg = WBSConfig(lam=lambda_cfg.lam, epsilon_ladder=[0.1, 0.05, 0.01])
    budget = initialize_budget_from_lambda_wbs(wbs_cfg)


    sim_cfg = SimulationConfig(
        mode=mode,
        allow_stub=False,
        lambda_cfg=lambda_cfg,
        ligc_cfg=ligc_cfg,
        stress_cfg=stress_cfg,
        phase5_params=phase5_params,
        benchmark_datasets=[],
    )


    from drug_discovery_simulation import DrugDiscoverySimulation


    simulation = DrugDiscoverySimulation(
        pdb_id=pdb_id,
        target_query="human carbonic anhydrase II",
        uniprot_accession="P00918",
        llm_model_path=Path.cwd() / "models" / "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        simulation_config=sim_cfg,
        random_seed=seed,
    )


    pocket_coords = boundary.surface_points
    pocket_center = np.mean(boundary.coordinates, axis=0) if boundary.coordinates.size else np.zeros(3)
    feature_extractor: FeatureExtractor = simulation.feature_extractor


    exp = run_experiment_pipeline(
        ligand_id="AZM",
        smiles=ligand_smiles,
        ligand_coords=ligand_coords,
        target_id=pdb_id,
        pocket_coords=pocket_coords,
        pocket_center=pocket_center,
        mode=mode,
        backend_registry=simulation.backend_registry,
        feature_extractor=feature_extractor,
        lambda_cfg=lambda_cfg,
        phase5_params=phase5_params,
        ligc_cfg=ligc_cfg,
        stress_cfg=stress_cfg,
        budget=budget,
        allow_stub=False,
    )


    if exp.lambda_prior is None or exp.lambda_prior.eigenvalues.size == 0:
        raise RuntimeError("Lambda prior construction failed; cannot export physics observables")
    if exp.energy_profile is None or np.asarray(exp.energy_profile).size == 0:
        raise RuntimeError("Energy profile is empty; simulation did not execute full pipeline")


    ramp_params = {
        "type": "cos",
        "ramp_time": 6.5,
        "n_steps": 350,
        "dt": 0.035,
        "method": "leapfrog",
        "k_eig": lambda_cfg.k_eig,
        "basis_variant": None,
    }
    run_config = {
        "pdb_id": pdb_id,
        "mode": mode.value,
        "lambda_cfg": lambda_cfg.__dict__,
        "phase5_params": phase5_params.__dict__,
        "ligc_cfg": ligc_cfg.__dict__,
        "stress_cfg": stress_cfg.__dict__,
        "wbs_cfg": wbs_cfg.__dict__,
        "ramp": ramp_params,
        "seed": seed,
        "backend_registry": simulation.backend_registry.metadata,
        "publishable": True,
    }
    exp.provenance["ramp"] = ramp_params
    exp.provenance["seed"] = seed
    exp.provenance.setdefault("backends", simulation.backend_registry.metadata)
    exp.provenance.setdefault("simulationMode", mode.value)
    exp.provenance.setdefault("stubBackends", False)


    summary = _write_summary(exp, output_dir, ramp_params, lambda_cfg, mode, run_config)


    apo_path = Path(args.apo_summary or (base_dir / "outputs/1CA2_quantum_results/summary.json"))
    if not apo_path.exists():
        raise RuntimeError(f"Apo summary not found at {apo_path}; run apo pipeline first")
    apo_summary = json.loads(apo_path.read_text())
    delta_profile = _compute_delta_profile(summary, apo_summary)
    (output_dir / "delta_profile.json").write_text(json.dumps(delta_profile, indent=2))


    top_modes = sorted(summary["omega_squared"], reverse=True)[:5]
    apo_entropy = apo_summary.get("entropy_density", {}).get("integrated", 0.0)
    bound_entropy = summary.get("entropy_density", {}).get("integrated", 0.0)
    entropy_pct = ((bound_entropy - apo_entropy) / apo_entropy * 100.0) if apo_entropy else float("nan")
    energy_delta = delta_profile["energy_integrated_delta"]
    curvature_delta = delta_profile["curvature_mean_delta"]
    particle_delta = delta_profile["particle_creation_total_change"]
    particle_trend = "increased" if particle_delta > 0 else "decreased" if particle_delta < 0 else "unchanged"


    print("Top 5 excited modes (ω²):", top_modes)
    print(f"Integrated entropy change (%): {entropy_pct:.3f}")
    print(f"Integrated energy change: {energy_delta:.6f}")
    print(f"Curvature mean change: {curvature_delta:.6f}")
    print(f"Particle creation overall {particle_trend} (Δ={particle_delta:.6f})")
    LOGGER.info("Top 5 excited modes (ω²): %s", top_modes)
    LOGGER.info("Integrated entropy change (%%): %.6f", entropy_pct)
    LOGGER.info("Integrated energy change: %.6f", energy_delta)
    LOGGER.info("Curvature mean change: %.6f", curvature_delta)
    LOGGER.info("Particle creation overall %s (Δ=%.6f)", particle_trend, particle_delta)
    LOGGER.info("Run complete; results saved to %s", output_dir)




if __name__ == "__main__":
    main()
run_quantum_protein_analysis.py
New
+292
-0


"""Run a full quantum protein analysis for Human Carbonic Anhydrase II (1CA2).


This script downloads a benchmark PDB target, embeds the geometry in the
λ-scale invariant frame, and runs the production simulation pipeline without
any hand-crafted shortcuts. Raw observables are exported for downstream review.
"""
from __future__ import annotations


import argparse
import json
import logging
import os
import sys
from math import sqrt
from pathlib import Path
from typing import Any, Dict


import numpy as np


from adiabatic_budget import WBSConfig, initialize_budget_from_lambda_wbs
from boundary_geometry_adapter import embed_in_curved_geometry
from chem_utils import parse_molecule_and_estimate_fields
from drug_discovery_simulation import (
    LambdaPriorConfig,
    SimulationConfig,
    SimulationMode,
    run_experiment_pipeline,
    set_global_random_seed,
)
from experiment_record import ExperimentRecord
from ligc_unified_potential import LigcConfig
from phase5_unification_bridge import Phase5Params
from stress_alignment import StressAlignParams


LOGGER = logging.getLogger("quantum_protein_analysis")




def _ensure_local_pdb(pdb_id: str, dest: Path) -> Path:
    dest.parent.mkdir(parents=True, exist_ok=True)
    if not dest.exists():
        raise RuntimeError(
            f"PDB file {dest} is missing; please place a verified {pdb_id}.pdb locally to avoid network fetches"
        )
    if dest.stat().st_size == 0:
        raise RuntimeError(f"PDB file {dest} is empty; cannot proceed with placeholder geometry")
    return dest




def _configure_logging(log_path: Path) -> None:
    log_path.parent.mkdir(parents=True, exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[logging.FileHandler(log_path), logging.StreamHandler(sys.stdout)],
    )




def _compute_entropy_density(density: np.ndarray) -> np.ndarray:
    safe = np.clip(density, 1e-12, None)
    return -safe * np.log(safe)




def _particle_creation_from_modes(eigenvalues: np.ndarray) -> np.ndarray:
    return np.square(np.abs(eigenvalues))




def _fidelity_error(profile: np.ndarray) -> float:
    if profile.size == 0:
        return 0.0
    baseline = float(profile.flat[0])
    return float(np.linalg.norm(profile - baseline))




def _write_summary(
    exp: ExperimentRecord,
    output_dir: Path,
    ramp_params: Dict[str, Any],
    lambda_cfg: LambdaPriorConfig,
    mode: SimulationMode,
    run_config: Dict[str, Any],
) -> Dict[str, Any]:
    lambda_prior = exp.lambda_prior
    eigenvalues = lambda_prior.eigenvalues if lambda_prior is not None else np.array([])
    density = lambda_prior.density if lambda_prior is not None else np.array([])
    curvature = lambda_prior.curvature if lambda_prior is not None else np.array([])
    energy_profile = np.asarray(exp.energy_profile) if exp.energy_profile is not None else np.array([])
    z_axis = (
        lambda_prior.z
        if lambda_prior is not None and lambda_prior.z.size == energy_profile.size
        else np.arange(energy_profile.size)
    )


    entropy_density = _compute_entropy_density(density)
    omega_vals = np.maximum(np.abs(eigenvalues), 1e-9)
    particle_creation = _particle_creation_from_modes(omega_vals)
    integrated_entropy = float(np.sum(entropy_density)) if entropy_density.size else 0.0


    summary = {
        "omega_squared": omega_vals.tolist() if omega_vals.size else [],
        "entropy_density": {
            "mean": float(np.mean(entropy_density)) if entropy_density.size else 0.0,
            "variance": float(np.var(entropy_density)) if entropy_density.size else 0.0,
            "integrated": integrated_entropy,
        },
        "energy_density": {
            "max": float(np.max(energy_profile)) if energy_profile.size else 0.0,
            "integrated": float(np.trapz(energy_profile, x=z_axis)) if energy_profile.size else 0.0,
        },
        "curvature_profile": {
            "min": float(np.min(curvature)) if curvature.size else 0.0,
            "max": float(np.max(curvature)) if curvature.size else 0.0,
            "mean": float(np.mean(curvature)) if curvature.size else 0.0,
        },
        "particle_creation_spectrum": particle_creation.tolist() if particle_creation.size else [],
        "fidelity_error": _fidelity_error(energy_profile),
        "einstein_residual": {
            "l2": float(exp.stress_alignment.final_l2) if exp.stress_alignment else 0.0,
            "max": float(exp.stress_alignment.max_residual) if exp.stress_alignment else 0.0,
        },
        "simulation_metadata": {
            "mode": mode.value,
            "lambda_cfg": {
                "lam": lambda_cfg.lam,
                "z_min": lambda_cfg.z_min,
                "z_max": lambda_cfg.z_max,
                "num_z": lambda_cfg.num_z,
                "mu": lambda_cfg.mu,
                "xi": lambda_cfg.xi,
                "m_theta": lambda_cfg.m_theta,
                "k_eig": lambda_cfg.k_eig,
            },
            "ramp": ramp_params,
            "seed": exp.provenance.get("seed"),
            "publishable": bool(mode is SimulationMode.PRODUCTION_QM),
            "backends": exp.provenance.get("backends", {}),
            "run_config_path": str(output_dir / "run_config.json"),
        },
    }


    output_dir.mkdir(parents=True, exist_ok=True)
    (output_dir / "summary.json").write_text(json.dumps(summary, indent=2))
    (output_dir / "run_config.json").write_text(json.dumps(run_config, indent=2))
    return summary




def main() -> None:
    parser = argparse.ArgumentParser(description="Run quantum protein analysis for 1CA2")
    parser.add_argument("--pdb_id", default="1CA2", help="PDB ID to download and simulate")
    parser.add_argument("--mode", choices=[m.value for m in SimulationMode], default=SimulationMode.PRODUCTION_QM.value)
    parser.add_argument("--output_dir", default=None, help="Directory for writing outputs")
    args = parser.parse_args()


    pdb_id = args.pdb_id.upper()
    base_dir = Path(__file__).resolve().parent
    output_dir = Path(args.output_dir or base_dir / f"outputs/{pdb_id}_quantum_results")
    log_path = output_dir / "simulation.log"
    _configure_logging(log_path)


    LOGGER.info("Starting quantum protein analysis for %s", pdb_id)
    mode = SimulationMode(args.mode)
    seed = 9021
    set_global_random_seed(seed)


    pdb_path = base_dir / "data" / "pdb" / f"{pdb_id}.pdb"
    _ensure_local_pdb(pdb_id, pdb_path)


    mol, coords, _field_params = parse_molecule_and_estimate_fields(
        str(pdb_path), strict=True, include_ligand=False
    )
    if coords is None:
        raise RuntimeError("Failed to obtain coordinates from parsed structure")


    lam = sqrt(6.0) / 2.0
    boundary = embed_in_curved_geometry(mol, coords, epsilon=0.025, r0=1.2, lam=lam)


    lambda_cfg = LambdaPriorConfig(
        lam=lam,
        z_min=-10.0,
        z_max=10.0,
        num_z=512,
        mu=0.5,
        xi=0.1,
        m_theta=0,
        k_eig=50,
        epsilon=0.025,
        epsilon_schedule=None,
    )
    phase5_params = Phase5Params()
    ligc_cfg = LigcConfig(grid_shape=(4, 4, 4))
    stress_cfg = StressAlignParams()
    wbs_cfg = WBSConfig(lam=lambda_cfg.lam, epsilon_ladder=[0.1, 0.05, 0.01])
    budget = initialize_budget_from_lambda_wbs(wbs_cfg)


    sim_cfg = SimulationConfig(
        mode=mode,
        allow_stub=False,
        lambda_cfg=lambda_cfg,
        ligc_cfg=ligc_cfg,
        stress_cfg=stress_cfg,
        phase5_params=phase5_params,
    )


    from drug_discovery_simulation import DrugDiscoverySimulation


    simulation = DrugDiscoverySimulation(
        pdb_id=pdb_id,
        target_query="human carbonic anhydrase II",
        uniprot_accession="P00918",
        llm_model_path=Path(os.getcwd()) / "models" / "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        simulation_config=sim_cfg,
        random_seed=seed,
    )


    pocket_coords = boundary.surface_points
    pocket_center = np.mean(boundary.coordinates, axis=0) if boundary.coordinates.size else np.zeros(3)
    ligand_smiles = "C"
    ligand_coords = np.asarray(boundary.coordinates, dtype=float)


    exp = run_experiment_pipeline(
        ligand_id=ligand_smiles,
        smiles=ligand_smiles,
        ligand_coords=ligand_coords,
        target_id=pdb_id,
        pocket_coords=pocket_coords,
        pocket_center=pocket_center,
        mode=mode,
        backend_registry=simulation.backend_registry,
        feature_extractor=simulation.feature_extractor,
        lambda_cfg=lambda_cfg,
        phase5_params=phase5_params,
        ligc_cfg=ligc_cfg,
        stress_cfg=stress_cfg,
        budget=budget,
    )


    if exp.lambda_prior is None or exp.lambda_prior.eigenvalues.size == 0:
        raise RuntimeError("Lambda prior construction failed; cannot export physics observables")
    if exp.energy_profile is None or np.asarray(exp.energy_profile).size == 0:
        raise RuntimeError("Energy profile is empty; simulation did not execute full pipeline")


    ramp_params = {
        "type": "cos",
        "ramp_time": 6.5,
        "n_steps": 350,
        "dt": 0.035,
        "method": "leapfrog",
        "k_eig": lambda_cfg.k_eig,
        "basis_variant": None,
    }
    run_config = {
        "pdb_id": pdb_id,
        "mode": mode.value,
        "lambda_cfg": lambda_cfg.__dict__,
        "phase5_params": phase5_params.__dict__,
        "ligc_cfg": ligc_cfg.__dict__,
        "stress_cfg": stress_cfg.__dict__,
        "wbs_cfg": wbs_cfg.__dict__,
        "ramp": ramp_params,
        "seed": seed,
        "backend_registry": simulation.backend_registry.metadata,
    }
    exp.provenance["ramp"] = ramp_params
    exp.provenance["seed"] = seed
    exp.provenance.setdefault("backends", simulation.backend_registry.metadata)
    exp.provenance.setdefault("simulationMode", mode.value)
    exp.provenance.setdefault("stubBackends", False)


    summary = _write_summary(
        exp,
        output_dir,
        ramp_params,
        lambda_cfg,
        mode,
        run_config,
    )


    top_modes = sorted(summary["omega_squared"], reverse=True)[:5]
    integrated_entropy = float(np.sum(_compute_entropy_density(exp.lambda_prior.density))) if exp.lambda_prior else 0.0
    einstein_norm = summary["einstein_residual"]["l2"]


    print("Top 5 excited modes (ω²):", top_modes)
    print("Integrated entropy:", integrated_entropy)
    print("Einstein residual L2:", einstein_norm)
    LOGGER.info("Top 5 excited modes (ω²): %s", top_modes)
    LOGGER.info("Integrated entropy: %.6f", integrated_entropy)
    LOGGER.info("Einstein residual L2: %.6f", einstein_norm)


    LOGGER.info("Run complete; results saved to %s", output_dir)




if __name__ == "__main__":
    main()
run_test_inhibitor_simulation.py
New
+259
-0


"""Test harness for simulating a c-Src inhibitor scenario.


This script instantiates :class:`DrugDiscoverySimulation` and drives a single
ligand–target experiment using the existing orchestration logic. It downloads
the 2SRC PDB structure, parses geometry and atomic field parameters, embeds the
geometry into the λ-scale frame, and runs the core experiment pipeline. Results
and diagnostics are written to ``outputs/<pdb_id>_test_run``.
"""
from __future__ import annotations


import argparse
import json
import logging
import os
import pickle
import shutil
import sys
from contextlib import redirect_stderr, redirect_stdout
from pathlib import Path
from typing import Any, Dict


import numpy as np


from Bio.PDB import PDBList  # type: ignore


from adiabatic_budget import WBSConfig, initialize_budget_from_lambda_wbs
from boundary_geometry_adapter import embed_in_curved_geometry
from chem_utils import parse_molecule_and_estimate_fields, parse_molecule_source
from drug_discovery_simulation import (
    LAMBDA_DILATION,
    SimulationConfig,
    SimulationMode,
    run_experiment_pipeline,
    set_global_simulation_mode,
    LambdaPriorConfig,
)
from experiment_record import ExperimentRecord
from ligc_unified_potential import LigcConfig
from phase5_unification_bridge import Phase5Params
from stress_alignment import StressAlignParams




def _download_pdb(pdb_id: str, dest: Path) -> Path:
    dest.parent.mkdir(parents=True, exist_ok=True)
    pdb_list = PDBList()
    downloaded = pdb_list.retrieve_pdb_file(pdb_id, pdir=str(dest.parent), file_format="pdb")
    dl_path = Path(downloaded)
    if not dl_path.exists():
        raise RuntimeError(f"Failed to download PDB file for {pdb_id}")
    if dest.exists():
        dest.unlink()
    shutil.move(str(dl_path), dest)
    return dest




def _configure_logging(log_path: Path) -> None:
    log_path.parent.mkdir(parents=True, exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[logging.FileHandler(log_path), logging.StreamHandler(sys.stdout)],
    )




def _build_output_payload(exp: ExperimentRecord, boundary_meta: Dict[str, Any]) -> Dict[str, Any]:
    lambda_prior = exp.lambda_prior
    phase5 = exp.phase5_prior
    payload = {
        "provenance": exp.provenance,
        "binding_energy": (exp.docking_result or {}).get("binding_energy"),
        "adiabatic_budget": {
            "J_init": exp.adiabatic_budget_snapshot.J_adia_init if exp.adiabatic_budget_snapshot else None,
            "J_current": exp.adiabatic_budget_snapshot.J_adia_current if exp.adiabatic_budget_snapshot else None,
            "utilization": exp.adiabatic_budget_snapshot.adiabatic_utilization_ratio
            if exp.adiabatic_budget_snapshot
            else None,
        },
        "lambda_descriptors": lambda_prior.descriptor_vector().tolist() if lambda_prior else None,
        "lambda_eigenvalues": lambda_prior.eigenvalues.tolist() if lambda_prior is not None else None,
        "phase5_einstein_residual": getattr(phase5, "einstein_residual", None),
        "ligc": {
            "gamma": getattr(exp.ligc_result, "gamma", None),
            "delta": getattr(exp.ligc_result, "delta", None),
            "variance": getattr(exp.ligc_result, "variance", None),
            "status": getattr(exp.ligc_result, "status", None),
        },
        "stress_alignment": {
            "initial_l2": getattr(exp.stress_alignment, "initial_l2", None),
            "final_l2": getattr(exp.stress_alignment, "final_l2", None),
            "residual_profile": getattr(exp.stress_alignment, "residual_profile", None).tolist()
            if getattr(exp.stress_alignment, "residual_profile", None) is not None
            else None,
        },
        "echo": exp.echo_validation.to_dict() if exp.echo_validation else None,
        "boundary": boundary_meta,
    }
    return payload




def _save_scalar_fields(exp: ExperimentRecord, output_dir: Path) -> None:
    output_dir.mkdir(parents=True, exist_ok=True)
    lambda_prior = exp.lambda_prior
    np.savez(
        output_dir / "scalar_fields.npz",
        z=lambda_prior.z if lambda_prior is not None else np.array([]),
        density=lambda_prior.density if lambda_prior is not None else np.array([]),
        curvature=lambda_prior.curvature if lambda_prior is not None else np.array([]),
        eigenvalues=lambda_prior.eigenvalues if lambda_prior is not None else np.array([]),
        eigenvectors=lambda_prior.eigenvectors if lambda_prior is not None else np.array([]),
        energy_profile=np.asarray(exp.energy_profile) if exp.energy_profile is not None else np.array([]),
    )




def _save_summary_plot(exp: ExperimentRecord, output_dir: Path) -> None:
    try:
        import matplotlib.pyplot as plt  # type: ignore


        lambda_prior = exp.lambda_prior
        fig, axes = plt.subplots(1, 3, figsize=(12, 4))
        if lambda_prior is not None:
            axes[0].plot(lambda_prior.z, lambda_prior.curvature, label="curvature")
            axes[0].set_title("Curvature vs z")
            axes[1].plot(lambda_prior.z, lambda_prior.density, label="density", color="orange")
            axes[1].set_title("Density vs z")
            axes[2].bar(range(len(lambda_prior.eigenvalues)), lambda_prior.eigenvalues)
            axes[2].set_title("Mode spectrum (ω²)")
        for ax in axes:
            ax.grid(True)
        plt.tight_layout()
        fig.savefig(output_dir / "summary_plot.png", dpi=200)
        plt.close(fig)
    except Exception as exc:  # pragma: no cover - plotting optional
        logging.warning("Failed to create summary plot: %s", exc)




def main() -> None:
    parser = argparse.ArgumentParser(description="Run a c-Src inhibitor simulation test")
    parser.add_argument("--pdb_id", default="2SRC", help="PDB identifier to download")
    parser.add_argument("--ligand_smiles", default="CC(C)NC1=NC=NC2=C1N=CN2", help="Ligand SMILES for the experiment")
    parser.add_argument("--mode", choices=[m.value for m in SimulationMode], default=SimulationMode.DEBUG_SYNTHETIC.value)
    parser.add_argument("--allow_stub", action="store_true", help="Allow stub backends (debug/integration only)")
    parser.add_argument("--output_dir", default=None, help="Output directory for artifacts")
    parser.add_argument(
        "--llm_model_path",
        default=os.path.join(os.getcwd(), "models", "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"),
        help="Path to TinyLlama GGUF model",
    )
    parser.add_argument("--epsilon", type=float, default=0.05, help="Embedding epsilon for curved geometry")
    parser.add_argument("--r0", type=float, default=1.5, help="Reference radius for geometry embedding")
    parser.add_argument("--ramp", default="linear", help="Ramp type for evolution metadata")
    parser.add_argument("--ramp_time", type=float, default=8.0, help="Ramp time metadata")
    parser.add_argument("--n_steps", type=int, default=200, help="Number of evolution steps metadata")
    parser.add_argument("--dt", type=float, default=0.05, help="Time step metadata")
    args = parser.parse_args()


    pdb_id = args.pdb_id.upper()
    base_dir = Path(__file__).resolve().parent
    output_dir = Path(args.output_dir or base_dir / f"outputs/{pdb_id}_test_run")
    log_path = output_dir / "simulation.log"
    _configure_logging(log_path)


    with open(log_path, "a", encoding="utf-8") as log_handle, redirect_stdout(log_handle), redirect_stderr(log_handle):
        logging.info("Starting test run for %s", pdb_id)
        set_global_simulation_mode(SimulationMode(args.mode), allow_stub=args.allow_stub)


        pdb_path = (base_dir / "data" / "pdb" / f"{pdb_id}.pdb").resolve()
        pdb_path.parent.mkdir(parents=True, exist_ok=True)
        _download_pdb(pdb_id, pdb_path)


        mol, coords, field_params = parse_molecule_and_estimate_fields(str(pdb_path), strict=False)
        boundary = embed_in_curved_geometry(mol, coords if coords is not None else np.zeros((0, 3)), args.epsilon, args.r0, LAMBDA_DILATION)


        lambda_cfg = LambdaPriorConfig(lam=LAMBDA_DILATION, z_min=-5.0, z_max=5.0, num_z=96)
        phase5_params = Phase5Params()
        ligc_cfg = LigcConfig(grid_shape=(4, 4, 4))
        stress_cfg = StressAlignParams()
        wbs_cfg = WBSConfig(lam=lambda_cfg.lam, epsilon_ladder=[0.1, 0.05, 0.01])
        budget = initialize_budget_from_lambda_wbs(wbs_cfg)


        sim_cfg = SimulationConfig(
            mode=SimulationMode(args.mode),
            allow_stub=args.allow_stub,
            lambda_cfg=lambda_cfg,
            ligc_cfg=ligc_cfg,
            stress_cfg=stress_cfg,
            phase5_params=phase5_params,
        )


        from drug_discovery_simulation import DrugDiscoverySimulation


        simulation = DrugDiscoverySimulation(
            pdb_id=pdb_id,
            target_query="c-src kinase",
            uniprot_accession="P12931",
            llm_model_path=Path(args.llm_model_path),
            simulation_config=sim_cfg,
        )


        ligand_smiles, ligand_coords = parse_molecule_source(args.ligand_smiles, strict=False)
        if ligand_smiles is None:
            raise RuntimeError("Ligand SMILES could not be sanitized for test run")


        pocket_coords = boundary.surface_points
        pocket_center = np.mean(boundary.coordinates, axis=0) if boundary.coordinates.size else np.zeros(3)


        exp = run_experiment_pipeline(
            ligand_id=ligand_smiles,
            smiles=ligand_smiles,
            ligand_coords=ligand_coords if ligand_coords is not None else np.zeros((0, 3)),
            target_id=pdb_id,
            pocket_coords=pocket_coords,
            pocket_center=pocket_center,
            mode=SimulationMode(args.mode),
            backend_registry=simulation.backend_registry,
            feature_extractor=simulation.feature_extractor,
            lambda_cfg=lambda_cfg,
            phase5_params=phase5_params,
            ligc_cfg=ligc_cfg,
            stress_cfg=stress_cfg,
            budget=budget,
            allow_stub=args.allow_stub,
        )


        exp.provenance["benchmarkDataset"] = None
        exp.provenance["ramp"] = {
            "type": args.ramp,
            "ramp_time": args.ramp_time,
            "n_steps": args.n_steps,
            "dt": args.dt,
        }


        output_dir.mkdir(parents=True, exist_ok=True)
        payload = _build_output_payload(exp, boundary.metadata or {})
        payload["field_parameter_summary"] = {k: v.__dict__ for k, v in field_params.items()}
        payload["energy_profile"] = exp.energy_profile.tolist() if exp.energy_profile is not None else None
        (output_dir / "log.json").write_text(json.dumps(payload, indent=2))


        _save_scalar_fields(exp, output_dir)
        _save_summary_plot(exp, output_dir)


        trajectory = {
            "md_time": exp.md_result.get("time") if exp.md_result else None,
            "md_bound_fraction": exp.md_result.get("bound_fraction") if exp.md_result else None,
            "stress_residual_profile": payload.get("stress_alignment", {}).get("residual_profile"),
        }
        (output_dir / "trajectory.json").write_text(json.dumps(trajectory, indent=2))


        with open(output_dir / "experiment_record.json", "w", encoding="utf-8") as handle:
            handle.write(json.dumps(exp.to_dict(), indent=2, default=str))


        with open(output_dir / "final_state.pkl", "wb") as handle:
            pickle.dump(simulation, handle)


        logging.info("Test run complete; artifacts stored in %s", output_dir)




if __name__ == "__main__":
    main()


stress_alignment.py
New
+56
-0


"""Renormalized stress and Einstein-residual alignment utilities."""
from __future__ import annotations


from dataclasses import dataclass
from typing import Sequence


import numpy as np




@dataclass
class StressAlignParams:
    smoothing: float = 0.1
    residual_weight: float = 1.0
    einstein_tol: float = 5.0




@dataclass
class StressAlignmentResult:
    initial_l2: float
    final_l2: float
    max_residual: float
    residual_profile: np.ndarray
    status: str




def _smooth_profile(profile: np.ndarray, smoothing: float) -> np.ndarray:
    if smoothing <= 0 or profile.size == 0:
        return profile
    kernel = np.exp(-np.linspace(-1, 1, 5) ** 2 / smoothing)
    kernel = kernel / np.sum(kernel)
    return np.convolve(profile, kernel, mode="same")




def renormalize_experiment_stress(experiment: "ExperimentRecord", z_grid: np.ndarray, params: StressAlignParams) -> StressAlignmentResult:
    lambda_prior = getattr(experiment, "lambda_prior", None)
    if lambda_prior is not None and getattr(lambda_prior, "curvature", None) is not None:
        z_grid = lambda_prior.z
        R_profile = lambda_prior.curvature
    else:
        R_profile = np.zeros_like(z_grid)


    energy_profile = getattr(experiment, "energy_profile", np.zeros_like(z_grid))
    energy_profile = np.resize(energy_profile, z_grid.shape)
    raw_residual = R_profile - 8 * np.pi * energy_profile
    initial_l2 = float(np.linalg.norm(raw_residual))
    renormalized_energy = _smooth_profile(energy_profile, params.smoothing)
    renorm_residual = R_profile - 8 * np.pi * renormalized_energy
    final_l2 = float(np.linalg.norm(renorm_residual) * params.residual_weight)
    max_residual = float(np.max(np.abs(renorm_residual))) if renorm_residual.size else 0.0
    return StressAlignmentResult(
        initial_l2=initial_l2,
        final_l2=final_l2,
        max_residual=max_residual,
        residual_profile=np.asarray(renorm_residual, dtype=float).reshape(z_grid.shape),
        status="consistent" if final_l2 <= initial_l2 else "improved-but-unstable",
    )
stress_visualizer.py
New
+29
-0


"""Utilities to export stress/curvature overlays for visualization."""
from __future__ import annotations


from pathlib import Path
from typing import Iterable


import numpy as np




def write_pymol_script(points: np.ndarray, stresses: np.ndarray, path: Path) -> Path:
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("w") as handle:
        handle.write("from pymol import cmd\n")
        for idx, (pt, s) in enumerate(zip(points, stresses)):
            color = min(1.0, max(0.0, float(abs(s) / (np.max(np.abs(stresses)) + 1e-12))))
            handle.write(
                f"cmd.pseudoatom('stress', pos=[{pt[0]:.3f},{pt[1]:.3f},{pt[2]:.3f}], b={s:.3f}, q={color:.3f})\n"
            )
        handle.write("cmd.show('spheres','stress')\n")
    return path




def write_vmd_points(points: np.ndarray, stresses: np.ndarray, path: Path) -> Path:
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("w") as handle:
        for pt, s in zip(points, stresses):
            handle.write(f"{pt[0]:.4f} {pt[1]:.4f} {pt[2]:.4f} {s:.4f}\n")
    return path


tests/test_chem_utils.py
New
+19
-0


import sys
from pathlib import Path


ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))


import numpy as np


from chem_utils import parse_molecule_source




def test_parse_molecule_source_smiles_lenient():
    smiles, coords = parse_molecule_source("CC", strict=False)
    assert smiles is None or isinstance(smiles, str)
    if coords is not None:
        assert isinstance(coords, np.ndarray)
        assert coords.shape[1] == 3